#!/usr/bin/env bash
# This script was generated by bashly 1.3.2 (https://bashly.dev)
# Modifying it manually is not recommended

# :wrapper.bash3_bouncer
if ((BASH_VERSINFO[0] < 4 || (BASH_VERSINFO[0] == 4 && BASH_VERSINFO[1] < 2))); then
  printf "bash version 4.2 or higher is required\n" >&2
  exit 1
fi

# :command.master_script
# :command.root_command
root_command() {
  # src/commands/root_command.sh
  #!/bin/bash
  # Call the main test execution function
  # All modules are automatically loaded by bashly
  run_tests

}

# :command.version_command
version_command() {
  echo "$version"
}

# :command.usage
grpctestify_usage() {
  printf "grpctestify - gRPC Server Testing Tool\n\n"

  printf "%s\n" "Usage:"
  printf "  grpctestify [TEST_PATH] [OPTIONS]\n"
  printf "  grpctestify --help | -h\n"
  printf "  grpctestify --version\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "Options:"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "--no-color, -c"
    printf "    Disable colored output\n"
    echo

    # :flag.usage
    printf "  %s\n" "--verbose, -v"
    printf "    Enable verbose debug output\n"
    echo

    # :flag.usage
    printf "  %s\n" "--progress PROGRESS_MODE"
    printf "    Show progress indicator\n"
    printf "    %s\n" "Allowed: none, dots"
    printf "    %s\n" "Default: none"
    echo

    # :flag.usage
    printf "  %s\n" "--parallel PARALLEL"
    printf "    Run N tests in parallel\n"
    printf "    %s\n" "Default: 1"
    echo

    # :flag.usage
    printf "  %s\n" "--timeout TIMEOUT"
    printf "    Timeout for individual tests in seconds\n"
    printf "    %s\n" "Default: 30"
    echo

    # :flag.usage
    printf "  %s\n" "--retry RETRIES"
    printf "    Number of retries for failed network calls\n"
    printf "    %s\n" "Default: 3"
    echo

    # :flag.usage
    printf "  %s\n" "--retry-delay DELAY"
    printf "    Initial delay between retries in seconds\n"
    printf "    %s\n" "Default: 1"
    echo

    # :flag.usage
    printf "  %s\n" "--no-retry"
    printf "    Disable retry mechanisms for network failures\n"
    echo

    # :flag.usage
    printf "  %s\n" "--update"
    printf "    Check for updates and update the script\n"
    echo

    # :flag.usage
    printf "  %s\n" "--completion SHELL_TYPE"
    printf "    Install shell completion (bash, zsh, or all)\n"
    echo

    # :flag.usage
    printf "  %s\n" "--config"
    printf "    Show current configuration\n"
    echo

    # :flag.usage
    printf "  %s\n" "--init-config CONFIG_FILE"
    printf "    Create default configuration file\n"
    echo

    # :flag.usage
    printf "  %s\n" "--list-plugins"
    printf "    List available plugins\n"
    echo

    # :flag.usage
    printf "  %s\n" "--create-plugin PLUGIN_NAME"
    printf "    Create a new plugin template\n"
    echo

    # :flag.usage
    printf "  %s\n" "--log-junit JUNIT_FILE"
    printf "    Save test results in JUnit XML format to specified file\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "--help, -h"
    printf "    Show this help\n"
    echo
    printf "  %s\n" "--version"
    printf "    Show version number\n"
    echo

    # :command.usage_args
    printf "%s\n" "Arguments:"

    # :argument.usage
    printf "  %s\n" "TEST_PATH"
    printf "    Test file or directory\n"
    echo

    # :command.usage_environment_variables
    printf "%s\n" "Environment Variables:"

    # :environment_variable.usage
    printf "  %s\n" "GRPCTESTIFY_ADDRESS"
    printf "    Default gRPC server address (e.g., localhost:4770)\n"
    printf "    %s\n" "Default: localhost:4770"
    echo

    # :environment_variable.usage
    printf "  %s\n" "GRPCTESTIFY_TIMEOUT"
    printf "    Default timeout for gRPC calls in seconds\n"
    printf "    %s\n" "Default: 30"
    echo

    # :environment_variable.usage
    printf "  %s\n" "GRPCTESTIFY_VERBOSE"
    printf "    Enable verbose output (true/false)\n"
    printf "    %s\n" "Default: false"
    echo

    # :environment_variable.usage
    printf "  %s\n" "EXTERNAL_PLUGIN_DIR"
    printf "    Directory for external plugins\n"
    printf "    %s\n" "Default: ~/.grpctestify/plugins"
    echo

  fi
}

# :command.normalize_input
# :command.normalize_input_function
normalize_input() {
  local arg passthru flags
  passthru=false

  while [[ $# -gt 0 ]]; do
    arg="$1"
    if [[ $passthru == true ]]; then
      input+=("$arg")
    elif [[ $arg =~ ^(--[a-zA-Z0-9_\-]+)=(.+)$ ]]; then
      input+=("${BASH_REMATCH[1]}")
      input+=("${BASH_REMATCH[2]}")
    elif [[ $arg =~ ^(-[a-zA-Z0-9])=(.+)$ ]]; then
      input+=("${BASH_REMATCH[1]}")
      input+=("${BASH_REMATCH[2]}")
    elif [[ $arg =~ ^-([a-zA-Z0-9][a-zA-Z0-9]+)$ ]]; then
      flags="${BASH_REMATCH[1]}"
      for ((i = 0; i < ${#flags}; i++)); do
        input+=("-${flags:i:1}")
      done
    elif [[ "$arg" == "--" ]]; then
      passthru=true
      input+=("$arg")
    else
      input+=("$arg")
    fi

    shift
  done
}

# :command.inspect_args
inspect_args() {
  if ((${#args[@]})); then
    readarray -t sorted_keys < <(printf '%s\n' "${!args[@]}" | sort)
    echo args:
    for k in "${sorted_keys[@]}"; do
      echo "- \${args[$k]} = ${args[$k]}"
    done
  else
    echo args: none
  fi

  if ((${#deps[@]})); then
    readarray -t sorted_keys < <(printf '%s\n' "${!deps[@]}" | sort)
    echo
    echo deps:
    for k in "${sorted_keys[@]}"; do
      echo "- \${deps[$k]} = ${deps[$k]}"
    done
  fi

  if ((${#env_var_names[@]})); then
    readarray -t sorted_names < <(printf '%s\n' "${env_var_names[@]}" | sort)
    echo
    echo "environment variables:"
    for k in "${sorted_names[@]}"; do
      echo "- \$$k = ${!k:-}"
    done
  fi
}

# :command.user_lib
# src/lib/commands/help.sh
#!/bin/bash

# help.sh - Help command implementation
# Shows help information and usage examples

# Dependencies are loaded by loader.sh in root_command.sh

# Show help information
show_help() {
    echo "$APP_NAME - $APP_DESCRIPTION"
    echo ""
    echo "Usage:"
    echo "  $APP_NAME [TEST_PATH] [OPTIONS]"
    echo "  $APP_NAME --help"
    echo "  $APP_NAME --version"
    echo ""
    echo "Options:"
    echo "  --no-color, -c"
    echo "    Disable colored output"
    echo ""
    echo "  --verbose, -v"
    echo "    Enable verbose debug output"
    echo ""
    echo "  --progress PROGRESS_MODE"
    echo "    Show progress indicator"
    echo "    Default: none"
    echo ""
    echo "  --parallel JOBS"
    echo "    Run N tests in parallel"
    echo "    Default: 1"
    echo ""
    echo "  --version"
    echo "    Show version information"
    echo ""
    echo "  --update"
    echo "    Check for updates and update the script"
    echo ""
    echo "  --help, -h"
    echo "    Show this help message"
    echo ""
    echo "Arguments:"
    echo "  TEST_PATH"
    echo "    Test file or directory"
    echo ""
    echo "Examples:"
    echo "  # Run single test file"
    echo "  $APP_NAME test.gctf"
    echo ""
    echo "  # Run all tests in directory"
    echo "  $APP_NAME examples/"
    echo ""
    echo "  # Run tests with verbose output"
    echo "  $APP_NAME --verbose examples/"
    echo ""
    echo "  # Run tests in parallel with progress"
    echo "  $APP_NAME examples/ --parallel 4 --progress=dots"
    echo ""
    echo "  # Disable colors"
    echo "  $APP_NAME --no-color test.gctf"
    echo ""
    echo "  # Generate JUnit XML report"
    echo "  $APP_NAME tests/ --log-junit results.xml"
    echo ""
    echo "  # Check for updates"
    echo "  $APP_NAME --update"
    echo ""
    echo "  # Show version"
    echo "  $APP_NAME --version"
    echo ""
    echo "Test File Format (.gctf):"
    echo "  --- ADDRESS ---"
    echo "  localhost:4770"
    echo ""
    echo "  --- ENDPOINT ---"
    echo "  package.service/Method"
    echo ""
    echo "  --- REQUEST ---"
    echo "  {"
    echo "    \"key\": \"value\""
    echo "  }"
    echo ""
    echo "  --- RESPONSE ---"
    echo "  {"
    echo "    \"status\": \"OK\""
    echo "  }"
    echo ""
    echo "For more information, visit: https://github.com/gripmock/grpctestify"
}

# Show version information
show_version() {
    echo "$APP_NAME $version"
}

# Show update information
show_update_help() {
    echo "Update functionality:"
    echo ""
    echo "  $APP_NAME --update"
    echo ""
    echo "This command will:"
    echo "  1. Check for newer versions"
    echo "  2. Download the latest version"
    echo "  3. Verify checksum"
    echo "  4. Replace current script"
    echo ""
    echo "Current version: $version"
}

# Show completion installation information
show_completion_help() {
    echo "Shell completion:"
    echo ""
    echo "  $APP_NAME --completion [bash|zsh|all]"
    echo ""
    echo "This command will:"
    echo "  1. Generate completion script for specified shell"
    echo "  2. Install completion to appropriate location"
    echo "  3. Provide instructions for activation"
    echo ""
    echo "Supported shells: bash, zsh, all (both)"
    echo "Default: all"
}

# Show current configuration
show_configuration() {
    echo "Current configuration:"
    echo ""
    echo "  Version: $version"
    echo "  Script: $(basename "$0")"
    echo "  Working directory: $(pwd)"
    echo ""
    echo "Dependencies:"
    if command_exists grpcurl; then
        echo "  âœ… grpcurl: $(grpcurl --version 2>&1 | head -n1 | awk '{print $2}' || echo "installed")"
    else
        echo "  âŒ grpcurl: not installed"
    fi

    if command_exists jq; then
        echo "  âœ… jq: $(jq --version 2>/dev/null | sed 's/jq-//' || echo "installed")"
    else
        echo "  âŒ jq: not installed"
    fi

    if command_exists bc; then
        echo "  âœ… bc: $(bc --version 2>/dev/null | head -n1 | awk '{print $2}' || echo "installed")"
    else
        echo "  âŒ bc: not installed"
    fi
    echo ""
    echo "Configuration: Command line flags only"
}

# Create default configuration file
create_default_config() {
    local config_file="$1"

    if [[ -z "$config_file" ]]; then
        log error "Config file path is required"
        return 1
    fi

    # Configuration is handled via command line flags only

    if [[ -f "$config_file" ]]; then
        log warning "Configuration file already exists: $config_file"
        log info "Use --init-config with a different filename to create a new config file"
        return 0
    fi

    cat > "$config_file" << 'EOF'
# gRPC Testify Configuration File
# This file contains default settings for gRPC Testify

# Test execution settings
parallel_jobs=1
test_timeout=30
progress_mode=none

# Retry settings
retry_attempts=3
retry_delay=1
no_retry=false

# Output settings
verbose=false
no_color=false

# Plugin settings
plugin_path=./plugins

# Service settings
default_address=localhost:4770
EOF

    log success "Configuration file created: $config_file"
    log info "You can edit this file to customize your settings"
}

# Install shell completion
install_completion() {
    local shell_type="${1:-all}"

    case "$shell_type" in
        "bash"|"all")
            install_bash_completion
            ;;
        "zsh"|"all")
            install_zsh_completion
            ;;
        *)
            log error "Unsupported shell type: $shell_type"
            log info "Supported shells: bash, zsh, all"
            return 1
            ;;
    esac
}

# Install bash completion
install_bash_completion() {
    local completion_dir="$HOME/.local/share/bash-completion/completions"
    local completion_file="$completion_dir/grpctestify"

    ensure_directory "$completion_dir"

    cat > "$completion_file" << 'EOF'
# Bash completion for grpctestify
_grpctestify() {
    local cur prev opts
    COMPREPLY=()
    cur="${COMP_WORDS[COMP_CWORD]}"
    prev="${COMP_WORDS[COMP_CWORD-1]}"

    opts="--help --version --update --completion --config --init-config --list-plugins --create-plugin --no-color --verbose --progress --parallel --timeout --retry --retry-delay --no-retry --log-junit"

    case "${prev}" in
        --progress)
            COMPREPLY=( $(compgen -W "none dots" -- ${cur}) )
            return 0
            ;;
        --completion)
            COMPREPLY=( $(compgen -W "bash zsh all" -- ${cur}) )
            return 0
            ;;
        --log-junit)
            COMPREPLY=( $(compgen -f -- ${cur}) )
            return 0
            ;;
    esac

    if [[ ${cur} == -* ]]; then
        COMPREPLY=( $(compgen -W "${opts}" -- ${cur}) )
        return 0
    fi

    # Complete with .gctf files
    COMPREPLY=( $(compgen -f -X '!*.gctf' -- ${cur}) )
}

complete -F _grpctestify grpctestify
EOF

    log success "Bash completion installed for user"
    log info "Add 'source ~/.local/share/bash-completion/completions/grpctestify' to your ~/.bashrc"
}

# Install zsh completion
install_zsh_completion() {
    local completion_dir="$HOME/.local/share/zsh/site-functions"
    local completion_file="$completion_dir/_grpctestify"

    ensure_directory "$completion_dir"

    cat > "$completion_file" << 'EOF'
#compdef grpctestify

_grpctestify() {
    local context state line
    typeset -A opt_args

    _arguments -C \
        '1: :->command' \
        '*::arg:->args' \
        '--help[Show help message]' \
        '--version[Show version information]' \
        '--update[Check for updates]' \
        '--completion[Install shell completion]:shell:(bash zsh all)' \
        '--config[Show current configuration]' \
        '--init-config[Create default configuration file]:config_file:_files' \
        '--list-plugins[List available plugins]' \
        '--create-plugin[Create a new plugin template]:plugin_name:' \
        '--no-color[Disable colored output]' \
        '--verbose[Enable verbose debug output]' \
        '--progress[Show progress indicator]:mode:(none dots)' \
        '--parallel[Run N tests in parallel]:jobs:' \
        '--timeout[Timeout for individual tests in seconds]:seconds:' \

        '--retry[Number of retries for failed network calls]:attempts:' \
        '--retry-delay[Initial delay between retries in seconds]:delay:' \
        '--no-retry[Disable retry mechanisms for network failures]' \
        '--log-junit[Save test results in JUnit XML format]:file:_files' \
        '*:test_file:_files -g "*.gctf"'
}

_grpctestify "$@"
EOF

    log success "Zsh completion installed to fpath"
    log info "Add '/Users/babichev/.local/share/zsh/site-functions' to your fpath in ~/.zshrc"
}

# src/lib/commands/plugins.sh
#!/bin/bash

# plugins.sh - Plugin management commands

# List available plugins
list_plugins_command() {
    local plugin_type="${1:-all}"

    echo "Available plugins:"
    echo ""

    # List internal plugins directly without loading
    echo "Internal plugins:"
    echo "  - grpc_response_time (response_time) -> evaluate_grpc_response_time"
    echo "    Evaluate gRPC response time assertions"
    echo ""
    echo "  - asserts (asserts) -> evaluate_enhanced_asserts"
    echo "    Enhanced assertions with inline types"
    echo ""
    echo "  - proto (proto) -> evaluate_proto_asserts"
    echo "    Protocol buffer field assertions"
    echo ""
    echo "  - tls (tls) -> evaluate_tls_asserts"
    echo "    TLS/SSL certificate assertions"
    echo ""

    # Check for external plugins
    local plugin_dir="${EXTERNAL_PLUGIN_DIR:-~/.grpctestify/plugins}"
    plugin_dir=$(expand_tilde "$plugin_dir")

    if [[ -d "$plugin_dir" ]]; then
        local external_plugins=()
        while IFS= read -r -d '' plugin_file; do
            external_plugins+=("$plugin_file")
        done < <(find "$plugin_dir" -name "*.sh" -type f -print0 2>/dev/null)

        if [[ ${#external_plugins[@]} -gt 0 ]]; then
            echo "External plugins (${#external_plugins[@]} found in $plugin_dir):"
            for plugin_file in "${external_plugins[@]}"; do
                local plugin_name=$(basename "$plugin_file" .sh)
                echo "  - $plugin_name (external)"
            done
        else
            echo "No external plugins found in $plugin_dir"
        fi
    else
        echo "External plugin directory not found: $plugin_dir"
    fi
}

# Create a new plugin template
create_plugin_command() {
    local plugin_name="$1"

    if [[ -z "$plugin_name" ]]; then
        error_required "Plugin name"
        show_plugin_api_help
        return 1
    fi

    # Convert to lowercase and validate
    plugin_name=$(echo "$plugin_name" | tr '[:upper:]' '[:lower:]')

    if [[ ! "$plugin_name" =~ ^[a-z][a-z0-9_]*$ ]]; then
        log error "Invalid plugin name: $plugin_name"
        log error "Plugin name must start with lowercase letter and contain only lowercase letters, numbers, and underscores"
        return 1
    fi

    # Create plugin directory
    local plugin_dir="${EXTERNAL_PLUGIN_DIR:-~/.grpctestify/plugins}"
    plugin_dir=$(expand_tilde "$plugin_dir")
    ensure_directory "$plugin_dir"

    # Use official Plugin API to create template
    log info "Creating plugin template using Plugin API..."
    create_plugin_template "$plugin_name" "assertion" "$plugin_dir"
}

# Test a plugin assertion
test_plugin_command() {
    local plugin_name="$1"
    local assertion_args="$2"

    if [[ -z "$plugin_name" || -z "$assertion_args" ]]; then
        log error "Plugin name and assertion arguments are required"
        return 1
    fi

    # Load all plugins first
    load_all_plugins

    # Check if plugin exists
    if [[ -z "${PLUGIN_REGISTRY[$plugin_name]:-}" ]]; then
        log error "Plugin not found: $plugin_name"
        log info "Available plugins: $(list_plugin_names)"
        return 1
    fi

    # Create a test response
    local test_response='{"test": "data", "_grpc_status": "0", "_response_time": "100"}'

    log info "Testing plugin: $plugin_name"
    log info "Arguments: $assertion_args"
    log info "Test response: $test_response"

    if execute_plugin_assertion "$plugin_name" "$test_response" "$assertion_args"; then
        log success "Plugin assertion passed"
        return 0
    else
        log error "Plugin assertion failed"
        return 1
    fi
}

# Handle global plugin flags
handle_plugin_flags() {
    if [[ "$FLAG_LIST_PLUGINS" == "true" ]]; then
        list_plugins_command "all"
        exit 0
    fi

    if [[ -n "$FLAG_CREATE_PLUGIN" ]]; then
        create_plugin_command "$FLAG_CREATE_PLUGIN"
        exit 0
    fi
}

# Export functions for use in other modules
export -f list_plugins_command
export -f create_plugin_command
export -f test_plugin_command
export -f handle_plugin_flags

# src/lib/commands/run.sh
#!/bin/bash

# run.sh - Main test execution command
# This file contains the main logic for running gRPC tests

# All modules are automatically loaded by bashly

# Main test execution function
run_tests() {
    local test_path="${args[test_path]}"

    # Handle version flag
    if [[ "${args[--version]}" == "1" ]]; then
        show_version
        return 0
    fi

    # Handle help flag
    if [[ "${args[--help]}" == "1" ]]; then
        show_help
        return 0
    fi

    # Handle update flag
    if [[ "${args[--update]}" == "1" ]]; then
        update_command
        return 0
    fi

    # Handle completion flag
    if [[ -n "${args[--completion]}" ]]; then
        send_completions
        return 0
    fi

    # Handle config flag
    if [[ "${args[--config]}" == "1" ]]; then
        show_configuration
        return 0
    fi

    # Handle init-config flag
    if [[ -n "${args[--init-config]}" ]]; then
        create_default_config "${args[--init-config]}"
        return 0
    fi

    # Handle list-plugins flag
    if [[ "${args[--list-plugins]}" == "1" ]]; then
        list_plugins
        return 0
    fi

    # Handle create-plugin flag
    if [[ -n "${args[--create-plugin]}" ]]; then
        create_plugin_command "${args[--create-plugin]}"
        return 0
    fi

    # Validate test path
    if [[ -z "$test_path" ]]; then
        echo "Error: Test path is required" >&2
        show_help
        return 1
    fi

    # Check if test path exists
    if [[ ! -e "$test_path" ]]; then
        log error "Test path does not exist: $test_path"
        return 1
    fi

    # Set configuration from command line flags
    setup_configuration

    # Run the tests
    execute_tests "$test_path"
}

# Setup configuration from command line flags and environment variables
setup_configuration() {
    # Set progress mode
    if [[ -n "${args[--progress]}" ]]; then
        PROGRESS_MODE="${args[--progress]}"
    fi

    # Set parallel execution
    if [[ -n "${args[--parallel]}" ]]; then
        if ! validate_parallel_jobs "${args[--parallel]}"; then
            exit 1
        fi
        PARALLEL_JOBS="${args[--parallel]}"
    fi

    # Set timeout (command line flag takes precedence over environment variable)
    if [[ -n "${args[--timeout]}" ]]; then
        if ! validate_positive_integer "${args[--timeout]}" "Timeout"; then
            exit 1
        fi
        RUNTIME_TIMEOUT="${args[--timeout]}"
    elif [[ -n "${GRPCTESTIFY_TIMEOUT}" ]]; then
        RUNTIME_TIMEOUT="${GRPCTESTIFY_TIMEOUT}"
    fi

    # Set retry configuration
    if [[ "${args[--no-retry]}" == "1" ]]; then
        RETRY_COUNT=0
    elif [[ -n "${args[--retry]}" ]]; then
        if ! validate_positive_integer "${args[--retry]}" "Retry count"; then
            exit 1
        fi
        RETRY_COUNT="${args[--retry]}"
    fi

    if [[ -n "${args[--retry-delay]}" ]]; then
        if ! validate_positive_integer "${args[--retry-delay]}" "Retry delay"; then
            exit 1
        fi
        RETRY_DELAY="${args[--retry-delay]}"
    fi

    # Always fail fast - stop on first error (like v0.0.13)
    FAIL_FAST=true

    # Set verbose mode (command line flag takes precedence over environment variable)
    if [[ "${args[--verbose]}" == "1" ]]; then
        VERBOSE=true
    elif [[ "${GRPCTESTIFY_VERBOSE}" == "true" ]]; then
        VERBOSE=true
    fi

        # Set no color
    if [[ "${args[--no-color]}" == "1" ]]; then
        NO_COLOR=true
    fi

    # Set junit logging
    if [[ -n "${args[--log-junit]}" ]]; then
        export JUNIT_OUTPUT_FILE="${args[--log-junit]}"
    fi
}

# Execute tests based on the provided path
execute_tests() {
    local test_path="$1"
    local test_files=()

    # Initialize global test result arrays for JUnit XML
    declare -g -a PASSED_TESTS=()
    declare -g -a FAILED_TESTS=()

    # Initialize report data
    init_report_data

    # Determine if it's a file or directory
    if [[ -f "$test_path" ]]; then
        # Single file
        if [[ "$test_path" == *.gctf ]]; then
            test_files=("$test_path")
        else
    log error "File must have .gctf extension: $test_path"
            return 1
        fi
    elif [[ -d "$test_path" ]]; then
        # Directory - find all .gctf files
        while IFS= read -r -d '' file; do
            test_files+=("$file")
        done < <(find "$test_path" -name "*.gctf" -type f -print0)

        if [[ ${#test_files[@]} -eq 0 ]]; then
    log error "No .gctf files found in directory: $test_path"
            return 1
        fi
    else
    log error "Invalid test path: $test_path"
        return 1
    fi

    # Run tests
    local test_exit_code=0
    if [[ "$PARALLEL_JOBS" -gt 1 ]]; then
        run_parallel_tests "${test_files[@]}"
        test_exit_code=$?
    else
        run_sequential_tests "${test_files[@]}"
        test_exit_code=$?
    fi

    return $test_exit_code
}

# Run tests sequentially
run_sequential_tests() {
    local test_files=("$@")
    local total_tests=${#test_files[@]}
    local passed=0
    local failed=0
    local start_time=$(date +%s)

    log info "Running $total_tests test(s) sequentially..."

    for test_file in "${test_files[@]}"; do
        local test_start_time=$(date +%s)
        local test_start_iso=$(date -Iseconds)

        if run_single_test "$test_file"; then
            passed=$((passed + 1))
            PASSED_TESTS+=("$test_file")
            local test_end_time=$(date +%s)
            local test_end_iso=$(date -Iseconds)
            local duration=$((test_end_time - test_start_time))
            add_test_result "$test_file" "PASS" "$duration" "" "$test_start_iso" "$test_end_iso"
        else
            failed=$((failed + 1))
            FAILED_TESTS+=("$test_file")
            local test_end_time=$(date +%s)
            local test_end_iso=$(date -Iseconds)
            local duration=$((test_end_time - test_start_time))
            add_test_result "$test_file" "FAIL" "$duration" "Test execution failed" "$test_start_iso" "$test_end_iso"

            # Always stop on first failure (v0.0.13 behavior)
            log error "Test failed, stopping execution"
            break
        fi
    done

    # Show summary (pass test files array for potential JUnit generation)
    declare -g -a ALL_TEST_FILES=("${test_files[@]}")
    show_summary $passed $failed $total_tests $start_time

    # Return exit code based on test results (like v0.0.13)
    if [[ $failed -gt 0 ]]; then
        return 1
    else
        return 0
    fi
}

# Run tests in parallel
run_parallel_tests() {
    local test_files=("$@")
    local total_tests=${#test_files[@]}
    local start_time=$(date +%s)

    log info "Running $total_tests test(s) in parallel (jobs: $PARALLEL_JOBS)..."

    # Use parallel execution
    run_parallel_execution "${test_files[@]}"
}

# Run a single test file
run_single_test() {
    local test_file="$1"
    local test_name=$(basename "$test_file" .gctf)

    # Show test header like v0.0.13 (only in progress=none mode)
    if [[ "${PROGRESS_MODE:-none}" == "none" ]]; then
        echo ""
        echo " â”€â”€â”€[ Test: $test_name ]â”€â”€â”€"
    fi

    log info "Running test: $test_name"

    # Parse test file
    local test_data
    test_data=$(parse_test_file "$test_file")

    local address endpoint requests responses options
    address=$(echo "$test_data" | jq -r '.address')
    endpoint=$(echo "$test_data" | jq -r '.endpoint')
    requests=$(echo "$test_data" | jq -r '.request')
    responses=$(echo "$test_data" | jq -r '.response')
    # ASSERT section removed - use ASSERTS instead
    options=$(extract_section "$test_file" "OPTIONS")

    if [[ -z "$address" || -z "$endpoint" ]]; then
        log error "Invalid test file: missing address or endpoint"
        return 1
    fi

    # Show configuration like v0.0.13 (only in progress=none mode)
    if [[ "${PROGRESS_MODE:-none}" == "none" ]]; then
        echo "â„¹ï¸ Configuration:"
        echo "â„¹ï¸   ADDRESS: $address"
        echo "â„¹ï¸   ENDPOINT: $endpoint"
        if [[ "$requests" != "null" && -n "$requests" ]]; then
            echo "â„¹ï¸   REQUEST: $(echo "$requests" | jq -c .)"
        fi
        if [[ "$responses" != "null" && -n "$responses" ]]; then
            echo "â„¹ï¸   RESPONSE: $(echo "$responses" | jq -c .)"
        fi
        echo "â„¹ï¸ Executing gRPC request to $address..."
    fi

    # Execute the test with timing
    local start_time=$(date +%s)
    if execute_test "$address" "$endpoint" "$requests" "$responses" "" "$options"; then
        local end_time=$(date +%s)
        local duration=$((end_time - start_time))

        if [[ "${PROGRESS_MODE:-none}" == "none" ]]; then
            log success "TEST PASSED: $test_name (${duration}s)"
            echo "â„¹ï¸ Completed: $test_name"
        elif [[ "${PROGRESS_MODE}" == "dots" ]]; then
            echo -n "."
        fi
        return 0
    else
        local end_time=$(date +%s)
        local duration=$((end_time - start_time))

        if [[ "${PROGRESS_MODE:-none}" == "none" ]]; then
            log error "TEST FAILED: $test_name (${duration}s)"
        elif [[ "${PROGRESS_MODE}" == "dots" ]]; then
            echo -n "F"
            echo ""
            echo " â”€â”€â”€[ Test: $test_name ]â”€â”€â”€"
            echo "â„¹ï¸ Configuration:"
            echo "â„¹ï¸   ADDRESS: $address"
            echo "â„¹ï¸   ENDPOINT: $endpoint"
            # Show detailed error info in dots mode too
        fi
        return 1
    fi
}

# Execute a single test
execute_test() {
    local address="$1"
    local endpoint="$2"
    local requests="$3"
    local responses="$4"
    local asserts="$5"
    local options="$6"

    # Parse options
    local timeout="${RUNTIME_TIMEOUT:-$DEFAULT_TIMEOUT}"
    local tolerance="0.01"
    local partial=false
    local redact_fields=()

    if [[ -n "$options" ]]; then
        timeout=$(echo "$options" | grep "timeout:" | cut -d: -f2 | tr -d ' ' || echo "$timeout")
        tolerance=$(echo "$options" | grep "tolerance:" | cut -d: -f2 | tr -d ' ' || echo "$tolerance")
        partial=$(echo "$options" | grep "partial:" | grep -q "true" && echo "true" || echo "false")
        redact_fields=($(echo "$options" | grep "redact:" | sed 's/redact: \[\(.*\)\]/\1/' | tr -d '"' | tr ',' ' '))
    fi

    # Execute gRPC call

    local response
    if ! response=$(execute_grpc_call "$address" "$endpoint" "$requests" "$timeout"); then

        return 1
    fi

    # Validate response

    if ! validate_response "$response" "$responses" "$asserts" "$tolerance" "$partial" "${redact_fields[@]}"; then

        return 1
    fi

    return 0
}

# Execute gRPC call using grpcurl
execute_grpc_call() {
    local address="$1"
    local endpoint="$2"
    local requests="$3"
    local timeout="$4"

    # Build grpcurl command
    local cmd="grpcurl -plaintext -d @ $address $endpoint"

    # Execute with timeout
    local grpc_stderr
    local grpc_status

    # Capture both stdout and stderr
    grpc_stderr=$(timeout "$timeout" bash -c "echo '$requests' | $cmd" 2>&1)
    grpc_status=$?

    if [[ $grpc_status -ne 0 ]]; then
        log error "gRPC call failed or timed out"
        echo "Error details: $grpc_stderr" >&2
        return 1
    fi

    echo "$grpc_stderr"
    return 0
}

# Validate response against expected response and assertions
validate_response() {
    local actual_response="$1"
    local expected_response="$2"
    local asserts="$3"
    local tolerance="$4"
    local partial="$5"
    shift 5
    local redact_fields=("$@")

    # Apply redaction if specified
    if [[ ${#redact_fields[@]} -gt 0 ]]; then
        for field in "${redact_fields[@]}"; do
            actual_response=$(echo "$actual_response" | jq "del(.$field)" 2>/dev/null || echo "$actual_response")
        done
    fi

    # Run assertions
    if [[ -n "$asserts" ]]; then
        if ! run_assertions "$actual_response" "$asserts"; then
            return 1
        fi
    fi

    # Compare with expected response if not partial
    if [[ "$partial" != "true" && -n "$expected_response" ]]; then

        if ! compare_responses "$actual_response" "$expected_response" "$tolerance"; then

            return 1
        fi

    fi

    return 0
}

# Run assertions using jq
run_assertions() {
    local response="$1"
    local asserts="$2"

    while IFS= read -r assertion; do
        if [[ -n "$assertion" && ! "$assertion" =~ ^[[:space:]]*# ]]; then
            if ! echo "$response" | jq -e "$assertion" >/dev/null 2>&1; then
    log error "Assertion failed: $assertion"
                return 1
            fi
        fi
    done <<< "$asserts"

    return 0
}

# Compare responses (overridden by runner.sh)

# Show test summary
show_summary() {
    local passed="$1"
    local failed="$2"
    local total="$3"
    local start_time="$4"
    local end_time=$(date +%s)
    local duration=$((end_time - start_time))
    local executed=$((passed + failed))
    local skipped=$((total - executed))
    local success_rate=0

    if [[ $total -gt 0 ]]; then
        success_rate=$((passed * 100 / total))
    fi

    echo
    log section "Test Execution Summary"
    echo "  ðŸ“Š Total tests planned: $total"
    echo "  ðŸƒ Tests executed: $executed"
    echo "  âœ… Passed: $passed"
    if [[ $failed -gt 0 ]]; then
        echo "  âŒ Failed: $failed"
    fi
    if [[ $skipped -gt 0 ]]; then
        echo "  â­ï¸  Skipped (due to early stop): $skipped"
    fi
    echo "  ðŸ“ˆ Success rate: $success_rate%"
    echo "  â±ï¸  Duration: ${duration}s"
    echo

    if [[ $failed -eq 0 ]]; then
        log success "ðŸŽ‰ All tests passed!"
        return 0
    else
        if [[ $skipped -gt 0 ]]; then
            log error "ðŸ’¥ $failed test(s) failed, $skipped test(s) not executed"
        else
            log error "ðŸ’¥ $failed test(s) failed"
        fi

        # Generate JUnit XML if requested (workaround for execution flow issue)
        if [[ -n "$JUNIT_OUTPUT_FILE" ]]; then
            echo "â„¹ï¸ Generating JUnit XML report: $JUNIT_OUTPUT_FILE" >&2
            local actual_passed="$passed"
            local actual_failed="$failed"
            generate_junit_xml "$JUNIT_OUTPUT_FILE" "$actual_passed" "$actual_failed" "$total" "$4" "${ALL_TEST_FILES[@]}"
        fi
        return 1
    fi
}

# Generate JUnit XML report
generate_junit_xml() {
    local output_file="$1"
    local passed="$2"
    local failed="$3"
    local total="$4"
    local start_time="$5"
    shift 5
    local all_test_files=("$@")

    local end_time=$(date +%s)
    local duration=$((end_time - start_time))
    local timestamp=$(date -Iseconds)
    local skipped=$((total - passed - failed))

    echo "â„¹ï¸ Creating JUnit XML: $output_file" >&2

    # Create output directory if it doesn't exist
    local output_dir=$(dirname "$output_file")
    mkdir -p "$output_dir"

    cat > "$output_file" << EOF
<?xml version="1.0" encoding="UTF-8"?>
<testsuites name="grpctestify"

           tests="$total"

           failures="$failed"

           errors="0"

           skipped="$skipped"

           time="$duration"
           timestamp="$timestamp">

  <properties>
    <property name="grpctestify.version" value="$APP_VERSION"/>
    <property name="hostname" value="$(hostname)"/>
    <property name="username" value="$(whoami)"/>
  </properties>

  <testsuite name="grpc-tests"

             tests="$total"

             failures="$failed"

             errors="0"

             skipped="$skipped"

             time="$duration">
EOF

    # Create associative arrays to track test status
    local -A test_status

    # Mark passed tests
    if [[ -n "${PASSED_TESTS[*]}" ]]; then
        for test_file in "${PASSED_TESTS[@]}"; do
            test_status["$test_file"]="passed"
        done
    fi

    # Mark failed tests
    if [[ -n "${FAILED_TESTS[*]}" ]]; then
        for test_file in "${FAILED_TESTS[@]}"; do
            test_status["$test_file"]="failed"
        done
    fi

    # Generate test cases for all tests
    for test_file in "${all_test_files[@]}"; do
        local test_name=$(basename "$test_file" .gctf)
        local status="${test_status[$test_file]:-skipped}"

        case "$status" in
            "passed")
                echo "    <testcase classname=\"grpctestify\" name=\"$test_name\" file=\"$test_file\" time=\"0\">" >> "$output_file"
                echo "    </testcase>" >> "$output_file"
                ;;
            "failed")
                echo "    <testcase classname=\"grpctestify\" name=\"$test_name\" file=\"$test_file\" time=\"0\">" >> "$output_file"
                echo "      <failure message=\"Test failed\" type=\"AssertionError\">" >> "$output_file"
                echo "        Test execution failed" >> "$output_file"
                echo "      </failure>" >> "$output_file"
                echo "    </testcase>" >> "$output_file"
                ;;
            "skipped")
                echo "    <testcase classname=\"grpctestify\" name=\"$test_name\" file=\"$test_file\" time=\"0\">" >> "$output_file"
                echo "      <skipped message=\"Test skipped due to early termination (fail-fast mode)\" type=\"Skipped\">" >> "$output_file"
                echo "        Test was not executed because a previous test failed and fail-fast mode is enabled" >> "$output_file"
                echo "      </skipped>" >> "$output_file"
                echo "    </testcase>" >> "$output_file"
                ;;
        esac
    done

    cat >> "$output_file" << EOF

  </testsuite>
</testsuites>
EOF

    echo "âœ… JUnit XML generated: $output_file" >&2
}

# src/lib/commands/update.sh
#!/bin/bash

# update.sh - Update command implementation
# Handles updating grpctestify to the latest version

# All modules are automatically loaded by bashly

# Update command implementation
update_command() {
    local force_update
    force_update=$(get_config "force_update" "false")

    log section "$APP_NAME $version - Update"

    # Initialize application
    initialize_app

    log info "Checking for updates..."

    # Check for updates
    if check_for_updates; then
        local latest_version=$(get_latest_version)
        log info "New version available: $latest_version"

        if [[ "$force_update" == "true" ]] || confirm_update; then
            perform_update
        else
            log info "Update cancelled by user"
        fi
    else
        log info "Already up to date (current: $version)"
    fi
}

# Check for updates
check_for_updates() {
    local latest_version
    latest_version=$(get_latest_version)

    if [[ $? -ne 0 ]]; then
        log error "Failed to check for updates"
        return 1
    fi

    # Compare versions
    if [[ "$latest_version" != "$version" ]]; then
        return 0  # Update available
    else
        return 1  # No update available
    fi
}

# Get latest version from GitHub API
get_latest_version() {
    local api_url="https://api.github.com/repos/gripmock/grpctestify/releases/latest"
    local latest_version

    if ! command -v curl >/dev/null 2>&1; then
        log error "curl is required for update checking"
        return 1
    fi

    if ! command -v jq >/dev/null 2>&1; then
        log error "jq is required for update checking"
        return 1
    fi

    # Query GitHub API with timeout
    local response
    if ! response=$(curl -s --connect-timeout 10 --max-time 30 "$api_url" 2>&1); then
        handle_network_error "$api_url" $?
        return 1
    fi

    # Extract version from response
    if ! latest_version=$(echo "$response" | jq -r '.tag_name // empty' 2>/dev/null); then
        log error "Failed to parse GitHub API response"
        return 1
    fi

    if [[ -z "$latest_version" || "$latest_version" == "null" ]]; then
        log error "No version information found in API response"
        return 1
    fi

    echo "$latest_version"
    return 0
}

# Download latest version
download_latest() {
    local download_url="$1"
    local output_file="$2"

    log info "Downloading latest version from: $download_url"

    if ! command -v curl >/dev/null 2>&1; then
        log error "curl is required for downloading updates"
        return 1
    fi

    # Download with progress
    if ! curl -L --connect-timeout 10 --max-time 300 -o "$output_file" "$download_url" 2>&1; then
        handle_network_error "$download_url" $?
        return 1
    fi

    # Verify file was downloaded
    if [[ ! -f "$output_file" || ! -s "$output_file" ]]; then
        log error "Downloaded file is empty or missing"
        return 1
    fi

    log success "Download completed"
    return 0
}

# Verify checksum
verify_checksum() {
    local file="$1"
    local expected_checksum="$2"

    if [[ -z "$expected_checksum" ]]; then
        log warning "No checksum provided, skipping verification"
        return 0
    fi

    log info "Verifying checksum..."

    if ! command -v sha256sum >/dev/null 2>&1 && ! command -v shasum >/dev/null 2>&1; then
        log warning "No SHA-256 tool available, skipping checksum verification"
        return 0
    fi

    # Calculate checksum
    local actual_checksum
    if command -v sha256sum >/dev/null 2>&1; then
        actual_checksum=$(sha256sum "$file" | cut -d' ' -f1)
    else
        actual_checksum=$(shasum -a 256 "$file" | cut -d' ' -f1)
    fi

    if [[ "$actual_checksum" == "$expected_checksum" ]]; then
        log success "Checksum verification passed"
        return 0
    else
        log error "Checksum verification failed"
        log error "Expected: $expected_checksum"
        log error "Actual: $actual_checksum"
        return 1
    fi
}

# Install update
install_update() {
    local update_file="$1"
    local target_file="$2"

    log info "Installing update..."

    # Create backup
    local backup_file="${target_file}.backup.$(date +%Y%m%d_%H%M%S)"
    if ! cp "$target_file" "$backup_file"; then
        log error "Failed to create backup"
        return 1
    fi

    log info "Backup created: $backup_file"

    # Replace with new version
    if ! cp "$update_file" "$target_file"; then
        log error "Failed to install update"
        # Restore backup
        cp "$backup_file" "$target_file"
        return 1
    fi

    # Set executable permissions
    if ! chmod +x "$target_file"; then
        log error "Failed to set executable permissions"
        return 1
    fi

    log success "Update installed successfully"
    log info "Backup available at: $backup_file"
    return 0
}

# Confirm update with user
confirm_update() {
    local latest_version="$1"

    echo ""
    log info "Update available: $version -> $latest_version"
    echo -n "Do you want to update? [y/N]: "
    read -r response

    case "$response" in
        [yY]|[yY][eE][sS])
            return 0
            ;;
        *)
            return 1
            ;;
    esac
}

# Perform the complete update process
perform_update() {
    local latest_version=$(get_latest_version)
    local download_url="https://github.com/gripmock/grpctestify/releases/download/${latest_version}/grpctestify.sh"
    local temp_file=$(mktemp)
    local current_script="$0"

    # Download latest version
    if ! download_latest "$download_url" "$temp_file"; then
        rm -f "$temp_file"
        return 1
    fi

    # Verify checksum using checksums.txt file (like in original version)
    local checksum_url="https://github.com/gripmock/grpctestify/releases/download/${latest_version}/checksums.txt"
    local expected_checksum
    if expected_checksum=$(curl -s --connect-timeout 10 --max-time 30 "$checksum_url" 2>/dev/null | grep "grpctestify.sh" | awk '{print $1}'); then
        if [[ -n "$expected_checksum" ]]; then
            if ! verify_checksum "$temp_file" "$expected_checksum"; then
                rm -f "$temp_file"
                return 1
            fi
        else
            log warning "Could not find grpctestify.sh checksum in checksums.txt"
        fi
    else
        log warning "Could not fetch checksums.txt, proceeding without verification"
    fi

    # Install update
    if ! install_update "$temp_file" "$current_script"; then
        rm -f "$temp_file"
        return 1
    fi

    # Clean up
    rm -f "$temp_file"

    log success "Update completed successfully!"
    log info "New version: $latest_version"
    return 0
}

# Show update help
show_update_help() {
    echo "Update functionality:"
    echo ""
    echo "  $APP_NAME --update"
    echo ""
    echo "This command will:"
    echo "  1. Check for newer versions"
    echo "  2. Download the latest version"
    echo "  3. Verify checksum"
    echo "  4. Replace current script"
    echo ""
    echo "Current version: $version"
}

# src/lib/core/app.sh
#!/bin/bash

# app.sh - Application initialization
# This file contains the initialize_app function used by the bashly-generated script

# Initialize application
initialize_app() {
    # Load configuration file first (highest priority)
    if declare -f load_configuration >/dev/null 2>&1; then
        load_configuration
    fi

    setup_colors
    # Dependencies are automatically checked by bashly
    # Don't show initialization message to match original behavior
}

# All other functions have been moved to their respective command files
# - Test execution functions are in src/lib/commands/test.sh
# - Main command logic is handled by bashly-generated root_command()

# src/lib/core/assertions.sh
#!/bin/bash

# assertions.sh - Response comparison logic
# Simple, clear assertion functions

extract_asserts() {
    local test_file="$1"
    local section_name="$2"

    extract_section_awk "$test_file" "$section_name"
}

evaluate_asserts() {
    local response="$1"
    local asserts_file="$2"
    local response_index="$3"

    local line_number=0
    while IFS= read -r line; do
        line_number=$((line_number + 1))

        # Skip empty lines and comments
        if [[ -z "$line" || "$line" =~ ^[[:space:]]*# ]]; then
            continue
        fi

        # Evaluate jq filter
        if ! echo "$response" | jq -e "$line" >/dev/null 2>&1; then
            echo "ASSERTS block failed at line $line_number: $line"
            echo "Response: $response"
            return 1
        fi
    done < "$asserts_file"

    return 0
}

# src/lib/core/colors.sh
#!/bin/bash

# colors.sh - Color and logging utilities
# This module provides color output and logging functionality

# Color configuration
setup_colors() {
    if [[ "${no_color:-false}" == "true" ]]; then
        RED=""
        GREEN=""
        YELLOW=""
        BLUE=""
        NC=""
        CHECK="OK"
        CROSS="ERR"
        INFO="INF"
        ALERT="WARN"
    else
        RED="\033[0;31m"
        GREEN="\033[0;32m"
        YELLOW="\033[0;33m"
        BLUE="\033[0;34m"
        NC="\033[0m"
        CHECK="âœ…"
        CROSS="âŒ"
        INFO="â„¹ï¸"
        ALERT="âš ï¸"
    fi
}

# Logging functions
log() {
    local level="$1"
    shift
    local message="$*"

    case "$level" in
        "error")
            printf "${RED}${CROSS} %s${NC}\n" "$message" >&2
            ;;
        "success")
            printf "${GREEN}${CHECK} %s${NC}\n" "$message"
            ;;
        "info")
            printf "${BLUE}${INFO} %s${NC}\n" "$message"
            ;;
        "section")
            printf "\n${YELLOW}â”€â”€â”€[ %s ]â”€â”€â”€${NC}\n" "$message"
            ;;
        "debug")
            if [[ "${verbose:-false}" == "true" ]]; then
                printf "${YELLOW}ðŸ” %s${NC}\n" "$message" >&2
            fi
            ;;
        "warning")
            printf "${YELLOW}${ALERT} %s${NC}\n" "$message" >&2
            ;;
    esac
}

# Dependencies are now handled by bashly configuration
# See src/bashly.yml for dependency definitions

# Initialize colors on module load
setup_colors

# src/lib/core/config.sh
#!/bin/bash

# config.sh - Centralized configuration
# Single source of truth for all configuration values

# Application metadata
readonly APP_NAME="grpctestify"
readonly APP_VERSION="v1.0.0"
readonly CONFIG_VERSION="1.0.0"

# Default values
readonly DEFAULT_TIMEOUT=30
readonly DEFAULT_ADDRESS="localhost:4770"
# shellcheck disable=SC2034  # Used in future versions
readonly DEFAULT_CACHE_TTL=3600
# shellcheck disable=SC2034  # Used in future versions
readonly DEFAULT_RETRY_ATTEMPTS=3
readonly DEFAULT_RETRY_DELAY=1
readonly DEFAULT_PARALLEL_JOBS=1
# shellcheck disable=SC2034  # Used in future versions
readonly DEFAULT_PORT_START=50051

# Author information
# shellcheck disable=SC2034  # Used in future versions
readonly DEFAULT_AUTHOR="Your Name"
# shellcheck disable=SC2034  # Used in future versions
readonly DEFAULT_EMAIL="your.email@domain.com"

# File paths and directories (SECURITY: safe defaults)
readonly DEFAULT_PLUGIN_DIR="$HOME/.grpctestify/plugins"
readonly DEFAULT_CACHE_DIR="${XDG_CACHE_HOME:-$HOME/.cache}/grpctestify"
readonly DEFAULT_CONFIG_FILE="$HOME/.grpctestify/config"

# Performance settings
readonly PARSE_CACHE_ENABLED=true
readonly DEPENDENCY_CACHE_TTL=3600
readonly MAX_PARALLEL_JOBS=16
readonly STARTUP_TIMEOUT=10

# Security settings
readonly ALLOW_INSECURE_CONNECTIONS=false
readonly VALIDATE_SSL_CERTIFICATES=true
readonly MAX_REQUEST_SIZE=1048576  # 1MB
readonly MAX_RESPONSE_SIZE=10485760  # 10MB

# Output formatting
readonly PROGRESS_LINE_LENGTH=80
readonly LOG_TIMESTAMP_FORMAT="%Y-%m-%d %H:%M:%S"
readonly COLOR_SUCCESS='\033[0;32m'
readonly COLOR_ERROR='\033[0;31m'
readonly COLOR_WARNING='\033[1;33m'
readonly COLOR_INFO='\033[0;34m'
readonly COLOR_RESET='\033[0m'

# Plugin configuration defaults
readonly PLUGIN_API_VERSION="1.0.0"
readonly PLUGIN_TIMEOUT=30
readonly PLUGIN_STRICT_MODE=false
readonly PLUGIN_DEBUG=false
readonly PLUGIN_MAX_RETRIES=3

# Validation rules
readonly VALID_SECTIONS="ADDRESS|ENDPOINT|REQUEST|RESPONSE|ERROR|HEADERS|REQUEST_HEADERS|OPTIONS|ASSERTS"

# Error codes (unified)
readonly ERROR_GENERAL=1
readonly ERROR_INVALID_ARGS=2
readonly ERROR_FILE_NOT_FOUND=3
readonly ERROR_DEPENDENCY_MISSING=4
readonly ERROR_NETWORK=5
readonly ERROR_PERMISSION=6
readonly ERROR_VALIDATION=7
readonly ERROR_TIMEOUT=8
readonly ERROR_RATE_LIMIT=9
readonly ERROR_QUOTA_EXCEEDED=10
readonly ERROR_SERVICE_UNAVAILABLE=11
readonly ERROR_CONFIGURATION=12

# Environment variable names
readonly ENV_ADDRESS="GRPCTESTIFY_ADDRESS"
readonly ENV_TIMEOUT="GRPCTESTIFY_TIMEOUT"
readonly ENV_PARALLEL="GRPCTESTIFY_PARALLEL"
readonly ENV_VERBOSE="GRPCTESTIFY_VERBOSE"
readonly ENV_NO_COLOR="GRPCTESTIFY_NO_COLOR"
readonly ENV_PLUGIN_PATH="GRPCTESTIFY_PLUGIN_PATH"
readonly ENV_CACHE_DIR="GRPCTESTIFY_CACHE_DIR"

# Feature flags
readonly FEATURE_CACHING_ENABLED=true
readonly FEATURE_PLUGINS_ENABLED=true
readonly FEATURE_PARALLEL_ENABLED=true
readonly FEATURE_PROGRESS_ENABLED=true
readonly FEATURE_RECOVERY_ENABLED=true

# Secure path validation (SECURITY: prevent path traversal)
validate_plugin_path() {
    local plugin_path="$1"

    # Ensure path is absolute and within safe directories
    case "$plugin_path" in
        "$HOME/.grpctestify/plugins"*)

            # Allow only in user's grpctestify directory
            if [[ "$plugin_path" != *".."* && "$plugin_path" == *.sh ]]; then
                return 0
            fi
            ;;
        *)
            log error "Plugin path not allowed: $plugin_path"
            return 1
            ;;
    esac

    log error "Invalid plugin path: $plugin_path"
    return 1
}

# Validate configuration value
validate_config() {
    local key="$1"
    local value="$2"

    case "$key" in
        "timeout"|"cache_ttl"|"retry_delay"|"parallel_jobs")
            if [[ ! "$value" =~ ^[0-9]+$ ]] || [[ "$value" -lt 1 ]]; then
                return 1
            fi
            ;;
        "strict_mode"|"debug"|"caching_enabled")
            if [[ ! "$value" =~ ^(true|false)$ ]]; then
                return 1
            fi
            ;;
        "address")
            if [[ ! "$value" =~ ^[a-zA-Z0-9.-]+:[0-9]+$ ]]; then
                return 1
            fi
            ;;
        "email")
            if [[ ! "$value" =~ ^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$ ]]; then
                return 1
            fi
            ;;
    esac

    return 0
}

# Initialize configuration
init_config() {
    # Set global variables from configuration
    GRPCTESTIFY_TIMEOUT=$(get_config "timeout" "$DEFAULT_TIMEOUT" "$ENV_TIMEOUT")
    GRPCTESTIFY_ADDRESS=$(get_config "address" "$DEFAULT_ADDRESS" "$ENV_ADDRESS")
    GRPCTESTIFY_PARALLEL=$(get_config "parallel" "$DEFAULT_PARALLEL_JOBS" "$ENV_PARALLEL")
    GRPCTESTIFY_CACHE_DIR=$(get_config "cache_dir" "$DEFAULT_CACHE_DIR" "$ENV_CACHE_DIR")

    # Validate critical configuration
    if ! validate_config "timeout" "$GRPCTESTIFY_TIMEOUT"; then
        echo "Error: Invalid timeout value: $GRPCTESTIFY_TIMEOUT" >&2
        return 1
    fi

    if ! validate_config "address" "$GRPCTESTIFY_ADDRESS"; then
        echo "Error: Invalid address format: $GRPCTESTIFY_ADDRESS" >&2
        return 1
    fi

    return 0
}

# Export configuration functions

export -f validate_config
export -f init_config

# src/lib/core/error_recovery.sh
#!/bin/bash

# error_recovery.sh - Error recovery and retry mechanisms

# Default retry configuration
DEFAULT_MAX_RETRIES=3
# DEFAULT_RETRY_DELAY is defined in config.sh
DEFAULT_BACKOFF_MULTIPLIER=2
DEFAULT_MAX_RETRY_DELAY=30

# Retry a function with exponential backoff (SECURITY: no eval)
retry_with_backoff() {
    local func_name="$1"
    shift
    local max_retries="${1:-$DEFAULT_MAX_RETRIES}"
    shift
    local initial_delay="${1:-$DEFAULT_RETRY_DELAY}"
    shift
    local backoff_multiplier="${1:-$DEFAULT_BACKOFF_MULTIPLIER}"
    shift
    local max_delay="${1:-$DEFAULT_MAX_RETRY_DELAY}"
    shift
    # Remaining arguments passed to function

    local attempt=1
    local delay="$initial_delay"

    while [[ $attempt -le $max_retries ]]; do
        log debug "Attempt $attempt/$max_retries: calling $func_name"

        if "$func_name" "$@"; then
            if [[ $attempt -gt 1 ]]; then
                log success "Function succeeded on attempt $attempt"
            fi
            return 0
        fi

        local exit_code=$?

        if [[ $attempt -eq $max_retries ]]; then
            log error "Command failed after $max_retries attempts"
            return $exit_code
        fi

        log warning "Command failed (attempt $attempt/$max_retries), retrying in ${delay}s..."
        sleep "$delay"

        # Calculate next delay with exponential backoff
        delay=$((delay * backoff_multiplier))
        if [[ $delay -gt $max_delay ]]; then
            delay="$max_delay"
        fi

        ((attempt++))
    done
}

# Retry gRPC call with network error handling
retry_grpc_call() {
    local address="$1"
    local endpoint="$2"
    local request="$3"
    local headers="$4"
    local max_retries="${5:-$DEFAULT_MAX_RETRIES}"

    local retry_count=0
    local last_error=""

    while [[ $retry_count -lt $max_retries ]]; do
        log debug "gRPC call attempt $((retry_count + 1))/$max_retries to $address$endpoint"

        # Attempt the gRPC call
        local grpc_output
        grpc_output=$(run_grpc_call "$address" "$endpoint" "$request" "$headers" "")
        local grpc_status=$?

        if [[ $grpc_status -eq 0 ]]; then
            if [[ $retry_count -gt 0 ]]; then
                log success "gRPC call succeeded on attempt $((retry_count + 1))"
            fi
            echo "$grpc_output"
            return 0
        fi

        last_error="$grpc_output"

        # Check if this is a retryable error
        if ! is_retryable_error "$grpc_output" "$grpc_status"; then
            log error "Non-retryable error: $grpc_output"
            echo "$grpc_output"
            return $grpc_status
        fi

        ((retry_count++))

        if [[ $retry_count -lt $max_retries ]]; then
            local delay
            delay=$((DEFAULT_RETRY_DELAY * (2 ** (retry_count - 1))))
            if [[ $delay -gt $DEFAULT_MAX_RETRY_DELAY ]]; then
                delay="$DEFAULT_MAX_RETRY_DELAY"
            fi

            log warning "gRPC call failed (attempt $retry_count/$max_retries), retrying in ${delay}s..."
            log debug "Error details: $grpc_output"
            sleep "$delay"
        fi
    done

    log error "gRPC call failed after $max_retries attempts"
    echo "$last_error"
    return 1
}

# Check if an error is retryable
is_retryable_error() {
    local error_output="$1"
    local exit_code="$2"

    # Network-related errors that are typically retryable
    local retryable_patterns=(
        "connection refused"
        "connection reset"
        "timeout"
        "network is unreachable"
        "temporary failure"
        "service unavailable"
        "internal server error"
        "bad gateway"
        "gateway timeout"
    )

    # Convert to lowercase for case-insensitive matching
    local lower_error
    lower_error=$(echo "$error_output" | tr '[:upper:]' '[:lower:]')

    for pattern in "${retryable_patterns[@]}"; do
        if [[ "$lower_error" == *"$pattern"* ]]; then
            return 0
        fi
    done

    # Check for specific gRPC status codes that are retryable
    case "$exit_code" in
        14|8|13|4)  # UNAVAILABLE, RESOURCE_EXHAUSTED, INTERNAL, DEADLINE_EXCEEDED
            return 0
            ;;
        *)
            return 1
            ;;
    esac
}

# Wait for service to become available
wait_for_service() {
    local address="$1"
    local timeout_seconds="${2:-30}"
    local check_interval="${3:-2}"

    log info "Waiting for service at $address (timeout: ${timeout_seconds}s)"

    local start_time
    start_time=$(date +%s)
    local end_time=$((start_time + timeout_seconds))

    while [[ $(date +%s) -lt $end_time ]]; do
        if check_service_health "$address"; then
            log success "Service is available at $address"
            return 0
        fi

        log debug "Service not ready, waiting ${check_interval}s..."
        sleep "$check_interval"
    done

    log error "Service at $address did not become available within ${timeout_seconds}s"
    return 1
}

# Check if a service is healthy
check_service_health() {
    local address="$1"

    # Try to connect to the gRPC service
    if timeout 5 grpcurl -plaintext "$address" list >/dev/null 2>&1; then
        return 0
    fi

    # Fallback: try to connect to the port
    local host
    local port
    host=$(echo "$address" | cut -d: -f1)
    port=$(echo "$address" | cut -d: -f2)

    if timeout 5 bash -c "echo > /dev/tcp/$host/$port" 2>/dev/null; then
        return 0
    fi

    return 1
}

# Handle network failures gracefully
handle_network_failure() {
    local error_message="$1"
    local test_file="$2"
    local retry_count="${3:-0}"

    log error "Network failure in test: $test_file"
    log error "Error: $error_message"

    if [[ $retry_count -gt 0 ]]; then
        log info "This was retry attempt $retry_count"
    fi

    # Check if we should suggest starting a test server
    if [[ "$error_message" == *"connection refused"* ]]; then
        log info "ðŸ’¡ Tip: Make sure your gRPC server is running"
        log info "   You can start a test server with: make up"
    fi

    # Check if we should suggest checking the address
    if [[ "$error_message" == *"network is unreachable"* ]]; then
        log info "ðŸ’¡ Tip: Check if the server address is correct"
        log info "   Current address: $(get_config 'default_address' 'localhost:4770')"
    fi
}

# Recover from test failures
recover_from_test_failure() {
    local test_file="$1"
    local error_message="$2"
    local max_recovery_attempts="${3:-2}"

    log warning "Attempting to recover from test failure: $test_file"

    local recovery_attempt=1

    while [[ $recovery_attempt -le $max_recovery_attempts ]]; do
        log info "Recovery attempt $recovery_attempt/$max_recovery_attempts"

        # Wait a bit before retrying
        sleep $((recovery_attempt * 2))

        # Try to run the test again
        if run_single_test "$test_file"; then
            log success "Test recovered successfully on attempt $recovery_attempt"
            return 0
        fi

        ((recovery_attempt++))
    done

    log error "Failed to recover test after $max_recovery_attempts attempts"
    return 1
}

# Get retry configuration from environment or config
get_retry_config() {
    local config_key="$1"
    local default_value="$2"

    case "$config_key" in
        "max_retries")
            echo "${MAX_RETRIES:-${default_value:-$DEFAULT_MAX_RETRIES}}"
            ;;
        "retry_delay")
            echo "${RETRY_DELAY:-${default_value:-$DEFAULT_RETRY_DELAY}}"
            ;;
        "backoff_multiplier")
            echo "${BACKOFF_MULTIPLIER:-${default_value:-$DEFAULT_BACKOFF_MULTIPLIER}}"
            ;;
        "max_retry_delay")
            echo "${MAX_RETRY_DELAY:-${default_value:-$DEFAULT_MAX_RETRY_DELAY}}"
            ;;
        *)
            echo "$default_value"
            ;;
    esac
}

# Export functions for use in other modules
export -f retry_with_backoff
export -f retry_grpc_call
export -f is_retryable_error
export -f wait_for_service
export -f check_service_health
export -f handle_network_failure
export -f recover_from_test_failure
export -f get_retry_config

# src/lib/core/error_system.sh
#!/bin/bash

# error_system.sh - Unified error handling system
# Combines basic error handling with advanced recovery capabilities

# Unified error codes are loaded from config.sh automatically by bashly

# Error context stack for advanced error tracking
declare -a ERROR_CONTEXT_STACK=()
declare -a ERROR_RECOVERY_STRATEGIES=()
declare -A ERROR_AGGREGATOR=()
declare -A CIRCUIT_BREAKER_STATE=()
declare -A CIRCUIT_BREAKER_FAILURES=()

# Basic error handling function
handle_error() {
    local exit_code="$1"
    local error_message="$2"
    local context="${3:-}"

    case "$exit_code" in
        $ERROR_GENERAL)
            log error "General error: $error_message"
            ;;
        $ERROR_INVALID_ARGS)
            log error "Invalid arguments: $error_message"
            ;;
        $ERROR_FILE_NOT_FOUND)
            log error "File not found: $error_message"
            ;;
        $ERROR_DEPENDENCY_MISSING)
            log error "Missing dependency: $error_message"
            ;;
        $ERROR_NETWORK)
            log error "Network error: $error_message"
            ;;
        $ERROR_PERMISSION)
            log error "Permission denied: $error_message"
            ;;
        $ERROR_VALIDATION)
            log error "Validation error: $error_message"
            ;;
        $ERROR_TIMEOUT)
            log error "Timeout: $error_message"
            ;;
        $ERROR_RATE_LIMIT)
            log error "Rate limit exceeded: $error_message"
            ;;
        $ERROR_QUOTA_EXCEEDED)
            log error "Quota exceeded: $error_message"
            ;;
        $ERROR_SERVICE_UNAVAILABLE)
            log error "Service unavailable: $error_message"
            ;;
        $ERROR_CONFIGURATION)
            log error "Configuration error: $error_message"
            ;;
        *)
            log error "Unknown error ($exit_code): $error_message"
            ;;
    esac

    if [[ -n "$context" ]]; then
        log debug "Context: $context"
    fi
}

# Advanced error context management
push_error_context() {
    local context="$1"
    ERROR_CONTEXT_STACK+=("$context")
    log debug "Error context pushed: $context"
}

pop_error_context() {
    if [[ ${#ERROR_CONTEXT_STACK[@]} -gt 0 ]]; then
        unset 'ERROR_CONTEXT_STACK[-1]'
        log debug "Error context popped"
    fi
}

get_error_context() {
    local context=""
    for ctx in "${ERROR_CONTEXT_STACK[@]}"; do
        if [[ -n "$context" ]]; then
            context="$context -> $ctx"
        else
            context="$ctx"
        fi
    done
    echo "$context"
}

# Error recovery strategies
register_recovery_strategy() {
    local error_pattern="$1"
    local recovery_function="$2"

    ERROR_RECOVERY_STRATEGIES+=("$error_pattern:$recovery_function")
    log debug "Registered recovery strategy for: $error_pattern"
}

# Enhanced error handler with context and recovery
handle_error_enhanced() {
    local exit_code="$1"
    local error_message="$2"
    local recovery_hint="${3:-}"

    local context="$(get_error_context)"
    local full_message="$error_message"

    if [[ -n "$context" ]]; then
        full_message="[$context] $error_message"
    fi

    # Use basic error handling for logging
    handle_error "$exit_code" "$full_message"

    # Attempt recovery if hint provided
    if [[ -n "$recovery_hint" ]]; then
        log info "Attempting recovery: $recovery_hint"
        attempt_error_recovery "$error_message" "$recovery_hint"
        return $?
    fi

    # Try registered recovery strategies
    for strategy in "${ERROR_RECOVERY_STRATEGIES[@]}"; do
        local pattern="${strategy%%:*}"
        local recovery_func="${strategy##*:}"

        if [[ "$error_message" =~ $pattern ]]; then
            log info "Attempting recovery with strategy: $recovery_func"
            if "$recovery_func" "$error_message" "$exit_code"; then
                log success "Recovery successful"
                return 0
            fi
        fi
    done

    return "$exit_code"
}

# Error recovery implementation
attempt_error_recovery() {
    local error_message="$1"
    local recovery_hint="$2"

    case "$recovery_hint" in
        "retry_with_backoff")
            log info "Retrying with exponential backoff..."
            return 0
            ;;
        "check_service")
            log info "Checking service availability..."
            if check_service_health "${GRPCTESTIFY_ADDRESS:-localhost:4770}"; then
                log success "Service is available"
                return 0
            fi
            ;;
        "fallback_address")
            log info "Trying fallback address..."
            return 1
            ;;
        "skip_test")
            log warning "Skipping test due to error"
            return 0
            ;;
        *)
            log debug "Unknown recovery hint: $recovery_hint"
            return 1
            ;;
    esac

    return 1
}

# Graceful degradation handler
handle_graceful_degradation() {
    local feature="$1"
    local error_message="$2"
    local fallback="${3:-}"

    log warning "Feature '$feature' degraded: $error_message"

    if [[ -n "$fallback" ]]; then
        log info "Using fallback: $fallback"
        return 0
    fi

    return 1
}

# Error aggregation for batch operations
aggregate_error() {
    local test_name="$1"
    local error_message="$2"

    ERROR_AGGREGATOR["$test_name"]="$error_message"
}

report_aggregated_errors() {
    local error_count=${#ERROR_AGGREGATOR[@]}

    if [[ $error_count -eq 0 ]]; then
        log success "No errors to report"
        return 0
    fi

    log error "Aggregated errors from $error_count tests:"

    for test_name in "${!ERROR_AGGREGATOR[@]}"; do
        log error "  $test_name: ${ERROR_AGGREGATOR[$test_name]}"
    done

    # Clear aggregator
    ERROR_AGGREGATOR=()

    return 1
}

# Circuit breaker pattern
check_circuit_breaker() {
    local service="$1"
    local max_failures="${2:-5}"
    local timeout="${3:-300}"

    local current_time=$(date +%s)
    local failure_count="${CIRCUIT_BREAKER_FAILURES[$service]:-0}"
    local last_failure="${CIRCUIT_BREAKER_STATE[$service]:-0}"

    # Reset if timeout passed
    if [[ $((current_time - last_failure)) -gt $timeout ]]; then
        CIRCUIT_BREAKER_FAILURES[$service]=0
        CIRCUIT_BREAKER_STATE[$service]=0
        log debug "Circuit breaker reset for $service"
        return 0
    fi

    # Check if circuit is open
    if [[ $failure_count -ge $max_failures ]]; then
        log warning "Circuit breaker open for $service ($failure_count failures)"
        return 1
    fi

    return 0
}

record_circuit_breaker_failure() {
    local service="$1"

    local current_count="${CIRCUIT_BREAKER_FAILURES[$service]:-0}"
    CIRCUIT_BREAKER_FAILURES[$service]=$((current_count + 1))
    CIRCUIT_BREAKER_STATE[$service]=$(date +%s)

    log debug "Circuit breaker failure recorded for $service (count: ${CIRCUIT_BREAKER_FAILURES[$service]})"
}

# File operation validation
validate_file_operation() {
    local file_path="$1"
    local operation="${2:-read}"

    case "$operation" in
        "read")
            if [[ ! -r "$file_path" ]]; then
                handle_error $ERROR_FILE_NOT_FOUND "Cannot read file: $file_path"
                return 1
            fi
            ;;
        "write")
            local dir_path=$(dirname "$file_path")
            if [[ ! -w "$dir_path" ]]; then
                handle_error $ERROR_PERMISSION "Cannot write to directory: $dir_path"
                return 1
            fi
            ;;
        "execute")
            if [[ ! -x "$file_path" ]]; then
                handle_error $ERROR_PERMISSION "Cannot execute file: $file_path"
                return 1
            fi
            ;;
    esac

    return 0
}

# Network error handling
handle_network_error() {
    local url="$1"
    local error_code="$2"

    case "$error_code" in
        6|7)
            handle_error $ERROR_NETWORK "Could not resolve host for: $url"
            ;;
        28)
            handle_error $ERROR_NETWORK "Connection timeout for: $url"
            ;;
        35|60)
            handle_error $ERROR_NETWORK "SSL/TLS error for: $url"
            ;;
        *)
            handle_error $ERROR_NETWORK "Network error ($error_code) for: $url"
            ;;
    esac
}

# Enhanced network error handling with recovery
handle_network_error_enhanced() {
    local error_output="$1"
    local test_file="$2"
    local retry_count="${3:-0}"

    push_error_context "network_error:$(basename "$test_file")"

    # Analyze error type
    local error_type="unknown"
    local error_lower=$(echo "$error_output" | tr '[:upper:]' '[:lower:]')
    if [[ "$error_lower" =~ "connection refused" ]]; then
        error_type="connection_refused"
    elif [[ "$error_lower" =~ "timeout" ]]; then
        error_type="timeout"
    elif [[ "$error_lower" =~ "not found" ]]; then
        error_type="not_found"
    elif [[ "$error_lower" =~ "permission denied" ]]; then
        error_type="permission_denied"
    fi

    log debug "Network error type detected: $error_type"

    # Apply appropriate recovery strategy
    case "$error_type" in
        "connection_refused")
            handle_error_enhanced $ERROR_SERVICE_UNAVAILABLE "$error_output" "check_service"
            ;;
        "timeout")
            handle_error_enhanced $ERROR_TIMEOUT "$error_output" "retry_with_backoff"
            ;;
        "not_found")
            handle_error_enhanced $ERROR_FILE_NOT_FOUND "$error_output" "skip_test"
            ;;
        *)
            handle_error_enhanced $ERROR_NETWORK "$error_output"
            ;;
    esac

    pop_error_context
    return $?
}

# Safe execution with error handling
safe_execute() {
    local error_context="${1:-}"
    shift

    if ! "$@"; then
        local exit_code=$?
        handle_error $exit_code "Command failed: $*" "$error_context"
        return $exit_code
    fi

    return 0
}

# Service health check
check_service_health() {
    local address="$1"

    if command -v grpcurl >/dev/null 2>&1; then
        if timeout 5 grpcurl -plaintext "$address" list >/dev/null 2>&1; then
            return 0
        fi
    fi

    return 1
}

# Export all functions
export -f handle_error
export -f handle_error_enhanced
export -f push_error_context
export -f pop_error_context
export -f get_error_context
export -f register_recovery_strategy
export -f attempt_error_recovery
export -f handle_graceful_degradation
export -f aggregate_error
export -f report_aggregated_errors
export -f check_circuit_breaker
export -f record_circuit_breaker_failure
export -f validate_file_operation
export -f handle_network_error
export -f handle_network_error_enhanced
export -f safe_execute
export -f check_service_health

# src/lib/core/fast_parser.sh
#!/bin/bash

# fast_parser.sh - Optimized section extraction
# Replaces complex AWK parser with simpler, faster bash implementation

# Configuration is loaded automatically by bashly

# Fast section extraction using pure bash
extract_section_fast() {
    local test_file="$1"
    local section="$2"

    # Quick validation
    if [[ ! -f "$test_file" || ! -r "$test_file" ]]; then
        return 1
    fi

    local in_section=false
    local section_pattern="^[[:space:]]*---[[:space:]]*${section}([[:space:]]+.*)?[[:space:]]*---"
    local end_pattern="^[[:space:]]*---"

    while IFS= read -r line; do
        # Skip empty lines and comments at start
        if [[ "$line" =~ ^[[:space:]]*$ ]] || [[ "$line" =~ ^[[:space:]]*# ]]; then
            [[ "$in_section" == "true" ]] || continue
        fi

        # Check for section start
        if [[ "$line" =~ $section_pattern ]]; then
            in_section=true
            continue
        fi

        # Check for section end
        if [[ "$in_section" == "true" && "$line" =~ $end_pattern ]]; then
            break
        fi

        # Output section content
        if [[ "$in_section" == "true" ]]; then
            # Remove inline comments (but preserve quoted strings)
            local processed_line="$line"

            # Simple comment removal (not quote-aware for performance)
            if [[ "$processed_line" =~ ^([^#]*)(#.*)?$ ]]; then
                processed_line="${BASH_REMATCH[1]}"
            fi

            # Trim whitespace
            processed_line="${processed_line#"${processed_line%%[![:space:]]*}"}"
            processed_line="${processed_line%"${processed_line##*[![:space:]]}"}"

            # Output non-empty lines
            [[ -n "$processed_line" ]] && echo "$processed_line"
        fi
    done < "$test_file"
}

# Quote-aware comment removal (for when precision is needed)
extract_section_precise() {
    local test_file="$1"
    local section="$2"

    # Fall back to AWK for complex cases requiring quote awareness
    awk -v sec="$section" '
    function strip_comments(line) {
        in_quote = 0
        escaped = 0
        result = ""

        for (i = 1; i <= length(line); i++) {
            char = substr(line, i, 1)

            if (escaped) {
                result = result char
                escaped = 0
            } else if (char == "\\") {
                result = result char
                escaped = 1
            } else if (char == "\"") {
                result = result char
                in_quote = !in_quote
            } else if (char == "#" && !in_quote) {
                break
            } else {
                result = result char
            }
        }

        # Trim whitespace
        gsub(/^[[:space:]]+|[[:space:]]+$/, "", result)
        return result
    }

    /^[[:space:]]*#/ { next }
    $0 ~ "^[[:space:]]*---[[:space:]]*" sec "([[:space:]]+.*)?[[:space:]]*---" {

        found = 1
        next

    }
    /^[[:space:]]*---/ { found = 0 }
    found {
        processed = strip_comments($0)
        if (processed != "") print processed
    }' "$test_file"
}

# Smart section extraction (chooses appropriate method)
extract_section_smart() {
    local test_file="$1"
    local section="$2"
    local precision="${3:-auto}"

    case "$precision" in
        "fast")
            extract_section_fast "$test_file" "$section"
            ;;
        "precise")
            extract_section_precise "$test_file" "$section"
            ;;
        "auto"|*)
            # Use fast method for most cases, precise for complex content
            local content=$(extract_section_fast "$test_file" "$section")

            # Check if content contains complex quoting that might need precise parsing
            if echo "$content" | grep -q '".*#.*"'; then
                extract_section_precise "$test_file" "$section"
            else
                echo "$content"
            fi
            ;;
    esac
}

# Batch section extraction (for performance)
extract_multiple_sections() {
    local test_file="$1"
    shift
    local sections=("$@")

    # Single file pass for multiple sections
    declare -A section_content
    declare -A section_found
    local current_section=""
    local in_section=false

    # Initialize arrays
    for section in "${sections[@]}"; do
        section_found["$section"]=false
        section_content["$section"]=""
    done

    while IFS= read -r line; do
        # Skip empty lines and comments outside sections
        if [[ ! "$in_section" && ( "$line" =~ ^[[:space:]]*$ || "$line" =~ ^[[:space:]]*# ) ]]; then
            continue
        fi

        # Check for any section start
        for section in "${sections[@]}"; do
            if [[ "$line" =~ ^[[:space:]]*---[[:space:]]*${section}([[:space:]]+.*)?[[:space:]]*--- ]]; then
                current_section="$section"
                in_section=true
                section_found["$section"]=true
                break
            fi
        done

        # Check for section end
        if [[ "$in_section" && "$line" =~ ^[[:space:]]*--- ]]; then
            in_section=false
            current_section=""
            continue
        fi

        # Collect section content
        if [[ "$in_section" && -n "$current_section" ]]; then
            # Simple processing
            local processed_line="$line"
            if [[ "$processed_line" =~ ^([^#]*)(#.*)?$ ]]; then
                processed_line="${BASH_REMATCH[1]}"
            fi
            processed_line="${processed_line#"${processed_line%%[![:space:]]*}"}"
            processed_line="${processed_line%"${processed_line##*[![:space:]]}"}"

            if [[ -n "$processed_line" ]]; then
                if [[ -n "${section_content[$current_section]}" ]]; then
                    section_content["$current_section"]+=$'\n'"$processed_line"
                else
                    section_content["$current_section"]="$processed_line"
                fi
            fi
        fi
    done < "$test_file"

    # Output results as JSON for easy parsing
    local json_output="{"
    local first=true

    for section in "${sections[@]}"; do
        if [[ "$first" == "true" ]]; then
            first=false
        else
            json_output+=","
        fi

        local content="${section_content[$section]}"
        # Escape JSON special characters
        content=$(echo "$content" | sed 's/\\/\\\\/g; s/"/\\"/g; s/'"'"'/\\'"'"'/g')
        json_output+="\"$section\":\"$content\""
    done

    json_output+="}"
    echo "$json_output"
}

# Performance test for different extraction methods
benchmark_extraction() {
    local test_file="$1"
    local section="${2:-ENDPOINT}"
    local iterations="${3:-100}"

    if [[ ! -f "$test_file" ]]; then
        echo "Test file not found: $test_file"
        return 1
    fi

    echo "Benchmarking extraction methods on $test_file (${iterations} iterations):"

    # Benchmark fast method
    local start_time=$(date +%s.%N 2>/dev/null || date +%s)
    for ((i=1; i<=iterations; i++)); do
        extract_section_fast "$test_file" "$section" >/dev/null
    done
    local end_time=$(date +%s.%N 2>/dev/null || date +%s)
    local fast_time=$(echo "$end_time - $start_time" | bc -l 2>/dev/null || echo "N/A")

    # Benchmark precise method

    start_time=$(date +%s.%N 2>/dev/null || date +%s)
    for ((i=1; i<=iterations; i++)); do
        extract_section_precise "$test_file" "$section" >/dev/null
    done
    end_time=$(date +%s.%N 2>/dev/null || date +%s)
    local precise_time=$(echo "$end_time - $start_time" | bc -l 2>/dev/null || echo "N/A")

    echo "Fast method:    ${fast_time}s"
    echo "Precise method: ${precise_time}s"

    if command -v bc >/dev/null 2>&1; then
        local speedup=$(echo "scale=2; $precise_time / $fast_time" | bc -l 2>/dev/null || echo "N/A")
        echo "Speedup:        ${speedup}x"
    fi
}

# Export functions
export -f extract_section_fast
export -f extract_section_precise

export -f extract_section_smart
export -f extract_multiple_sections
export -f benchmark_extraction

# src/lib/core/parallel.sh
#!/bin/bash

# parallel.sh - Advanced parallel execution utilities

# Default timeout for individual tests (in seconds)
DEFAULT_TEST_TIMEOUT=30

# Run a single test with timeout
run_test_with_timeout() {
    local test_file="$1"
    local timeout_seconds="${2:-$DEFAULT_TEST_TIMEOUT}"
    local result_file="$3"

    # Create a temporary script for timeout execution
    local timeout_script
    timeout_script=$(mktemp)

    cat > "$timeout_script" << EOF
#!/bin/bash
set -e

# All modules are automatically loaded by bashly

# Run the test
if run_single_test "$test_file"; then
    echo "PASS:$test_file" > "$result_file"
    exit 0
else
    echo "FAIL:$test_file" > "$result_file"
    exit 1
fi
EOF

    chmod +x "$timeout_script"

    # Run with timeout
    if timeout "$timeout_seconds" "$timeout_script"; then
        local exit_code=$?
        rm -f "$timeout_script"
        return $exit_code
    else
        local exit_code=$?
        echo "TIMEOUT:$test_file" > "$result_file"
        rm -f "$timeout_script"
        return 124  # Timeout exit code
    fi
}

# Enhanced parallel test execution with job management
run_enhanced_parallel_tests() {
    local test_files="$1"
    local parallel_jobs="$2"
    local timeout_seconds="${3:-$DEFAULT_TEST_TIMEOUT}"

    log info "Running enhanced parallel tests with $parallel_jobs jobs (timeout: ${timeout_seconds}s)"

    # Setup progress indicator
    local progress_mode
    progress_mode=$(get_config "progress_mode" "none")
    local test_count
    test_count=$(echo "$test_files" | wc -l)

    if [[ "$progress_mode" != "none" ]]; then
        setup_progress "$progress_mode" "$test_count"
    fi

    # Create temporary directory for results
    local results_dir
    results_dir=$(mktemp -d)
    local failed_tests=0
    local passed_tests=0
    local timeout_tests=0
    local failed_test_files=()
    local timeout_test_files=()

    # Function to run a single test with timeout
    run_single_test_with_timeout() {
        local test_file="$1"
        local result_file="$results_dir/$(basename "$test_file" | tr '/' '_').result"

        # Run the test with timeout
        if run_test_with_timeout "$test_file" "$timeout_seconds" "$result_file"; then
            return 0
        else
            local exit_code=$?
            if [[ $exit_code -eq 124 ]]; then
                echo "TIMEOUT:$test_file" > "$result_file"
            else
                echo "FAIL:$test_file" > "$result_file"
            fi
            return $exit_code
        fi
    }

    # Export function for parallel execution
    export -f run_single_test_with_timeout
    export -f run_test_with_timeout
    export -f run_single_test
    export -f run_grpc_call
    export -f compare_responses
    export -f extract_section
    export -f parse_test_file
    export -f evaluate_asserts_with_plugins
    export -f apply_tolerance_comparison
    export -f apply_percentage_tolerance_comparison
    export -f log
    export -f print_progress
    export -f setup_colors

    export -f validate_address
    export -f validate_json
    # Dependencies are handled by bashly

    # Run tests in parallel using xargs with timeout
    echo "$test_files" | xargs -n 1 -P "$parallel_jobs" -I {} bash -c 'run_single_test_with_timeout "{}"'

    # Collect results
    for result_file in "$results_dir"/*.result; do
        if [[ -f "$result_file" ]]; then
            local result
            result=$(cat "$result_file")
            local test_file
            test_file=$(echo "$result" | cut -d: -f2-)

            if [[ "$result" == PASS:* ]]; then
                ((passed_tests++))
                if [[ "$progress_mode" != "none" ]]; then
                    print_progress "." "$progress_mode"
                fi
            elif [[ "$result" == TIMEOUT:* ]]; then
                ((timeout_tests++))
                timeout_test_files+=("$test_file")
                if [[ "$progress_mode" != "none" ]]; then
                    print_progress "T" "$progress_mode"
                fi
                log error "Test timed out: $test_file"
            else
                ((failed_tests++))
                failed_test_files+=("$test_file")
                if [[ "$progress_mode" != "none" ]]; then
                    print_progress "F" "$progress_mode"
                fi
                log error "Test failed: $test_file"
            fi
        fi
    done

    # Cleanup results directory
    rm -rf "$results_dir"

    # Finish progress
    if [[ "$progress_mode" != "none" ]]; then
        finish_progress
    fi

    # Show detailed summary
    log section "Enhanced Parallel Test Summary"
    log info "Total tests: $test_count"
    log info "Passed tests: $passed_tests"
    log info "Failed tests: $failed_tests"
    log info "Timeout tests: $timeout_tests"

    if [[ ${#failed_test_files[@]} -gt 0 ]]; then
        log error "Failed test files:"
        for failed_file in "${failed_test_files[@]}"; do
            log error "  - $failed_file"
        done
    fi

    if [[ ${#timeout_test_files[@]} -gt 0 ]]; then
        log error "Timeout test files:"
        for timeout_file in "${timeout_test_files[@]}"; do
            log error "  - $timeout_file"
        done
    fi

    # Return appropriate exit code
    if [[ $failed_tests -gt 0 ]] || [[ $timeout_tests -gt 0 ]]; then
        return 1
    fi

    return 0
}

# Wait for parallel jobs with timeout
wait_for_parallel_jobs() {
    local pids=("$@")
    local timeout_seconds="${PARALLEL_TIMEOUT:-300}"
    local start_time
    start_time=$(date +%s)

    while [[ ${#pids[@]} -gt 0 ]]; do
        local current_time
        current_time=$(date +%s)
        local elapsed=$((current_time - start_time))

        if [[ $elapsed -gt $timeout_seconds ]]; then
            log error "Parallel execution timeout after ${timeout_seconds}s"
            # Kill remaining processes
            for pid in "${pids[@]}"; do
                if kill -0 "$pid" 2>/dev/null; then
                    kill -TERM "$pid" 2>/dev/null || true
                fi
            done
            return 124
        fi

        # Check which processes are still running
        local remaining_pids=()
        for pid in "${pids[@]}"; do
            if kill -0 "$pid" 2>/dev/null; then
                remaining_pids+=("$pid")
            fi
        done
        pids=("${remaining_pids[@]}")

        if [[ ${#pids[@]} -gt 0 ]]; then
            sleep 1
        fi
    done

    return 0
}

# Print failed tests summary
print_failed_tests() {
    local failed_tests=("$@")

    if [[ ${#failed_tests[@]} -eq 0 ]]; then
        return 0
    fi

    log section "Failed Tests Summary"
    for test_file in "${failed_tests[@]}"; do
        log error "âŒ $test_file"
    done

    log info "Total failed tests: ${#failed_tests[@]}"
}

# Get optimal number of parallel jobs based on system resources
get_optimal_parallel_jobs() {
    local requested_jobs="$1"
    local cpu_count
    cpu_count=$(nproc 2>/dev/null || sysctl -n hw.ncpu 2>/dev/null || echo "4")

    # Use minimum of requested jobs and CPU count * 2
    local optimal_jobs
    optimal_jobs=$((cpu_count * 2))

    if [[ "$requested_jobs" -gt "$optimal_jobs" ]]; then
        log warning "Requested $requested_jobs jobs, but optimal is $optimal_jobs (CPU count: $cpu_count)"
        echo "$optimal_jobs"
    else
        echo "$requested_jobs"
    fi
}

# Main parallel test execution function (from original version)
run_test_parallel() {
    local test_files=("$@")
    local parallel_jobs=$(get_flag "parallel" "1")
    local timeout_seconds=$(get_flag "timeout" "$DEFAULT_TEST_TIMEOUT")
    local fail_fast="true"  # Always fail fast

    # Validate parallel jobs - must be positive integer (regex: start-of-line + digits + end-of-line)
    if ! [[ "$parallel_jobs" =~ ^[0-9]+$ ]] || [[ "$parallel_jobs" -lt 1 ]]; then
        log error "Invalid parallel jobs: $parallel_jobs"
        return 1
    fi

    # Get optimal parallel jobs if auto is requested
    if [[ "$parallel_jobs" == "auto" ]]; then
        parallel_jobs=$(get_optimal_parallel_jobs "$parallel_jobs")
    fi

    log info "Starting parallel test execution with $parallel_jobs jobs"
    log debug "Test files: ${test_files[*]}"
    log debug "Timeout: ${timeout_seconds}s"
    log debug "Fail fast: $fail_fast"

    # Create results directory
    local results_dir
    results_dir=$(mktemp -d)
    local pids=()
    local test_results=()
    local failed_tests=()
    local passed_tests=()
    local timeout_tests=()

    # Function to run a single test in parallel
    run_single_test_parallel() {
        local test_file="$1"
        local result_file="$results_dir/$(basename "$test_file" | tr '/' '_').result"
        local pid_file="$results_dir/$(basename "$test_file" | tr '/' '_').pid"

        # Store PID
        echo $$ > "$pid_file"

        # Run the test with timeout and error recovery
        if timeout "$timeout_seconds" bash -c "
            # All modules are automatically loaded by bashly
            if run_single_test '$test_file'; then
                echo 'PASS:$test_file' > '$result_file'
                exit 0
            else
                local exit_code=\$?
                # Try to recover from test failure if retry is enabled
                if ! is_no_retry; then
                    if recover_from_test_failure '$test_file' 'Test failed' 1; then
                        echo 'PASS:$test_file' > '$result_file'
                        exit 0
                    fi
                fi
                echo 'FAIL:$test_file' > '$result_file'
                exit \$exit_code
            fi
        "; then
            echo "PASS:$test_file" > "$result_file"
        else
            local exit_code=$?
            if [[ $exit_code -eq 124 ]]; then
                echo "TIMEOUT:$test_file" > "$result_file"
            else
                echo "FAIL:$test_file" > "$result_file"
            fi
        fi
    }

    # Export function for parallel execution
    export -f run_single_test_parallel
    export -f run_single_test
    export -f run_grpc_call
    export -f run_grpc_call_with_retry
    export -f compare_responses
    export -f extract_section
    export -f parse_test_file
    export -f evaluate_asserts_with_plugins
    export -f apply_tolerance_comparison
    export -f apply_percentage_tolerance_comparison
    export -f log
    export -f print_progress
    export -f setup_colors

    export -f validate_address
    export -f validate_json
    # Dependencies are handled by bashly
    export -f is_no_retry
    export -f recover_from_test_failure
    export -f handle_network_failure
    export -f check_service_health
    export -f wait_for_service

    # Start tests in parallel
    for test_file in "${test_files[@]}"; do
        # Run test in background
        run_single_test_parallel "$test_file" &
        local pid=$!
        pids+=("$pid")

        # Limit number of parallel jobs
        if [[ ${#pids[@]} -ge $parallel_jobs ]]; then
            # Wait for one job to complete
            wait_for_parallel_tests "${pids[@]}"
            # Remove completed PIDs
            local remaining_pids=()
            for pid in "${pids[@]}"; do
                if kill -0 "$pid" 2>/dev/null; then
                    remaining_pids+=("$pid")
                fi
            done
            pids=("${remaining_pids[@]}")
        fi

        # Check fail-fast condition
        if [[ "$fail_fast" == "true" ]]; then
            # Check if any test has failed
            for result_file in "$results_dir"/*.result; do
                if [[ -f "$result_file" ]]; then
                    local result
                    result=$(cat "$result_file")
                    if [[ "$result" == FAIL:* ]]; then
                        log error "Fail-fast enabled: stopping execution due to test failure"
                        # Kill remaining processes
                        for pid in "${pids[@]}"; do
                            if kill -0 "$pid" 2>/dev/null; then
                                kill -TERM "$pid" 2>/dev/null || true
                            fi
                        done
                        # Collect results and return
                        collect_parallel_results "$results_dir" passed_tests failed_tests timeout_tests
                        print_failed_tests "${failed_tests[@]}"
                        rm -rf "$results_dir"
                        return 1
                    fi
                fi
            done
        fi
    done

    # Wait for remaining jobs
    wait_for_parallel_tests "${pids[@]}"

    # Collect results
    collect_parallel_results "$results_dir" passed_tests failed_tests timeout_tests

    # Cleanup
    rm -rf "$results_dir"

    # Print summary
    print_parallel_summary "${#test_files[@]}" "${#passed_tests[@]}" "${#failed_tests[@]}" "${#timeout_tests[@]}"

    # Print failed tests if any
    if [[ ${#failed_tests[@]} -gt 0 ]]; then
        print_failed_tests "${failed_tests[@]}"
    fi

    # Return appropriate exit code
    if [[ ${#failed_tests[@]} -gt 0 ]] || [[ ${#timeout_tests[@]} -gt 0 ]]; then
        return 1
    fi

    return 0
}

# Wait for parallel tests to complete (from original version)
wait_for_parallel_tests() {
    local pids=("$@")
    local timeout_seconds="${PARALLEL_TIMEOUT:-300}"
    local start_time
    start_time=$(date +%s)

    log debug "Waiting for ${#pids[@]} parallel tests to complete"

    while [[ ${#pids[@]} -gt 0 ]]; do
        local current_time
        current_time=$(date +%s)
        local elapsed=$((current_time - start_time))

        if [[ $elapsed -gt $timeout_seconds ]]; then
            log error "Parallel execution timeout after ${timeout_seconds}s"
            # Kill remaining processes
            for pid in "${pids[@]}"; do
                if kill -0 "$pid" 2>/dev/null; then
                    kill -TERM "$pid" 2>/dev/null || true
                fi
            done
            return 124
        fi

        # Check which processes are still running
        local remaining_pids=()
        for pid in "${pids[@]}"; do
            if kill -0 "$pid" 2>/dev/null; then
                remaining_pids+=("$pid")
            fi
        done
        pids=("${remaining_pids[@]}")

        if [[ ${#pids[@]} -gt 0 ]]; then
            sleep 0.1  # Shorter sleep for better responsiveness
        fi
    done

    log debug "All parallel tests completed"
    return 0
}

# Collect results from parallel execution
collect_parallel_results() {
    local results_dir="$1"
    local -n passed_tests_ref="$2"
    local -n failed_tests_ref="$3"
    local -n timeout_tests_ref="$4"

    passed_tests_ref=()
    failed_tests_ref=()
    timeout_tests_ref=()

    for result_file in "$results_dir"/*.result; do
        if [[ -f "$result_file" ]]; then
            local result
            result=$(cat "$result_file")
            local test_file
            test_file=$(echo "$result" | cut -d: -f2-)

            if [[ "$result" == PASS:* ]]; then
                passed_tests_ref+=("$test_file")
            elif [[ "$result" == TIMEOUT:* ]]; then
                timeout_tests_ref+=("$test_file")
            else
                failed_tests_ref+=("$test_file")
            fi
        fi
    done
}

# Print parallel execution summary
print_parallel_summary() {
    local total_tests="$1"
    local passed_count="$2"
    local failed_count="$3"
    local timeout_count="$4"

    log section "Parallel Test Execution Summary"
    log info "Total tests: $total_tests"
    log success "Passed tests: $passed_count"

    if [[ $failed_count -gt 0 ]]; then
        log error "Failed tests: $failed_count"
    fi

    if [[ $timeout_count -gt 0 ]]; then
        log error "Timeout tests: $timeout_count"
    fi

    # Calculate success rate
    local success_rate=0
    if [[ $total_tests -gt 0 ]]; then
        success_rate=$((passed_count * 100 / total_tests))
    fi

    log info "Success rate: ${success_rate}%"
}

# Parallel test discovery functions
discover_test_files() {
    local search_paths=("$@")
    local discovered_files=()

    # If no paths provided, use current directory
    if [[ ${#search_paths[@]} -eq 0 ]]; then
        search_paths=(".")
    fi

    log debug "Discovering test files in paths: ${search_paths[*]}"

    for path in "${search_paths[@]}"; do
        if [[ -f "$path" ]]; then
            # Single file
            if [[ "$path" == *.gctf ]]; then
                discovered_files+=("$path")
            fi
        elif [[ -d "$path" ]]; then
            # Directory - find all .gctf files recursively
            while IFS= read -r -d '' file; do
                discovered_files+=("$file")
            done < <(find "$path" -name "*.gctf" -type f -print0 2>/dev/null)
        fi
    done

    # Remove duplicates and sort
    if [[ ${#discovered_files[@]} -gt 0 ]]; then
        printf '%s\n' "${discovered_files[@]}" | sort -u
    fi
}

# Parallel test discovery with categorization
discover_and_categorize_tests() {
    local search_paths=("$@")
    local discovered_files
    discovered_files=$(discover_test_files "${search_paths[@]}")

    if [[ -z "$discovered_files" ]]; then
        log warning "No test files found in specified paths"
        return 1
    fi

    local total_count
    total_count=$(echo "$discovered_files" | wc -l)
    log info "Discovered $total_count test files"

    # Categorize tests by directory structure
    local categorized_tests=()
    local categories=()

    while IFS= read -r test_file; do
        if [[ -n "$test_file" ]]; then
            local dir_name
            dir_name=$(dirname "$test_file")
            local category
            category=$(basename "$dir_name")

            # Add to category if not already present
            if [[ ! " ${categories[*]} " =~ " $category " ]]; then
                categories+=("$category")
            fi

            categorized_tests+=("$category:$test_file")
        fi
    done <<< "$discovered_files"

    # Print categorization summary
    log section "Test Discovery Summary"
    for category in "${categories[@]}"; do
        local count=0
        for test in "${categorized_tests[@]}"; do
            if [[ "$test" == "$category:"* ]]; then
                ((count++))
            fi
        done
        log info "Category '$category': $count tests"
    done

    # Return discovered files
    echo "$discovered_files"
}

# Parallel test discovery with filtering
discover_tests_with_filters() {
    local search_paths=("$@")
    local filter_pattern="${TEST_FILTER:-}"
    local exclude_pattern="${TEST_EXCLUDE:-}"
    local max_depth="${TEST_MAX_DEPTH:-}"

    local discovered_files
    discovered_files=$(discover_test_files "${search_paths[@]}")

    if [[ -z "$discovered_files" ]]; then
        return 1
    fi

    local filtered_files=()

    while IFS= read -r test_file; do
        if [[ -n "$test_file" ]]; then
            local include_file=true

            # Apply include filter
            if [[ -n "$filter_pattern" ]]; then
                if [[ ! "$test_file" =~ $filter_pattern ]]; then
                    include_file=false
                fi
            fi

            # Apply exclude filter
            if [[ -n "$exclude_pattern" ]] && [[ "$include_file" == true ]]; then
                if [[ "$test_file" =~ $exclude_pattern ]]; then
                    include_file=false
                fi
            fi

            # Apply depth filter
            if [[ -n "$max_depth" ]] && [[ "$include_file" == true ]]; then
                local depth
                depth=$(echo "$test_file" | tr -cd '/' | wc -c)
                if [[ $depth -gt $max_depth ]]; then
                    include_file=false
                fi
            fi

            if [[ "$include_file" == true ]]; then
                filtered_files+=("$test_file")
            fi
        fi
    done <<< "$discovered_files"

    if [[ ${#filtered_files[@]} -gt 0 ]]; then
        printf '%s\n' "${filtered_files[@]}"
    fi
}

# Parallel test discovery with dependency analysis
discover_tests_with_dependencies() {
    local search_paths=("$@")
    local discovered_files
    discovered_files=$(discover_test_files "${search_paths[@]}")

    if [[ -z "$discovered_files" ]]; then
        return 1
    fi

    local dependency_map=()
    local independent_tests=()
    local dependent_tests=()

    while IFS= read -r test_file; do
        if [[ -n "$test_file" ]]; then
            # DEPENDS section removed - all tests are now independent
            independent_tests+=("$test_file")
        fi
    done <<< "$discovered_files"

    # Print dependency analysis
    log section "Test Dependency Analysis"
    log info "Independent tests: ${#independent_tests[@]}"
    log info "Dependent tests: ${#dependent_tests[@]}"

    if [[ ${#dependent_tests[@]} -gt 0 ]]; then
        log info "Dependency relationships:"
        for dep_info in "${dependency_map[@]}"; do
            local test_file
            test_file=$(echo "$dep_info" | cut -d: -f1)
            local dependencies
            dependencies=$(echo "$dep_info" | cut -d: -f2-)
            log info "  $test_file depends on: $dependencies"
        done
    fi

    # Return all discovered files
    echo "$discovered_files"
}

# Optimize test execution order based on dependencies and test characteristics
optimize_test_execution_order() {
    local test_files=("$@")
    local optimized_order=()
    local independent_tests=()
    local dependent_tests=()

    # DEPENDS section removed - all tests are independent
    independent_tests=("${test_files[@]}")
    dependent_tests=()

    # Add independent tests first (can run in parallel)
    optimized_order+=("${independent_tests[@]}")

    # Add dependent tests (need to be run after dependencies)
    optimized_order+=("${dependent_tests[@]}")

    # Return optimized order
    printf '%s\n' "${optimized_order[@]}"
}

# Export new functions
export -f discover_test_files
export -f discover_and_categorize_tests
export -f discover_tests_with_filters
export -f discover_tests_with_dependencies
export -f optimize_test_execution_order

# src/lib/core/parser.sh
#!/bin/bash

# parser.sh - Test file parsing
# Simple, efficient parsing functions

extract_section() {
    local test_file="$1"
    local section="$2"

    extract_section_awk "$test_file" "$section" | sed -e 's/^[[:space:]]*//' -e 's/[[:space:]]*$//'
}

parse_test_file() {
    local test_file="$1"

    # Extract all sections
    local address
    address="$(extract_section "$test_file" "ADDRESS")"
    local endpoint
    endpoint="$(extract_section "$test_file" "ENDPOINT")"
    local request
    request="$(extract_section "$test_file" "REQUEST")"
    local response
    response="$(extract_section "$test_file" "RESPONSE")"
    local error
    error="$(extract_section "$test_file" "ERROR")"
    local headers
    headers="$(extract_section "$test_file" "HEADERS")"
    local request_headers
    request_headers="$(extract_section "$test_file" "REQUEST_HEADERS")"
    # RESPONSE_HEADERS and RESPONSE_TRAILERS removed - use @header()/@trailer() assertions instead

    # Set defaults for backward compatibility
    if [[ -z "$address" ]]; then
        # Use environment variable if available, otherwise use default
        address="${GRPCTESTIFY_ADDRESS:-localhost:4770}"
    fi

    if [[ -z "$endpoint" ]]; then
        log error "Missing ENDPOINT section in $test_file"
        return 1
    fi

    # RESPONSE is optional if ERROR is present (backward compatibility)
    # Both can be empty for some test cases

    # Return structured data using jq for proper JSON escaping
    jq -n \
        --arg address "$address" \
        --arg endpoint "$endpoint" \
        --arg request "$request" \
        --arg response "$response" \
        --arg error "$error" \
        --arg headers "$headers" \
        --arg request_headers "$request_headers" \
        '{
            address: $address,
            endpoint: $endpoint,
            request: $request,
            response: $response,
            error: $error,
            headers: $headers,
            request_headers: $request_headers
        }'
}

parse_inline_options() {
    local header="$1"

    # Extract options from header: --- RESPONSE key=value ... ---
    if [[ "$header" =~ ---[[:space:]]*RESPONSE[[:space:]]+(.+)[[:space:]]*--- ]]; then
        local options_str="${BASH_REMATCH[1]}"

        # Simple approach: split by spaces and process each token
        local tokens=()
        local in_quotes=false
        local current_token=""

        # Tokenize the options string, respecting quotes
        for ((i=0; i<${#options_str}; i++)); do
            local char="${options_str:$i:1}"

            if [[ "$char" == '"' ]]; then
                in_quotes=$((!in_quotes))
                current_token+="$char"
            elif [[ "$char" == ' ' && $in_quotes -eq 0 ]]; then
                if [[ -n "$current_token" ]]; then
                    tokens+=("$current_token")
                    current_token=""
                fi
            else
                current_token+="$char"
            fi
        done

        # Add the last token if any
        if [[ -n "$current_token" ]]; then
            tokens+=("$current_token")
        fi

        # Process each token as key=value pair or standalone flags
        for token in "${tokens[@]}"; do
            if [[ "$token" =~ ^([a-zA-Z_][a-zA-Z0-9_]*(\[[^\]]*\])?)=(.*)$ ]]; then
                # Key=value format
                local key="${BASH_REMATCH[1]}"
                local value="${BASH_REMATCH[3]}"

                # Remove quotes from value
                value="${value%\"}"
                value="${value#\"}"

                echo "$key=$value"
            elif [[ "$token" =~ ^([a-zA-Z_][a-zA-Z0-9_]*)$ ]]; then
                # Standalone flag (e.g., with_asserts)
                echo "${BASH_REMATCH[1]}=true"
            fi
        done
    fi
}

# src/lib/core/performance_cache.sh
#!/bin/bash

# performance_cache.sh - Performance optimization and caching utilities
# Improves startup time and reduces repeated computations

# Dependencies are loaded automatically by bashly

# Cache directory for parsed files
PARSE_CACHE_DIR="${DEFAULT_CACHE_DIR}"

# Initialize cache system
init_performance_cache() {
    if [[ ! -d "$PARSE_CACHE_DIR" ]]; then
        # Create cache directory with secure permissions
        if ! mkdir -p "$PARSE_CACHE_DIR" 2>/dev/null; then
            # Fallback to user-specific temp directory
            PARSE_CACHE_DIR="${HOME}/.cache/grpctestify"
            mkdir -p "$PARSE_CACHE_DIR" 2>/dev/null || return 1
        fi

        # Set secure permissions (owner only)
        chmod 700 "$PARSE_CACHE_DIR" 2>/dev/null || true
    fi
}

# Generate cache key for file
get_cache_key() {
    local file="$1"
    local file_hash=""

    if command -v md5sum >/dev/null 2>&1; then
        file_hash=$(md5sum "$file" 2>/dev/null | cut -d' ' -f1)
    elif command -v shasum >/dev/null 2>&1; then
        file_hash=$(shasum -a 256 "$file" 2>/dev/null | cut -d' ' -f1)
    else
        # Fallback to file stats
        file_hash=$(stat -c '%Y-%s' "$file" 2>/dev/null || stat -f '%m-%z' "$file" 2>/dev/null || date +%s)
    fi

    echo "${file_hash}"
}

# Cached version of extract_section
extract_section_cached() {
    local test_file="$1"
    local section="$2"

    # Initialize cache if needed
    init_performance_cache

    # Generate cache key
    local cache_key
    cache_key="$(get_cache_key "$test_file")"
    local cache_file="$PARSE_CACHE_DIR/${cache_key}_${section}"

    # Check if cached version exists and is newer than source
    if [[ -f "$cache_file" && "$cache_file" -nt "$test_file" ]]; then
        cat "$cache_file" 2>/dev/null
        return $?
    fi

    # Parse and cache the result
    local result
    result=$(extract_section_awk "$test_file" "$section")
    local status=$?

    # Cache successful results
    if [[ $status -eq 0 && -n "$result" ]]; then
        echo "$result" > "$cache_file" 2>/dev/null || true
    fi

    echo "$result"
    return $status
}

# Fast dependency check with caching
check_dependencies_cached() {
    local deps_cache="$PARSE_CACHE_DIR/dependencies_check"
    local cache_ttl=3600  # 1 hour

    # Check if cache is fresh
    if [[ -f "$deps_cache" ]]; then
        local cache_age=$(($(date +%s) - $(stat -c %Y "$deps_cache" 2>/dev/null || stat -f %m "$deps_cache" 2>/dev/null || echo 0)))
        if [[ $cache_age -lt $cache_ttl ]]; then
            cat "$deps_cache"
            return $?
        fi
    fi

    # Check dependencies and cache result
    local result=""
    local status=0

    for cmd in grpcurl jq bc; do
        if ! command -v "$cmd" >/dev/null 2>&1; then
            result+="Missing dependency: $cmd\n"
            status=1
        fi
    done

    # Cache the result
    init_performance_cache
    echo -e "$result" > "$deps_cache" 2>/dev/null || true

    if [[ $status -eq 0 ]]; then
        echo "All dependencies available"
    else
        echo -e "$result"
    fi

    return $status
}

# Clean old cache files
cleanup_cache() {
    local max_age="${1:-86400}"  # 24 hours default

    if [[ -d "$PARSE_CACHE_DIR" ]]; then
        find "$PARSE_CACHE_DIR" -type f -mtime +1 -delete 2>/dev/null || true

        # Remove empty directory
        rmdir "$PARSE_CACHE_DIR" 2>/dev/null || true
    fi
}

# Performance monitoring
start_timer() {
    PERF_START_TIME=$(date +%s.%N 2>/dev/null || date +%s)
}

end_timer() {
    local label="${1:-Operation}"
    local end_time=$(date +%s.%N 2>/dev/null || date +%s)

    if command -v bc >/dev/null 2>&1; then
        local duration=$(echo "$end_time - $PERF_START_TIME" | bc -l 2>/dev/null || echo "0")
        log debug "$label took ${duration}s"
    fi
}

# Optimized file parsing with early exit
parse_test_file_fast() {
    local test_file="$1"

    # Quick validation
    if [[ ! -f "$test_file" || ! -r "$test_file" ]]; then
        return 1
    fi

    start_timer

    # Use cached extraction
    local address="$(extract_section_cached "$test_file" "ADDRESS")"
    local endpoint="$(extract_section_cached "$test_file" "ENDPOINT")"

    # Early exit if endpoint is missing
    if [[ -z "$endpoint" ]]; then
        end_timer "Fast parse (failed)"
        return 1
    fi

    local request="$(extract_section_cached "$test_file" "REQUEST")"
    local response="$(extract_section_cached "$test_file" "RESPONSE")"
    local error="$(extract_section_cached "$test_file" "ERROR")"
    local headers="$(extract_section_cached "$test_file" "HEADERS")"
    local request_headers="$(extract_section_cached "$test_file" "REQUEST_HEADERS")"

    # Set defaults efficiently
    [[ -z "$address" ]] && address="${GRPCTESTIFY_ADDRESS:-localhost:4770}"
    [[ -z "$headers" ]] && headers="$request_headers"

    # Generate JSON output efficiently
    jq -n \
        --arg address "$address" \
        --arg endpoint "$endpoint" \
        --arg request "$request" \
        --arg response "$response" \
        --arg error "$error" \
        --arg request_headers "$headers" \
        '{
            address: $address,
            endpoint: $endpoint,
            request: $request,
            response: $response,
            error: $error,
            request_headers: $request_headers
        }'

    end_timer "Fast parse"
    return 0
}

# src/lib/core/plugin_api.sh
#!/bin/bash

# plugin_api.sh - Official Plugin Development API
# Provides standardized interface for developing gRPC Testify plugins

# Plugin API version
# PLUGIN_API_VERSION is defined in config.sh

# Plugin development utilities
PLUGIN_DEV_MODE="${GRPCTESTIFY_PLUGIN_DEV:-false}"

# Plugin template generation
create_plugin_template() {
    local plugin_name="$1"
    local plugin_type="${2:-assertion}"  # assertion, validation, utility
    local output_dir="${3:-plugins}"

    if [[ -z "$plugin_name" ]]; then
        log error "Plugin name is required"
        return 1
    fi

    # Validate plugin name
    if [[ ! "$plugin_name" =~ ^[a-z][a-z0-9_]*$ ]]; then
        log error "Plugin name must start with lowercase letter and contain only lowercase letters, numbers, and underscores"
        return 1
    fi

    local plugin_file="${output_dir}/grpc_${plugin_name}.sh"
    local test_file="${output_dir}/grpc_${plugin_name}.bats"
    local docs_file="${output_dir}/grpc_${plugin_name}.md"

    # Create output directory
    mkdir -p "$output_dir"

    log info "Creating plugin template: $plugin_name"

    # Generate main plugin file
    generate_plugin_source "$plugin_name" "$plugin_type" > "$plugin_file"

    # Generate test file
    generate_plugin_tests "$plugin_name" "$plugin_type" > "$test_file"

    # Generate documentation
    generate_plugin_docs "$plugin_name" "$plugin_type" > "$docs_file"

    # Make plugin executable
    chmod +x "$plugin_file"
    chmod +x "$test_file"

    log success "Plugin template created successfully:"
    log info "  Source: $plugin_file"
    log info "  Tests:  $test_file"
    log info "  Docs:   $docs_file"

    log info ""
    log info "Next steps:"
    log info "1. Edit $plugin_file to implement your plugin logic"
    log info "2. Update tests in $test_file"
    log info "3. Run tests: bats $test_file"
    log info "4. Update documentation in $docs_file"
    log info "5. Register plugin in plugin_system_enhanced.sh"
}

# Generate plugin source template
generate_plugin_source() {
    local plugin_name="$1"
    local plugin_type="$2"

    cat << EOF
#!/bin/bash

# grpc_${plugin_name}.sh - ${plugin_name^} plugin for gRPC Testify
# Plugin Type: $plugin_type
# API Version: $PLUGIN_API_VERSION

# Plugin metadata
PLUGIN_${plugin_name^^}_VERSION="$CONFIG_VERSION"
PLUGIN_${plugin_name^^}_DESCRIPTION="Description of ${plugin_name} plugin"
PLUGIN_${plugin_name^^}_AUTHOR="Your Name <info@babichev.net>"

# Plugin configuration (using centralized config)
declare -A PLUGIN_${plugin_name^^}_CONFIG=(
    ["timeout"]="\$PLUGIN_TIMEOUT"
    ["strict_mode"]="\$PLUGIN_STRICT_MODE"
    ["debug"]="\$PLUGIN_DEBUG"
    ["max_retries"]="\$PLUGIN_MAX_RETRIES"
)

# Main plugin assertion function
assert_${plugin_name}() {
    local response="\$1"
    local parameter="\$2"
    local expected_value="\$3"
    local operation_type="\${4:-equals}"

    # Validate inputs
    if [[ -z "\$response" ]]; then
        log error "${plugin_name^} plugin: Empty response"
        return 1
    fi

    if [[ -z "\$parameter" ]]; then
        log error "${plugin_name^} plugin: Parameter is required"
        return 1
    fi

    # Validate parameter name (security check)
    if [[ ! "\$parameter" =~ ^[a-zA-Z0-9._-]+$ ]]; then
        log error "${plugin_name^} plugin: Invalid parameter name '\$parameter'"
        return 1
    fi

    # Validate response is valid JSON (basic check)
    if [[ "\$response" != "{}" ]] && ! echo "\$response" | jq empty >/dev/null 2>&1; then
        log error "${plugin_name^} plugin: Invalid JSON response"
        return 1
    fi

    # Debug logging
    if [[ "\${PLUGIN_${plugin_name^^}_CONFIG[debug]}" == "true" ]]; then
        log debug "${plugin_name^} plugin: Processing parameter '\$parameter'"
        log debug "${plugin_name^} plugin: Expected value '\$expected_value'"
        log debug "${plugin_name^} plugin: Operation type '\$operation_type'"
    fi

    # Extract value from response
    local actual_value
    case "\$operation_type" in
        "equals"|"legacy")
            actual_value=\$(extract_${plugin_name}_value "\$response" "\$parameter")
            ;;
        "test")
            actual_value=\$(extract_${plugin_name}_value "\$response" "\$parameter")
            ;;
        *)
            log error "${plugin_name^} plugin: Unknown operation type '\$operation_type'"
            return 1
            ;;
    esac

    if [[ -z "\$actual_value" ]]; then
        log error "${plugin_name^} plugin: Could not extract value for parameter '\$parameter'"
        return 1
    fi

    # Perform assertion based on operation type
    case "\$operation_type" in
        "equals"|"legacy")
            if [[ "\$actual_value" == "\$expected_value" ]]; then
                log debug "${plugin_name^} assertion passed: '\$parameter' == '\$expected_value'"
                return 0
            else
                log error "${plugin_name^} assertion failed: '\$parameter' expected '\$expected_value', got '\$actual_value'"
                return 1
            fi
            ;;
        "test")
            if echo "\$actual_value" | grep -qE "\$expected_value"; then
                log debug "${plugin_name^} test assertion passed: '\$parameter' matches pattern '\$expected_value'"
                return 0
            else
                log error "${plugin_name^} test assertion failed: '\$parameter' value '\$actual_value' does not match pattern '\$expected_value'"
                return 1
            fi
            ;;
    esac
}

# Value extraction function (customize based on your plugin's needs)
extract_${plugin_name}_value() {
    local response="\$1"
    local parameter="\$2"

    # Generic value extraction - customize based on your plugin's needs
    # Common patterns:
    # - Headers: echo "\$response" | jq -r ".headers[\"\$parameter\"] // empty"
    # - Fields: echo "\$response" | jq -r ".\$parameter // empty"

    # - Nested: echo "\$response" | jq -r ".data.\$parameter // empty"

    # Default implementation extracts field directly
    echo "\$response" | jq -r ".\$parameter // empty" 2>/dev/null || echo ""
}

# Test function for @${plugin_name}(...) | test(...) syntax
test_${plugin_name}() {
    local response="\$1"
    local parameter="\$2"
    local pattern="\$3"

    assert_${plugin_name} "\$response" "\$parameter" "\$pattern" "test"
}

# Plugin configuration functions
set_${plugin_name}_config() {
    local key="\$1"
    local value="\$2"

    if [[ -z "\$key" ]]; then
        log error "${plugin_name^} plugin: Configuration key is required"
        return 1
    fi

    PLUGIN_${plugin_name^^}_CONFIG["\$key"]="\$value"
    log debug "${plugin_name^} plugin: Configuration '\$key' set to '\$value'"
}

get_${plugin_name}_config() {
    local key="\$1"

    if [[ -z "\$key" ]]; then
        log error "${plugin_name^} plugin: Configuration key is required"
        return 1
    fi

    echo "\${PLUGIN_${plugin_name^^}_CONFIG[\$key]}"
}

# Plugin validation function
validate_${plugin_name}_plugin() {
    local issues=()

    # Check required functions
    if ! declare -f extract_${plugin_name}_value >/dev/null; then
        issues+=("Missing extract_${plugin_name}_value function")
    fi

    if ! declare -f assert_${plugin_name} >/dev/null; then
        issues+=("Missing assert_${plugin_name} function")
    fi

    # Check configuration
    if [[ -z "\${PLUGIN_${plugin_name^^}_VERSION}" ]]; then
        issues+=("Missing plugin version")
    fi

    if [[ -z "\${PLUGIN_${plugin_name^^}_DESCRIPTION}" ]]; then
        issues+=("Missing plugin description")
    fi

    # Report issues
    if [[ \${#issues[@]} -gt 0 ]]; then
        log error "${plugin_name^} plugin validation failed:"
        for issue in "\${issues[@]}"; do
            log error "  - \$issue"
        done
        return 1
    fi

    log success "${plugin_name^} plugin validation passed"
    return 0
}

# Plugin registration function
register_${plugin_name}_plugin() {
    # Validate plugin before registration
    if ! validate_${plugin_name}_plugin; then
        log error "Cannot register ${plugin_name} plugin: validation failed"
        return 1
    fi

    # Register with plugin system
    register_plugin "${plugin_name}" "assert_${plugin_name}" "\${PLUGIN_${plugin_name^^}_DESCRIPTION}" "external"

    log info "${plugin_name^} plugin registered successfully (version \${PLUGIN_${plugin_name^^}_VERSION})"
}

# Plugin help function
show_${plugin_name}_help() {
    cat << 'HELP_EOF'
${plugin_name^} Plugin Help
=======================

Usage in test files:
  @${plugin_name}("parameter") == "expected_value"
  @${plugin_name}("parameter") | test("regex_pattern")

Configuration:
  Set configuration: set_${plugin_name}_config "key" "value"
  Get configuration: get_${plugin_name}_config "key"

Available configuration options:
$(for key in \${!PLUGIN_${plugin_name^^}_CONFIG[@]}; do
    printf "  %-20s %s\n" "\$key:" "\${PLUGIN_${plugin_name^^}_CONFIG[\$key]}"
done)

Examples:
  # Basic assertion
  @${plugin_name}("field") == "expected"

  # Pattern matching
  @${plugin_name}("field") | test("^[0-9]+\$")

  # Combined with jq
  @${plugin_name}("field") == "value" and .other_field == "test"

For more information, see the plugin documentation.
HELP_EOF
}

# Export plugin functions
export -f assert_${plugin_name}
export -f test_${plugin_name}
export -f extract_${plugin_name}_value
export -f set_${plugin_name}_config
export -f get_${plugin_name}_config
export -f validate_${plugin_name}_plugin
export -f register_${plugin_name}_plugin
export -f show_${plugin_name}_help
EOF
}

# Generate plugin test template
generate_plugin_tests() {
    local plugin_name="$1"
    local plugin_type="$2"

    cat << EOF
#!/usr/bin/env bats

# grpc_${plugin_name}.bats - Tests for ${plugin_name} plugin

# Load the plugin
load './grpc_${plugin_name}.sh'
load '../core/colors.sh'

setup() {
    # Initialize colors for testing
    setup_colors
}

@test "${plugin_name} plugin loads without errors" {
    # Test plugin loading
    run validate_${plugin_name}_plugin
    [ \$status -eq 0 ]
}

@test "${plugin_name} plugin has required metadata" {
    # Test version
    [ -n "\${PLUGIN_${plugin_name^^}_VERSION}" ]

    # Test description
    [ -n "\${PLUGIN_${plugin_name^^}_DESCRIPTION}" ]

    # Test author
    [ -n "\${PLUGIN_${plugin_name^^}_AUTHOR}" ]
}

@test "${plugin_name} plugin configuration works" {
    # Set configuration
    run set_${plugin_name}_config "test_key" "test_value"
    [ \$status -eq 0 ]

    # Get configuration
    run get_${plugin_name}_config "test_key"
    [ \$status -eq 0 ]
    [ "\$output" = "test_value" ]
}

@test "${plugin_name} plugin validation catches errors" {
    # Add specific validation tests based on plugin requirements
    # run assert_${plugin_name} "" "parameter" "expected"
    # [ \$status -ne 0 ]

    # Plugin-specific validation tests not implemented yet
}

@test "${plugin_name} plugin assertion works with valid input" {
    # Add positive test cases for plugin functionality
    # local test_response='{"field": "value"}'
    # run assert_${plugin_name} "\$test_response" "field" "value"
    # [ \$status -eq 0 ]

    # Positive test cases not implemented yet
}

@test "${plugin_name} plugin assertion fails with invalid input" {
    # Add negative test cases for error handling
    # local test_response='{"field": "wrong_value"}'
    # run assert_${plugin_name} "\$test_response" "field" "expected_value"
    # [ \$status -ne 0 ]

    # Negative test cases not implemented yet
}

@test "${plugin_name} plugin supports pattern testing" {
    # Add pattern testing for regex functionality
    # local test_response='{"field": "test123"}'
    # run test_${plugin_name} "\$test_response" "field" "^test[0-9]+\$"
    # [ \$status -eq 0 ]

    # Pattern testing not implemented yet
}

@test "${plugin_name} plugin handles edge cases" {
    # Test empty response
    run assert_${plugin_name} "" "field" "value"
    [ \$status -ne 0 ]

    # Test missing parameter
    run assert_${plugin_name} '{"field": "value"}' "" "value"
    [ \$status -ne 0 ]

    # Test missing field
    run assert_${plugin_name} '{"other": "value"}' "field" "value"
    [ \$status -ne 0 ]
}

@test "${plugin_name} plugin registration works" {
    # Test plugin registration
    run register_${plugin_name}_plugin
    [ \$status -eq 0 ]
}

@test "${plugin_name} plugin help is available" {
    # Test help function
    run show_${plugin_name}_help
    [ \$status -eq 0 ]
    [[ "\$output" =~ "${plugin_name^} Plugin Help" ]]
}

# Add more specific tests based on your plugin's functionality
# Examples:
# - Test different data types
# - Test complex JSON structures
# - Test error conditions
# - Test performance with large responses
# - Test integration with other plugins
EOF
}

# Generate plugin documentation template
generate_plugin_docs() {
    local plugin_name="$1"
    local plugin_type="$2"

    cat << EOF
# ${plugin_name^} Plugin

Plugin for gRPC Testify that provides ${plugin_name} validation functionality.

**Type**: $plugin_type

**API Version**: $PLUGIN_API_VERSION

**Status**: Development

Custom plugin template generated by grpctestify.

\`\`\`php
--- ASSERTS ---
@${plugin_name}("parameter") == "expected_value"
@${plugin_name}("parameter") | test("regex_pattern")
\`\`\`

\`\`\`php
# Basic assertion
@${plugin_name}("field") == "expected"

# Pattern matching
@${plugin_name}("field") | test("^[0-9]+\$")

# Combined with jq
@${plugin_name}("field") == "value" and .other_field == "test"
\`\`\`

The plugin supports the following configuration options:

| Option | Default | Description |
|--------|---------|-------------|
| \`timeout\` | \`30\` | Plugin operation timeout in seconds |
| \`strict_mode\` | \`false\` | Enable strict validation mode |
| \`debug\` | \`false\` | Enable debug logging |

\`\`\`bash
# Set configuration
set_${plugin_name}_config "timeout" "60"
set_${plugin_name}_config "strict_mode" "true"

# Get configuration
timeout=\$(get_${plugin_name}_config "timeout")
\`\`\`

Main assertion function for the plugin.

**Parameters:**
- \`response\` - gRPC response JSON
- \`parameter\` - Parameter to extract/validate
- \`expected_value\` - Expected value or pattern
- \`operation_type\` - Type of operation (equals, test)

**Returns:**
- \`0\` - Assertion passed
- \`1\` - Assertion failed

Pattern testing function for regex validation.

Extracts value from response for the given parameter.

Sets plugin configuration.

Gets plugin configuration value.

Implementation details to document:
- How the plugin extracts values from responses
- What data formats are supported
- Error handling approach and recovery strategies
- Performance considerations and optimizations

Run the plugin tests:

\`\`\`bash
bats grpc_${plugin_name}.bats
\`\`\`

Development guidelines:
- How to extend the plugin functionality
- Adding new features and capabilities
- Contributing guidelines and best practices

Examples showing the plugin in production scenarios:
- Integration with CI/CD pipelines
- Complex assertion patterns
- Performance optimization techniques

Common issues and their solutions:
- Configuration problems and fixes
- Performance issues and optimization
- Integration challenges and workarounds

Enable debug mode for detailed logging:

\`\`\`bash
set_${plugin_name}_config "debug" "true"
\`\`\`

- Initial plugin template

This plugin is part of gRPC Testify and follows the same license terms.
EOF
}

# Plugin validation API
validate_plugin_api() {
    local plugin_file="$1"

    if [[ ! -f "$plugin_file" ]]; then
        log error "Plugin file not found: $plugin_file"
        return 1
    fi

    local plugin_name
    plugin_name=$(basename "$plugin_file" .sh | sed 's/^grpc_//')

    log info "Validating plugin: $plugin_name"

    # Source the plugin
    if ! source "$plugin_file"; then
        log error "Failed to source plugin file: $plugin_file"
        return 1
    fi

    # Check required functions
    local required_functions=(
        "assert_${plugin_name}"
        "register_${plugin_name}_plugin"
    )

    local validation_errors=()

    for func in "${required_functions[@]}"; do
        if ! declare -f "$func" >/dev/null; then
            validation_errors+=("Missing required function: $func")
        fi
    done

    # Check metadata variables
    local version_var="PLUGIN_${plugin_name^^}_VERSION"
    local desc_var="PLUGIN_${plugin_name^^}_DESCRIPTION"

    if [[ -z "${!version_var}" ]]; then
        validation_errors+=("Missing version variable: $version_var")
    fi

    if [[ -z "${!desc_var}" ]]; then
        validation_errors+=("Missing description variable: $desc_var")
    fi

    # Report validation results
    if [[ ${#validation_errors[@]} -gt 0 ]]; then
        log error "Plugin validation failed:"
        for error in "${validation_errors[@]}"; do
            log error "  - $error"
        done
        return 1
    fi

    log success "Plugin validation passed: $plugin_name"
    return 0
}

# Plugin testing API
test_plugin_api() {
    local plugin_file="$1"

    if [[ ! -f "$plugin_file" ]]; then
        log error "Plugin file not found: $plugin_file"
        return 1
    fi

    local test_file="${plugin_file%.sh}.bats"

    if [[ ! -f "$test_file" ]]; then
        log warning "No test file found: $test_file"
        return 1
    fi

    log info "Running plugin tests: $test_file"

    if command -v bats >/dev/null 2>&1; then
        bats "$test_file"
    else
        log error "bats not found. Install bats to run plugin tests."
        return 1
    fi
}

# Plugin installation API
install_plugin_api() {
    local plugin_file="$1"
    local install_dir="${2:-~/.grpctestify/plugins}"

    if [[ ! -f "$plugin_file" ]]; then
        log error "Plugin file not found: $plugin_file"
        return 1
    fi

    # Validate plugin first
    if ! validate_plugin_api "$plugin_file"; then
        log error "Plugin validation failed. Cannot install."
        return 1
    fi

    # Copy to installation directory
    local plugin_name
    plugin_name=$(basename "$plugin_file")
    local dest_file="$install_dir/$plugin_name"

    mkdir -p "$install_dir"

    if cp "$plugin_file" "$dest_file"; then
        chmod +x "$dest_file"
        log success "Plugin installed: $dest_file"
    else
        log error "Failed to install plugin: $plugin_file"
        return 1
    fi

    # Copy tests if they exist
    local test_file="${plugin_file%.sh}.bats"
    if [[ -f "$test_file" ]]; then
        local dest_test="$install_dir/$(basename "$test_file")"
        if cp "$test_file" "$dest_test"; then
            chmod +x "$dest_test"
            log info "Plugin tests installed: $dest_test"
        fi
    fi

    return 0
}

# Plugin development help
show_plugin_api_help() {
    cat << 'EOF'
gRPC Testify Plugin Development API
==================================

COMMANDS:
  create-plugin <name> [type] [dir]  Create new plugin template
  validate-plugin <file>             Validate plugin compliance
  test-plugin <file>                 Run plugin tests
  install-plugin <file> [dir]        Install plugin to system

PLUGIN TYPES:
  assertion    - Custom assertion plugins (default)
  validation   - Type validation plugins

  utility      - Utility and helper plugins

EXAMPLES:
  # Create a new assertion plugin
  create_plugin_template "custom_auth" "assertion" "my_plugins"

  # Validate plugin compliance
  validate_plugin_api "my_plugins/grpc_custom_auth.sh"

  # Run plugin tests
  test_plugin_api "my_plugins/grpc_custom_auth.sh"

  # Install plugin
  install_plugin_api "my_plugins/grpc_custom_auth.sh"

PLUGIN STRUCTURE:
  grpc_plugin_name.sh     - Main plugin source
  grpc_plugin_name.bats   - Plugin tests
  grpc_plugin_name.md     - Plugin documentation

REQUIRED FUNCTIONS:
  assert_<name>()           - Main assertion function
  register_<name>_plugin()  - Plugin registration
  validate_<name>_plugin()  - Plugin validation

OPTIONAL FUNCTIONS:
  test_<name>()            - Pattern testing function
  extract_<name>_value()   - Value extraction
  set_<name>_config()      - Configuration setter
  get_<name>_config()      - Configuration getter

METADATA VARIABLES:
  PLUGIN_<NAME>_VERSION     - Plugin version
  PLUGIN_<NAME>_DESCRIPTION - Plugin description
  PLUGIN_<NAME>_AUTHOR      - Plugin author

For detailed documentation, see: docs/api-reference/plugin-development.md
EOF
}

# Export API functions
export -f create_plugin_template
export -f generate_plugin_source
export -f generate_plugin_tests
export -f generate_plugin_docs
export -f validate_plugin_api
export -f test_plugin_api
export -f install_plugin_api
export -f show_plugin_api_help

# src/lib/core/plugin_system_enhanced.sh
#!/bin/bash

# plugin_system_enhanced.sh - Enhanced plugin system for extensible assertions
# Supports both embedded internal plugins and external plugin loading

# Plugin registry - stores available plugins (using globals for bashly compatibility)
declare -A PLUGIN_REGISTRY
declare -A PLUGIN_DESCRIPTIONS
declare -A PLUGIN_TYPES

# Plugin directories
EXTERNAL_PLUGIN_DIR="${EXTERNAL_PLUGIN_DIR:-~/.grpctestify/plugins}"

# Register a plugin
register_plugin() {
    local plugin_name="$1"
    local plugin_function="$2"
    local plugin_description="${3:-Custom assertion plugin}"
    local plugin_type="${4:-external}"

    if [[ -z "$plugin_name" || -z "$plugin_function" ]]; then
        log error "Plugin registration failed: name and function required"
        return 1
    fi

    if ! declare -f "$plugin_function" >/dev/null 2>&1; then
        log error "Plugin registration failed: function '$plugin_function' not found"
        return 1
    fi

    PLUGIN_REGISTRY["$plugin_name"]="$plugin_function"
    PLUGIN_DESCRIPTIONS["$plugin_name"]="$plugin_description"
    PLUGIN_TYPES["$plugin_name"]="$plugin_type"
    log debug "Registered $plugin_type plugin: $plugin_name -> $plugin_function"
    return 0
}

# Load embedded internal plugins (called during initialization)
load_internal_plugins() {
    log debug "Loading embedded internal plugins..."

    # Register internal plugins directly (these will be embedded in the final script)
    register_grpc_response_time_plugin
    register_asserts_plugin
    register_proto_plugin
    register_tls_plugin
    register_grpc_headers_trailers_plugin
    register_type_validation_plugin

    log info "Loaded ${#PLUGIN_REGISTRY[@]} internal plugins"
}

# Load external plugins from directory
load_external_plugins() {
    local plugin_dir="$1"

    if [[ -z "$plugin_dir" ]]; then
        plugin_dir="$EXTERNAL_PLUGIN_DIR"
    fi

    # Expand tilde
    plugin_dir=$(expand_tilde "$plugin_dir")

    if [[ ! -d "$plugin_dir" ]]; then
        log debug "External plugin directory not found: $plugin_dir"
        return 0
    fi

    log info "Loading external plugins from: $plugin_dir"

    # Source all .sh files in plugin directory
    local loaded_count=0
    for plugin_file in "$plugin_dir"/*.sh; do
        if [[ -f "$plugin_file" ]]; then
            log debug "Loading external plugin: $(basename "$plugin_file")"
            if source "$plugin_file"; then
                ((loaded_count++))
            else
                log error "Failed to load external plugin: $(basename "$plugin_file")"
            fi
        fi
    done

    log info "Loaded $loaded_count external plugins"
}

# Load all plugins (internal + external)
load_all_plugins() {
    load_internal_plugins
    load_external_plugins
}

# Execute plugin assertion
execute_plugin_assertion() {
    local plugin_name="$1"
    local response="$2"
    local header_name="$3"
    local expected_value="$4"
    local operation_type="$5"

    if [[ -z "${PLUGIN_REGISTRY[$plugin_name]:-}" ]]; then
        log error "Plugin not found: $plugin_name"
        log info "Available plugins: $(list_plugin_names)"
        return 1
    fi

    local plugin_function="${PLUGIN_REGISTRY[$plugin_name]}"
    local plugin_type="${PLUGIN_TYPES[$plugin_name]}"

    log debug "Executing $plugin_type plugin: $plugin_name with header: $header_name, value: $expected_value, operation: $operation_type"

    # Execute plugin function with appropriate arguments based on operation type
    case "$operation_type" in
        "equals"|"exists")
            if ! "$plugin_function" "$response" "$header_name" "$expected_value"; then
                log error "Plugin assertion failed: $plugin_name"
                return 1
            fi
            ;;
        "test")
            if ! "$plugin_function" "$response" "$header_name" "$expected_value"; then
                log error "Plugin pattern test failed: $plugin_name"
                return 1
            fi
            ;;
        "legacy")
            # Legacy format - pass header_name as args
            if ! "$plugin_function" "$response" "$header_name"; then
                log error "Plugin assertion failed: $plugin_name"
                return 1
            fi
            ;;
        *)
            log error "Unknown operation type: $operation_type"
            return 1
            ;;
    esac

    return 0
}

# Parse plugin assertion syntax: @plugin_name:args or @plugin_name("args") operation
parse_plugin_assertion() {
    local assertion_line="$1"

    # Support new function-style syntax: @header("name") == "value" or @trailer("name") | test("pattern")
    if [[ "$assertion_line" =~ ^@([a-zA-Z_][a-zA-Z0-9_]*)\(\"([^\"]*)\"\)[[:space:]]*(.*)$ ]]; then
        local plugin_name="${BASH_REMATCH[1]}"
        local header_name="${BASH_REMATCH[2]}"
        local operation="${BASH_REMATCH[3]}"

        # Parse operation type and expected value
        if [[ "$operation" =~ ^==[[:space:]]*\"([^\"]*)\"$ ]]; then
            # Equality check: @header("name") == "value"
            local expected_value="${BASH_REMATCH[1]}"
            echo "$plugin_name|$header_name|$expected_value|equals"
        elif [[ "$operation" =~ ^\|[[:space:]]*test\(\"([^\"]*)\"\)$ ]]; then
            # Pattern test: @header("name") | test("pattern")
            local pattern="${BASH_REMATCH[1]}"
            echo "test_$plugin_name|$header_name|$pattern|test"
        else
            # Simple existence check: @header("name")
            echo "$plugin_name|$header_name||exists"
        fi
        return 0
    fi

    # Support legacy colon syntax: @plugin_name:args
    if [[ "$assertion_line" =~ ^@([a-zA-Z_][a-zA-Z0-9_]*):(.+)$ ]]; then
        local plugin_name="${BASH_REMATCH[1]}"
        local plugin_args="${BASH_REMATCH[2]}"
        echo "$plugin_name|$plugin_args||legacy"
        return 0
    fi

    return 1
}

# Enhanced assertion evaluator with plugin support
evaluate_asserts_with_plugins() {
    local test_file="$1"
    local responses_array="$2"

    # Extract ASSERT sections
    local asserts_content=$(extract_asserts "$test_file" "ASSERTS")

    if [[ -z "$asserts_content" ]]; then
        return 0  # No asserts to evaluate
    fi

    # Create temporary file for asserts
    local asserts_file=$(mktemp)
    echo "$asserts_content" > "$asserts_file"

    # Load all plugins if not already loaded
    if [[ ${#PLUGIN_REGISTRY[@]} -eq 0 ]]; then
        load_all_plugins
    fi

    # Evaluate asserts against responses
    local response_count=$(echo "$responses_array" | jq 'length')

    if [[ $response_count -eq 1 ]]; then
        # Single response - apply asserts to it
        local response=$(echo "$responses_array" | jq -r '.[0]')
        if ! evaluate_asserts_enhanced "$response" "$asserts_file" 1; then
            rm -f "$asserts_file"
            return 1
        fi
    else
        # Multiple responses - apply asserts to each
        for i in $(seq 0 $((response_count - 1))); do
            local response=$(echo "$responses_array" | jq -r ".[$i]")
            if ! evaluate_asserts_enhanced "$response" "$asserts_file" $((i+1)); then
                rm -f "$asserts_file"
                return 1
            fi
        done
    fi

    # Cleanup
    rm -f "$asserts_file"
    return 0
}

# Enhanced assertion evaluator that supports both jq and plugins
evaluate_asserts_enhanced() {
    local response="$1"
    local asserts_file="$2"
    local response_index="$3"

    local line_number=0
    while IFS= read -r line; do
        line_number=$((line_number + 1))

        # Skip empty lines and comments
        if [[ -z "$line" || "$line" =~ ^[[:space:]]*# ]]; then
            continue
        fi

        # Check if it's a plugin assertion
        if plugin_info=$(parse_plugin_assertion "$line"); then
            IFS='|' read -r plugin_name header_name expected_value operation_type <<< "$plugin_info"

            if ! execute_plugin_assertion "$plugin_name" "$response" "$header_name" "$expected_value" "$operation_type"; then
                echo "ASSERTS block failed at line $line_number: $line"
                echo "Response: $response"
                return 1
            fi
        else
            # Standard jq filter
            if ! echo "$response" | jq -e "$line" >/dev/null 2>&1; then
                echo "ASSERTS block failed at line $line_number: $line"
                echo "Response: $response"
                return 1
            fi
        fi
    done < "$asserts_file"

    return 0
}

# List available plugins
list_plugins() {
    # Load all plugins first
    load_all_plugins

    if [[ ${#PLUGIN_REGISTRY[@]} -eq 0 ]]; then
        echo "No plugins registered"
        return 0
    fi

    echo "Available plugins:"
    for plugin_name in "${!PLUGIN_REGISTRY[@]}"; do
        local plugin_function="${PLUGIN_REGISTRY[$plugin_name]}"
        local plugin_description="${PLUGIN_DESCRIPTIONS[$plugin_name]}"
        local plugin_type="${PLUGIN_TYPES[$plugin_name]}"
        echo "  - $plugin_name ($plugin_type) -> $plugin_function"
        echo "    $plugin_description"
    done
}

# List plugin names only
list_plugin_names() {
    local names=()
    for plugin_name in "${!PLUGIN_REGISTRY[@]}"; do
        names+=("$plugin_name")
    done
    echo "${names[*]}"
}

# Plugin development helpers
create_plugin_template() {
    local plugin_name="$1"
    local plugin_file="$EXTERNAL_PLUGIN_DIR/${plugin_name}.sh"

    if [[ -z "$plugin_name" ]]; then
        log error "Plugin name required"
        return 1
    fi

    # Create plugin directory if it doesn't exist
    ensure_directory "$EXTERNAL_PLUGIN_DIR"

    # Create plugin template
    cat > "$plugin_file" << EOF
#!/bin/bash

# ${plugin_name}.sh - Custom assertion plugin
# Usage: @${plugin_name}:args

# Plugin function - must be named assert_${plugin_name}
assert_${plugin_name}() {
    local response="\$1"
    local args="\$2"

    # Parse arguments
    # Example: args could be "key=value,other=value2"

    # Your custom assertion logic here
    # Return 0 for success, 1 for failure

    log debug "Executing ${plugin_name} assertion with args: \$args"
    log debug "Response: \$response"

    # Example assertion - replace with your logic
    if [[ -n "\$response" ]]; then
        return 0
    else
        return 1
    fi
}

# Register the plugin
register_plugin "${plugin_name}" "assert_${plugin_name}" "Custom ${plugin_name} assertion" "external"
EOF

    chmod +x "$plugin_file"
    log success "Created external plugin template: $plugin_file"
    return 0
}

# Internal plugin registration functions (these will be embedded in the final script)

# Plugin registration functions (moved from individual plugin files for bashly embedding)

# Register Enhanced Asserts plugin
register_asserts_plugin() {
    register_plugin "asserts" "evaluate_enhanced_asserts" "Enhanced assertions with inline types" "internal"
}

# Register Proto plugin
register_proto_plugin() {
    register_plugin "proto" "parse_proto_section" "Proto contracts and descriptor files handler" "internal"
}

# Register TLS plugin
register_tls_plugin() {
    register_plugin "tls" "parse_tls_section" "TLS/mTLS configuration handler" "internal"
}

register_grpc_response_time_plugin() {
    # gRPC response time assertion plugin
    # Usage: @grpc_response_time:1000 (max milliseconds) or @grpc_response_time:500-2000 (range)

    assert_grpc_response_time() {
        local response="$1"
        local expected_time="$2"

        # Extract response time from response metadata or context
        local actual_time
        if actual_time=$(echo "$response" | jq -r '._response_time // .response_time // .duration // .time // empty' 2>/dev/null); then
            if [[ "$actual_time" == "null" || -z "$actual_time" ]]; then
                log error "Response time not found in gRPC response metadata"
                return 1
            fi
        else
            log error "Failed to parse gRPC response for response time"
            return 1
        fi

        # Parse expected time (support ranges like 500-2000)
        if [[ "$expected_time" =~ ^([0-9]+)-([0-9]+)$ ]]; then
            local min_time="${BASH_REMATCH[1]}"
            local max_time="${BASH_REMATCH[2]}"

            if [[ $actual_time -ge $min_time && $actual_time -le $max_time ]]; then
                log debug "gRPC response time $actual_time ms is in range $min_time-$max_time ms"
                return 0
            else
                log error "gRPC response time $actual_time ms is not in range $min_time-$max_time ms"
                return 1
            fi
        else
            # Single max time
            if [[ $actual_time -le $expected_time ]]; then
                log debug "gRPC response time $actual_time ms is within limit $expected_time ms"
                return 0
            else
                log error "gRPC response time $actual_time ms exceeds limit $expected_time ms"
                return 1
            fi
        fi
    }

    register_plugin "grpc_response_time" "assert_grpc_response_time" "gRPC response time assertion" "internal"
}

# Export functions for use in other modules
export -f register_plugin
export -f load_internal_plugins
export -f load_external_plugins
export -f load_all_plugins
export -f execute_plugin_assertion
export -f parse_plugin_assertion
export -f evaluate_asserts_with_plugins
export -f evaluate_asserts_enhanced
export -f list_plugins
export -f list_plugin_names
export -f create_plugin_template
export -f register_grpc_response_time_plugin
export -f register_asserts_plugin
export -f register_proto_plugin
export -f register_tls_plugin

# src/lib/core/plugin_template.sh
#!/bin/bash

# plugin_template.sh - Standardized plugin template
# Use this template for creating consistent plugins

# Standard plugin registration function
# Usage: register_standard_plugin "plugin_name" "main_function" "description"
register_standard_plugin() {
    local plugin_name="$1"
    local main_function="$2"

    local description="$3"
    local plugin_type="${4:-internal}"

    # Validate inputs
    if [[ -z "$plugin_name" || -z "$main_function" || -z "$description" ]]; then
        log error "Plugin registration requires: name, function, description"
        return 1
    fi

    # Check if function exists
    if ! declare -f "$main_function" >/dev/null 2>&1; then
        log error "Plugin function '$main_function' not found"
        return 1
    fi

    # Register the plugin
    register_plugin "$plugin_name" "$main_function" "$description" "$plugin_type"

    # Export the function
    export -f "$main_function"

    log debug "Registered $plugin_type plugin: $plugin_name"
}

# Standard assertion plugin template (SECURITY: no eval)
# Usage: create_assertion_plugin "name" - creates template file
create_assertion_plugin() {
    local plugin_name="$1"
    local plugin_file="${DEFAULT_PLUGIN_DIR}/grpc_${plugin_name}.sh"

    # Validate plugin name
    if [[ ! "$plugin_name" =~ ^[a-zA-Z_][a-zA-Z0-9_]*$ ]]; then
        log error "Invalid plugin name: $plugin_name"
        return 1
    fi

    # Validate and create plugin directory
    if ! validate_plugin_path "$plugin_file"; then
        return 1
    fi

    mkdir -p "$(dirname "$plugin_file")"

    # Generate plugin template file (safer than eval)
    cat > "$plugin_file" << EOF
#!/bin/bash

# Custom plugin: $plugin_name
# Generated by grpctestify plugin template

assert_${plugin_name}() {
    local response="\$1"
    local args="\$2"

    # Standard validation
    if [[ -z "\$response" ]]; then
        log error "${plugin_name}: Empty response"
        return 1
    fi

    # Add your plugin-specific logic here
    # Example:
    # local field_value=\$(echo "\$response" | jq -r '.your_field')
    # [[ "\$field_value" == "\$args" ]]

    return 0
}

# Plugin registration
register_plugin "${plugin_name}" "assert_${plugin_name}" "Custom $plugin_name assertion" "external"

EOF

    chmod 644 "$plugin_file"
    log success "Plugin template created: $plugin_file"
}

# Plugin metadata helper
set_plugin_metadata() {
    local plugin_name="$1"
    local version="$2"
    local author="$3"

    local version_var="PLUGIN_${plugin_name^^}_VERSION"
    local author_var="PLUGIN_${plugin_name^^}_AUTHOR"

    declare -g "$version_var"="$version"
    declare -g "$author_var"="$author"
}

# src/lib/core/progress.sh
#!/bin/bash

# progress.sh - Progress tracking utilities
# Simple progress tracking for test execution

# Progress tracking variables
PROGRESS_COUNT=0
PROGRESS_CURRENT_LINE_LENGTH=0
# Use PROGRESS_LINE_LENGTH from config.sh as max line length
PROGRESS_SUCCESS_COUNT=0
PROGRESS_FAILURE_COUNT=0
START_TIME="$(date +%s.%N)"

# Performance metrics
declare -a TEST_TIMES=()
TOTAL_RESPONSE_TIME=0
MAX_RESPONSE_TIME=0
MIN_RESPONSE_TIME=999999

# Record test performance
record_test_performance() {
    local test_time="$1"
    TEST_TIMES+=("$test_time")
    TOTAL_RESPONSE_TIME=$((TOTAL_RESPONSE_TIME + test_time))

    if (( test_time > MAX_RESPONSE_TIME )); then
        MAX_RESPONSE_TIME=$test_time
    fi

    if (( test_time < MIN_RESPONSE_TIME )); then
        MIN_RESPONSE_TIME=$test_time
    fi
}

print_progress() {
    local char="$1"
    local progress_mode="${2:-none}"

    if [[ "$progress_mode" == "dots" ]]; then
        printf "%s" "$char" >&2
        PROGRESS_COUNT=$((PROGRESS_COUNT + 1))
        PROGRESS_CURRENT_LINE_LENGTH=$((PROGRESS_CURRENT_LINE_LENGTH + 1))

        # Track success/failure counts
        if [[ "$char" == "." ]]; then
            PROGRESS_SUCCESS_COUNT=$((PROGRESS_SUCCESS_COUNT + 1))
        elif [[ "$char" == "F" ]]; then
            PROGRESS_FAILURE_COUNT=$((PROGRESS_FAILURE_COUNT + 1))
            printf "\n" >&2
            PROGRESS_CURRENT_LINE_LENGTH=0
        fi

        # Wrap at ~80 chars (but not for failures, they get their own line)
        if [[ $PROGRESS_CURRENT_LINE_LENGTH -ge $PROGRESS_LINE_LENGTH && "$char" != "F" ]]; then
            printf "\n" >&2
            PROGRESS_CURRENT_LINE_LENGTH=0
        fi
    fi
}

print_progress_summary() {
    local progress_mode="${1:-none}"

    if [[ "$progress_mode" == "dots" ]]; then
        printf "\n" >&2

        # Calculate elapsed time
        local end_time=$(date +%s.%N)
        local elapsed_time=$(echo "$end_time - $START_TIME" | bc -l 2>/dev/null || echo "0.00")

        # Print summary like Jest/pytest
        printf "Test Suites: " >&2
        if [[ $PROGRESS_FAILURE_COUNT -eq 0 ]]; then
            printf "${GREEN}1 passed${NC}" >&2
        else
            printf "${RED}1 failed${NC}" >&2
        fi
        printf ", 1 total\n" >&2

        printf "Tests:       " >&2
        if [[ $PROGRESS_FAILURE_COUNT -eq 0 ]]; then
            printf "${GREEN}%d passed${NC}" "$PROGRESS_SUCCESS_COUNT" >&2
        else
            printf "${RED}%d failed${NC}, ${GREEN}%d passed${NC}" "$PROGRESS_FAILURE_COUNT" "$PROGRESS_SUCCESS_COUNT" >&2
        fi
        printf ", %d total\n" "$PROGRESS_COUNT" >&2

        printf "Time:        %.2fs\n" "$elapsed_time" >&2

        # Show performance metrics if available
        if [[ $PROGRESS_COUNT -gt 0 && ${#TEST_TIMES[@]} -gt 0 ]]; then
            local avg_response_time=$((TOTAL_RESPONSE_TIME / PROGRESS_COUNT))
            printf "Performance: Avg: %dms, Min: %dms, Max: %dms\n" \
                "$avg_response_time" "$MIN_RESPONSE_TIME" "$MAX_RESPONSE_TIME" >&2
        fi

        # Add final status
        if [[ $PROGRESS_FAILURE_COUNT -eq 0 ]]; then
            printf "${GREEN}âœ“ All tests passed${NC}\n" >&2
        else
            printf "${RED}âœ— %d test(s) failed${NC}\n" "$PROGRESS_FAILURE_COUNT" >&2
        fi
    fi
}

# src/lib/core/report_generator.sh
#!/bin/bash

# report_generator.sh - Generate test reports
# Supports console output format

# Global report data structure

# Note: Using separate variables instead of associative arrays for broader compatibility
REPORT_DATA_start_time=""
REPORT_DATA_end_time=""
REPORT_DATA_total_tests=0
REPORT_DATA_passed_count=0
REPORT_DATA_failed_count=0
REPORT_DATA_timeout_count=0
REPORT_DATA_skipped_count=0
REPORT_DATA_total_duration=0
REPORT_DATA_hostname=""
REPORT_DATA_username=""
REPORT_DATA_grpctestify_version=""
REPORT_DATA_success_rate=0

# Arrays to store test results by category for detailed reporting
PASSED_TESTS=()
FAILED_TESTS=()
TIMEOUT_TESTS=()
SKIPPED_TESTS=()

# Initialize report data
init_report_data() {
    # shellcheck disable=SC2034  # Used in future versions
    REPORT_DATA_start_time=$(date -Iseconds)
    REPORT_DATA_total_tests=0
    REPORT_DATA_passed_count=0
    REPORT_DATA_failed_count=0
    REPORT_DATA_timeout_count=0
    REPORT_DATA_skipped_count=0
    REPORT_DATA_total_duration=0
    # shellcheck disable=SC2034  # Used in future versions
    REPORT_DATA_hostname=$(hostname)
    # shellcheck disable=SC2034  # Used in future versions
    REPORT_DATA_username=$(whoami)
    # shellcheck disable=SC2034  # Used in future versions
    REPORT_DATA_grpctestify_version="$APP_VERSION"

    # Reset all counters and arrays to initial state
    PASSED_TESTS=()
    FAILED_TESTS=()
    TIMEOUT_TESTS=()
    SKIPPED_TESTS=()
}

# Add test result to report data
add_test_result() {
    local test_file="$1"
    local status="$2"  # Test outcome: PASS/FAIL/TIMEOUT/SKIP
    local duration="${3:-0}"
    # shellcheck disable=SC2034  # Used in future versions
    local error_message="${4:-}"
    # shellcheck disable=SC2034  # Used in future versions
    local start_time="${5:-$(date -Iseconds)}"
    # shellcheck disable=SC2034  # Used in future versions
    local end_time="${6:-$(date -Iseconds)}"

    # shellcheck disable=SC2034  # Used in future versions
    local test_name
    test_name=$(basename "$test_file" .gctf)
    # shellcheck disable=SC2034  # Used in future versions
    local test_key="${test_file//\//_}"

    # Store individual test result (simplified - no detailed storage for now)

    # Update counters and arrays
    REPORT_DATA_total_tests=$((REPORT_DATA_total_tests + 1))
    REPORT_DATA_total_duration=$((REPORT_DATA_total_duration + duration))

    case "$status" in
        "PASS")
            REPORT_DATA_passed_count=$((REPORT_DATA_passed_count + 1))
            PASSED_TESTS+=("$test_file")
            ;;
        "FAIL")
            REPORT_DATA_failed_count=$((REPORT_DATA_failed_count + 1))
            FAILED_TESTS+=("$test_file")
            ;;
        "TIMEOUT")
            REPORT_DATA_timeout_count=$((REPORT_DATA_timeout_count + 1))
            TIMEOUT_TESTS+=("$test_file")
            ;;
        "SKIP")
            REPORT_DATA_skipped_count=$((REPORT_DATA_skipped_count + 1))
            SKIPPED_TESTS+=("$test_file")
            ;;
    esac
}

# Finalize report data
finalize_report_data() {
    # shellcheck disable=SC2034  # Used in future versions
    REPORT_DATA_end_time=$(date -Iseconds)

    # Calculate success rate
    local total=$REPORT_DATA_total_tests
    local passed=$REPORT_DATA_passed_count
    local success_rate=0

    if [[ $total -gt 0 ]]; then
        success_rate=$((passed * 100 / total))
    fi

    REPORT_DATA_success_rate=$success_rate
}

# Generate console report (default/existing format)
generate_console_report() {
    local output_file="${1:-}"

    # Skip console summary if already shown by show_summary function
    # Only show detailed sections (failed tests, etc.)

    # Show failed tests details
    if [[ ${#FAILED_TESTS[@]} -gt 0 ]]; then
        log section "Failed Tests"
        for test_file in "${FAILED_TESTS[@]}"; do
            log error "  âŒ $test_file"
        done
    fi

    # Show timeout tests details
    if [[ ${#TIMEOUT_TESTS[@]} -gt 0 ]]; then
        log section "Timeout Tests"
        for test_file in "${TIMEOUT_TESTS[@]}"; do
            log error "  â° $test_file"
        done
    fi

    # If output file specified, also write to file
    if [[ -n "$output_file" ]]; then
        {
            echo "=== gRPC Testify Report ==="
            echo "Generated: $(date)"
            echo "Total tests: $REPORT_DATA_total_tests"
            echo "Passed: $REPORT_DATA_passed_count"
            echo "Failed: $REPORT_DATA_failed_count"
            echo "Timeout: $REPORT_DATA_timeout_count"
            echo "Skipped: $REPORT_DATA_skipped_count"
            echo "Success rate: $REPORT_DATA_success_rate%"
            echo "Duration: ${REPORT_DATA_total_duration}ms"
            echo

            if [[ ${#FAILED_TESTS[@]} -gt 0 ]]; then
                echo "Failed Tests:"
                for test_file in "${FAILED_TESTS[@]}"; do
                    echo "  - $test_file"
                done
                echo
            fi

            if [[ ${#TIMEOUT_TESTS[@]} -gt 0 ]]; then
                echo "Timeout Tests:"
                for test_file in "${TIMEOUT_TESTS[@]}"; do
                    echo "  - $test_file"
                done
            fi
        } > "$output_file"

        log info "Console report written to: $output_file"
    fi
}

# Main report generation function
generate_report() {
    local format="${1:-console}"
    local output_file="${2:-}"

    # Finalize report data before generation
    finalize_report_data

    case "$format" in
        "console")
            generate_console_report "$output_file"
            ;;
        *)
            log error "Unknown report format: $format"
            log error "Supported formats: console"
            return 1
            ;;
    esac
}

# Export functions for use in other modules
export -f init_report_data
export -f add_test_result
export -f finalize_report_data
export -f generate_report
export -f generate_console_report

# src/lib/core/response_comparison.sh
#!/bin/bash

# response_comparison.sh - Response comparison utilities
# Handles comparison of gRPC responses with various options

# Compare responses with advanced options
compare_responses() {
    local expected="$1"
    local actual="$2"
    local options="${3:-}"

    # Parse options if provided
    local type="exact"
    local tolerance=""
    local tol_percent=""
    local partial="false"
    local redact=""
    local unordered_arrays="false"
    local unordered_arrays_paths=""

    if [[ -n "$options" ]]; then
        while IFS='=' read -r key value; do
            case "$key" in
                "type") type="$value" ;;
                "tolerance") tolerance="$value" ;;
                "tol_percent") tol_percent="$value" ;;
                "partial") partial="$value" ;;
                "redact") redact="$value" ;;
                "unordered_arrays") unordered_arrays="$value" ;;
                "unordered_arrays_paths") unordered_arrays_paths="$value" ;;
            esac
        done <<< "$options"
    fi

    # Apply redaction if specified
    if [[ -n "$redact" ]]; then
        local redact_paths="$(echo "$redact" | tr ',' ' ')"
        for path in $redact_paths; do
            expected="$(echo "$expected" | jq "del($path)")"
            actual="$(echo "$actual" | jq "del($path)")"
        done
    fi

    # Apply tolerance if specified
    if [[ -n "$tolerance" ]]; then
        if apply_tolerance_comparison "$expected" "$actual" "$tolerance"; then
            return 0
        fi
    fi

    # Apply percentage tolerance if specified
    if [[ -n "$tol_percent" ]]; then
        if apply_percentage_tolerance_comparison "$expected" "$actual" "$tol_percent"; then
            return 0
        fi
    fi

    # Apply unordered arrays normalization if specified
    if [[ "$unordered_arrays" == "true" ]]; then
        expected="$(echo "$expected" | jq -S .)"
        actual="$(echo "$actual" | jq -S .)"
    fi

    # Apply specific path unordered arrays normalization if specified
    if [[ -n "$unordered_arrays_paths" ]]; then
        local paths="$(echo "$unordered_arrays_paths" | tr ',' ' ')"
        for path in $paths; do
            expected="$(echo "$expected" | jq "$path |= sort")"
            actual="$(echo "$actual" | jq "$path |= sort")"
        done
    fi

    # Perform comparison based on type
    case "$type" in
        "exact")
            # Use jq to compare JSON responses if both are valid JSON
            if command -v jq >/dev/null 2>&1; then
                if echo "$actual" | jq . >/dev/null 2>&1 && echo "$expected" | jq . >/dev/null 2>&1; then
                    # Both are valid JSON, normalize and compare them (sort keys for order independence)
                    local normalized_actual="$(echo "$actual" | jq -S -c .)"
                    local normalized_expected="$(echo "$expected" | jq -S -c .)"

                    if [[ "$normalized_actual" == "$normalized_expected" ]]; then
                        return 0
                    else
                        return 1
                    fi
                fi
            fi

            # Fallback to string comparison
            if [[ "$actual" == "$expected" ]]; then
                return 0
            else
                return 1
            fi
            ;;
        "partial")
            # Check if expected is a subset of actual
            if command -v jq >/dev/null 2>&1; then
                if echo "$actual" | jq . >/dev/null 2>&1 && echo "$expected" | jq . >/dev/null 2>&1; then
                    # Use jq to check if expected is contained in actual
                    if jq -n --argjson actual "$actual" --argjson expected "$expected" \
                        '$actual | contains($expected)' | grep -q true; then
                        return 0
                    else
                        return 1
                    fi
                fi
            fi

            # Fallback to string containment
            if [[ "$actual" == *"$expected"* ]]; then
                return 0
            else
                return 1
            fi
            ;;
        *)
            log error "Unknown comparison type: $type"
            return 1
            ;;
    esac
}

# Apply tolerance comparison for numeric values
apply_tolerance_comparison() {
    local expected="$1"
    local actual="$2"
    local tolerance_spec="$3"

    # Parse tolerance specification: tolerance[path]=value
    if [[ "$tolerance_spec" =~ ^tolerance\[(.+)\]=(.+)$ ]]; then
        local path="${BASH_REMATCH[1]}"
        local tolerance_value="${BASH_REMATCH[2]}"

        # Extract expected and actual values at the specified path
        local expected_val="$(echo "$expected" | jq -r "$path // empty" 2>/dev/null)"
        local actual_val="$(echo "$actual" | jq -r "$path // empty" 2>/dev/null)"

        # Check if both values are numeric
        if [[ "$expected_val" =~ ^-?[0-9]+\.?[0-9]*$ ]] && [[ "$actual_val" =~ ^-?[0-9]+\.?[0-9]*$ ]]; then
            # Calculate absolute difference
            local diff="$(echo "$expected_val - $actual_val" | bc -l 2>/dev/null || echo "0")"
            local abs_diff="$(echo "$diff" | sed 's/^-//')"

            # Check if difference is within tolerance
            if (( $(echo "$abs_diff <= $tolerance_value" | bc -l) )); then
                return 0
            else
                log debug "Tolerance comparison failed for path $path: expected=$expected_val, actual=$actual_val, diff=$abs_diff, tolerance=$tolerance_value"
                return 1
            fi
        else
            log debug "Tolerance comparison skipped for path $path: non-numeric values (expected=$expected_val, actual=$actual_val)"
            return 0
        fi
    else
        log error "Invalid tolerance specification: $tolerance_spec"
        return 1
    fi
}

# Apply percentage tolerance comparison for numeric values
apply_percentage_tolerance_comparison() {
    local expected="$1"
    local actual="$2"
    local tol_percent_spec="$3"

    # Parse tolerance specification: tol_percent[path]=value
    if [[ "$tol_percent_spec" =~ ^tol_percent\[(.+)\]=(.+)$ ]]; then
        local path="${BASH_REMATCH[1]}"
        local tolerance_percent="${BASH_REMATCH[2]}"

        # Extract expected and actual values at the specified path
        local expected_val="$(echo "$expected" | jq -r "$path // empty" 2>/dev/null)"
        local actual_val="$(echo "$actual" | jq -r "$path // empty" 2>/dev/null)"

        # Check if both values are numeric
        if [[ "$expected_val" =~ ^-?[0-9]+\.?[0-9]*$ ]] && [[ "$actual_val" =~ ^-?[0-9]+\.?[0-9]*$ ]]; then
            # Calculate percentage difference
            local diff="$(echo "$expected_val - $actual_val" | bc -l 2>/dev/null || echo "0")"
            local abs_diff="$(echo "$diff" | sed 's/^-//')"
            local percent_diff="$(echo "scale=6; $abs_diff * 100 / $expected_val" | bc -l 2>/dev/null || echo "0")"

            # Check if percentage difference is within tolerance
            if (( $(echo "$percent_diff <= $tolerance_percent" | bc -l) )); then
                return 0
            else
                log debug "Percentage tolerance comparison failed for path $path: expected=$expected_val, actual=$actual_val, percent_diff=$percent_diff%, tolerance=$tolerance_percent%"
                return 1
            fi
        else
            log debug "Percentage tolerance comparison skipped for path $path: non-numeric values (expected=$expected_val, actual=$actual_val)"
            return 0
        fi
    else
        log error "Invalid percentage tolerance specification: $tol_percent_spec"
        return 1
    fi
}

# src/lib/core/runner.sh
#!/bin/bash

# runner.sh - Test execution logic
# Core test execution functionality

# Source response comparison utilities

run_grpc_call() {
    local address="$1"
    local endpoint="$2"
    local request="$3"
    local headers="$4"
    local proto_file="$5"

    # Build command array
    local cmd=("grpcurl" "-plaintext")

    if [[ -n "$proto_file" ]]; then
        cmd+=("-proto" "$proto_file")
    fi

    if [[ -n "$headers" ]]; then
        while IFS= read -r header; do
            if [[ -n "$header" ]]; then
                cmd+=("-H" "$header")
            fi
        done <<< "$headers"
    fi

    if [[ -n "$request" ]]; then
        cmd+=("-d" "$request")
    fi

    cmd+=("$address" "$endpoint")
    "${cmd[@]}" 2>&1
}

# Enhanced gRPC call with retry mechanism
run_grpc_call_with_retry() {
    local address="$1"
    local endpoint="$2"
    local request="$3"
    local headers="$4"
    local proto_file="$5"

    # Check if retry is disabled
    if is_no_retry; then
        log debug "Retry mechanism disabled, using direct gRPC call"
        run_grpc_call "$address" "$endpoint" "$request" "$headers" "$proto_file"
        return $?
    fi

    # Get retry configuration
    local max_retries="$(get_retry_count)"
    local retry_delay="$(get_retry_delay)"

    log debug "Using retry mechanism: max_retries=$max_retries, delay=${retry_delay}s"

    # Use the retry mechanism from error_recovery.sh
    retry_grpc_call "$address" "$endpoint" "$request" "$headers" "$max_retries"
}

compare_responses() {
    local expected="$1"
    local actual="$2"
    local options="$3"

    # Parse inline options
    local type="exact"
    local count="==1"
    local tolerance=""
    local tol_percent=""
    local redact=""
    local unordered_arrays="false"
    local unordered_arrays_paths=""
    local with_asserts="false"

    # Apply options if provided
    if [[ -n "$options" ]]; then
        while IFS='=' read -r key value; do
            case "$key" in
                "type")
                    type="$value"
                    ;;
                "count")
                    count="$value"
                    ;;
                "tolerance"*)
                    tolerance="$key=$value"
                    ;;
                "tol_percent"*)
                    tol_percent="$key=$value"
                    ;;
                "redact")
                    redact="$value"
                    ;;
                "unordered_arrays")
                    unordered_arrays="$value"
                    ;;
                "unordered_arrays_paths")
                    unordered_arrays_paths="$value"
                    ;;
                "with_asserts")
                    with_asserts="$value"
                    ;;
            esac
        done <<< "$options"
    fi

    # Apply redaction if specified
    if [[ -n "$redact" ]]; then
        local redact_paths="$(echo "$redact" | tr ',' ' ')"
        for path in $redact_paths; do
            expected="$(echo "$expected" | jq "del($path)")"
            actual="$(echo "$actual" | jq "del($path)")"
        done
    fi

    # Apply tolerance if specified
    if [[ -n "$tolerance" ]]; then
        if ! apply_tolerance_comparison "$expected" "$actual" "$tolerance"; then
            return 1
        fi
    fi

    # Apply percentage tolerance if specified
    if [[ -n "$tol_percent" ]]; then
        if ! apply_percentage_tolerance_comparison "$expected" "$actual" "$tol_percent"; then
            return 1
        fi
    fi

    # Apply unordered arrays normalization if specified
    if [[ "$unordered_arrays" == "true" ]]; then
        expected="$(echo "$expected" | jq -S .)"
        actual="$(echo "$actual" | jq -S .)"
    fi

    # Apply specific path unordered arrays normalization if specified
    if [[ -n "$unordered_arrays_paths" ]]; then
        local paths="$(echo "$unordered_arrays_paths" | tr ',' ' ')"
        for path in $paths; do
            expected="$(echo "$expected" | jq "$path |= sort")"
            actual="$(echo "$actual" | jq "$path |= sort")"
        done
    fi

    # Perform comparison based on type
    case "$type" in
        "exact")
            # Use jq to compare JSON responses if both are valid JSON
            if command -v jq >/dev/null 2>&1; then
                if echo "$actual" | jq . >/dev/null 2>&1 && echo "$expected" | jq . >/dev/null 2>&1; then
                    # Both are valid JSON, normalize and compare them (sort keys for order independence)
                    local normalized_actual="$(echo "$actual" | jq -S -c .)"
                    local normalized_expected="$(echo "$expected" | jq -S -c .)"

                    if [[ "$normalized_actual" == "$normalized_expected" ]]; then
                        return 0
                    else
                        return 1
                    fi
                fi
            fi

            # Fallback to string comparison
            if [[ "$expected" == "$actual" ]]; then
                return 0
            else
                return 1
            fi
            ;;
        "partial")
            # Check if all keys in expected exist in actual with same values
            if echo "$actual" | jq -e --argjson expected "$expected" 'contains($expected)' >/dev/null 2>&1; then
                return 0
            else
                return 1
            fi
            ;;
        *)
            log error "Unknown comparison type: $type"
            return 1
            ;;
    esac
}

run_test() {
    local test_file="$1"
    local progress_mode="${2:-none}"
    local test_name="$(basename "$test_file" .gctf)"

    log section "Test: $test_name"

    # Parse test file
    local test_data="$(parse_test_file "$test_file")"
    if [[ $? -ne 0 ]]; then
        handle_error $ERROR_VALIDATION "Failed to parse test file: $test_file"
        return 1
    fi

    # Extract test components
    local address=$(echo "$test_data" | jq -r '.address')
    local endpoint=$(echo "$test_data" | jq -r '.endpoint')
    local request=$(echo "$test_data" | jq -r '.request')
    local response=$(echo "$test_data" | jq -r '.response')
    local error=$(echo "$test_data" | jq -r '.error')
    local headers=$(echo "$test_data" | jq -r '.request_headers')

    # Validate required components
    if [[ -z "$endpoint" ]]; then
        handle_error $ERROR_VALIDATION "Missing ENDPOINT in $test_file"
        return 1
    fi

    # Check if we have ASSERTS (priority over RESPONSE)
    local asserts_content=$(extract_asserts "$test_file" "ASSERTS")

    if [[ -z "$response" && -z "$error" && -z "$asserts_content" ]]; then
        handle_error $ERROR_VALIDATION "Missing RESPONSE, ERROR, or ASSERTS in $test_file"
        return 1
    fi

    # Set default address if not provided
    if [[ -z "$address" ]]; then
        address="localhost:4770"
    fi

    # Check service availability before running test (if retry is enabled)
    if ! is_no_retry; then
        log debug "Checking service availability at $address"
        if ! check_service_health "$address"; then
            log warning "Service at $address is not available, attempting to wait for it..."
            if ! wait_for_service "$address" 30 2; then
                log error "Service at $address is not available after waiting"
                handle_network_failure "Service unavailable" "$test_file"

                return 1
            fi
        fi
    fi

    # Execute gRPC call with retry mechanism
    local start_time=$(date +%s%3N)
    local grpc_output
    local grpc_status

    # Use enhanced gRPC call with retry mechanism
    grpc_output=$(run_grpc_call_with_retry "$address" "$endpoint" "$request" "$headers" "")
    grpc_status=$?

    local end_time=$(date +%s%3N)
    local execution_time=$((end_time - start_time))

    # Handle network failures gracefully
    if [[ $grpc_status -ne 0 ]]; then
        handle_network_failure "$grpc_output" "$test_file"
    fi

    # Check if we have ASSERTS (highest priority - works with both success and error responses)
    local actual_array="[$grpc_output]"
    if evaluate_asserts_with_plugins "$test_file" "$actual_array" 2>/dev/null; then
        # ASSERTS passed - test successful (regardless of gRPC status)
        if [[ $grpc_status -ne 0 ]]; then
            log success "TEST PASSED: $test_name (expected error, $execution_time ms)"

        else
            log success "TEST PASSED: $test_name ($execution_time ms)"

        fi
        print_progress "." "$progress_mode"
        return 0
    fi

    # No ASSERTS or they failed, check gRPC status
    if [[ $grpc_status -ne 0 ]]; then
        if [[ -n "$error" ]]; then
            # Expected error case
            log success "TEST PASSED: $test_name (expected error, $execution_time ms)"
            print_progress "." "$progress_mode"

            return 0
        else
            # Unexpected error - use error recovery if available
            if declare -f handle_network_failure >/dev/null 2>&1; then
                handle_network_failure "$grpc_output" "$test_file" "0"
            else
                log error "gRPC request failed with status $grpc_status"
                log error "Response: $grpc_output"
            fi
            print_progress "F" "$progress_mode"

            return 1
        fi
    fi

    # Success case - check RESPONSE
    if [[ -n "$response" ]]; then
        # Extract RESPONSE header to get inline options
        local response_header=$(extract_section_header "$test_file" "RESPONSE")
        local response_options=$(parse_inline_options "$response_header")

        if compare_responses "$response" "$grpc_output" "$response_options"; then
            # Check if with_asserts is enabled
            local with_asserts="false"
            if [[ -n "$response_options" ]]; then
                while IFS='=' read -r key value; do
                    if [[ "$key" == "with_asserts" ]]; then
                        with_asserts="$value"
                        break
                    fi
                done <<< "$response_options"
            fi

            # If with_asserts is enabled, run ASSERTS on the same response
            if [[ "$with_asserts" == "true" && -n "$asserts_content" ]]; then
                local actual_array="[$grpc_output]"
                if ! evaluate_asserts_with_plugins "$test_file" "$actual_array" 2>/dev/null; then
                    log error "TEST FAILED: $test_name - ASSERTS failed ($execution_time ms)"
                    print_progress "F" "$progress_mode"
                    return 1
                fi
            fi

            log success "TEST PASSED: $test_name ($execution_time ms)"
            print_progress "." "$progress_mode"

            return 0
        else
            log error "TEST FAILED: $test_name ($execution_time ms)"
            log error "--- Expected ---"
            printf "%s\n" "$response"
            log error "+++ Actual +++"
            printf "%s\n" "$grpc_output"
            print_progress "F" "$progress_mode"

            return 1
        fi
    else
        # No RESPONSE and no ASSERTS - test passes (no validation)
        log success "TEST PASSED: $test_name ($execution_time ms)"
        print_progress "." "$progress_mode"

        return 0
    fi

    return 0
}

# Apply tolerance comparison for numeric values
apply_tolerance_comparison() {
    local expected="$1"
    local actual="$2"
    local tolerance_spec="$3"

    # Parse tolerance specification: tolerance[path]=value
    if [[ "$tolerance_spec" =~ ^tolerance\[(.+)\]=(.+)$ ]]; then
        local path="${BASH_REMATCH[1]}"
        local tolerance_value="${BASH_REMATCH[2]}"

        # Extract expected and actual values at the specified path
        local expected_val=$(echo "$expected" | jq -r "$path // empty" 2>/dev/null)
        local actual_val=$(echo "$actual" | jq -r "$path // empty" 2>/dev/null)

        # Check if both values are numeric
        if [[ "$expected_val" =~ ^-?[0-9]+\.?[0-9]*$ ]] && [[ "$actual_val" =~ ^-?[0-9]+\.?[0-9]*$ ]]; then
            # Calculate absolute difference
            local diff=$(echo "$expected_val - $actual_val" | bc -l 2>/dev/null || echo "0")
            local abs_diff=$(echo "$diff" | sed 's/^-//')

            # Check if difference is within tolerance
            if (( $(echo "$abs_diff <= $tolerance_value" | bc -l) )); then
                return 0
            else
                log debug "Tolerance comparison failed for path $path: expected=$expected_val, actual=$actual_val, diff=$abs_diff, tolerance=$tolerance_value"
                return 1
            fi
        else
            log debug "Tolerance comparison skipped for path $path: non-numeric values (expected=$expected_val, actual=$actual_val)"
            return 0
        fi
    else
        log error "Invalid tolerance specification: $tolerance_spec"
        return 1
    fi
}

# Apply percentage tolerance comparison for numeric values
apply_percentage_tolerance_comparison() {
    local expected="$1"
    local actual="$2"
    local tol_percent_spec="$3"

    # Parse tolerance specification: tol_percent[path]=value
    if [[ "$tol_percent_spec" =~ ^tol_percent\[(.+)\]=(.+)$ ]]; then
        local path="${BASH_REMATCH[1]}"
        local tolerance_percent="${BASH_REMATCH[2]}"

        # Extract expected and actual values at the specified path
        local expected_val=$(echo "$expected" | jq -r "$path // empty" 2>/dev/null)
        local actual_val=$(echo "$actual" | jq -r "$path // empty" 2>/dev/null)

        # Check if both values are numeric
        if [[ "$expected_val" =~ ^-?[0-9]+\.?[0-9]*$ ]] && [[ "$actual_val" =~ ^-?[0-9]+\.?[0-9]*$ ]]; then
            # Calculate percentage difference
            local diff=$(echo "$expected_val - $actual_val" | bc -l 2>/dev/null || echo "0")
            local abs_diff=$(echo "$diff" | sed 's/^-//')
            local percent_diff=$(echo "scale=6; $abs_diff * 100 / $expected_val" | bc -l 2>/dev/null || echo "0")

            # Check if percentage difference is within tolerance
            if (( $(echo "$percent_diff <= $tolerance_percent" | bc -l) )); then
                return 0
            else
                log debug "Percentage tolerance comparison failed for path $path: expected=$expected_val, actual=$actual_val, diff=$percent_diff%, tolerance=$tolerance_percent%"
                return 1
            fi
        else
            log debug "Percentage tolerance comparison skipped for path $path: non-numeric values (expected=$expected_val, actual=$actual_val)"
            return 0
        fi
    else
        log error "Invalid percentage tolerance specification: $tol_percent_spec"
        return 1
    fi
}

# src/lib/core/utils.sh
#!/bin/bash

# utils.sh - Shared utility functions
# Common functions used across multiple modules

# Process line with comment and quote handling
process_line() {
    local line="$1"
    local in_str=0
    local escaped=0
    local res=""

    for ((i=1; i<=${#line}; i++)); do
        local c="${line:$((i-1)):1}"
        if ((escaped)); then
            res+="$c"
            escaped=0
        elif [[ "$c" == "\\" ]]; then
            res+="$c"
            escaped=1
        elif [[ "$c" == "\"" ]]; then
            res+="$c"
            in_str=$((!in_str))
        elif [[ "$c" == "#" && $in_str -eq 0 ]]; then
            break
        else
            res+="$c"
        fi
    done

    echo "$res"
}

# Extract section from test file using awk
# This is a complex parser that:
# 1. Finds sections delimited by "--- SECTION_NAME ---"
# 2. Handles comments (# characters) properly inside and outside quoted strings
# 3. Processes escape sequences and quoted strings correctly
# 4. Strips comments while preserving quoted content
extract_section_awk() {
    local test_file="$1"
    local section="$2"

    awk -v sec="$section" '
    # Smart comment removal: processes line character-by-character to handle quotes correctly
    function process_line(line) {
        in_str = 0
        escaped = 0
        res = ""
        for (i = 1; i <= length(line); i++) {
            c = substr(line, i, 1)
            if (escaped) {
                res = res c
                escaped = 0
            } else if (c == "\\") {
                res = res c
                escaped = 1
            } else if (c == "\"") {
                res = res c
                in_str = !in_str
            } else if (c == "#" && !in_str) {
                break
            } else {
                res = res c
            }
        }
        return res
    }
    $0 ~ /^[[:space:]]*#/ { next }
    $0 ~ "^[[:space:]]*---[[:space:]]*" sec "([[:space:]]+.*)?[[:space:]]*---" {

        found=1
        # Capture the full line for modifier detection
        modifier_line = $0
        next

    }

    /^[[:space:]]*---/ {

        found=0

    }

    found {
        processed = process_line($0)
        gsub(/^[[:space:]]*/, "", processed)
        gsub(/[[:space:]]*$/, "", processed)
        if (processed != "") {
            printf "%s\n", processed
        }
    }' "$test_file"
}

# Extract section header (the --- SECTION_NAME ... --- line itself)
extract_section_header() {
    local test_file="$1"
    local section="$2"

    grep -n "^[[:space:]]*---[[:space:]]*${section}" "$test_file" | head -1 | cut -d: -f2-
}

# JSON validation is handled by validation.sh module

# Sanitize string for safe usage
sanitize_string() {
    local input="$1"
    # Remove control characters and normalize whitespace
    echo "$input" | tr -d '\000-\037' | sed 's/[[:space:]]\+/ /g' | sed 's/^[[:space:]]*//;s/[[:space:]]*$//'
}

# Check if command exists
command_exists() {
    local cmd="$1"
    command -v "$cmd" >/dev/null 2>&1
}

# Get current timestamp
get_timestamp() {
    date '+%Y-%m-%d %H:%M:%S'
}

# Create directory if it doesn't exist
ensure_directory() {
    local dir="$1"
    if [[ ! -d "$dir" ]]; then
        mkdir -p "$dir" || return 1
    fi
    return 0
}

# Get file extension
get_file_extension() {
    local file="$1"
    echo "${file##*.}"
}

# Trim leading and trailing whitespace
trim_whitespace() {
    local str="$1"
    echo "$str" | sed 's/^[[:space:]]*//;s/[[:space:]]*$//'
}

# Expand tilde in path to home directory
expand_tilde() {
    local path="$1"
    echo "${path/#\~/$HOME}"
}

# Unused error functions removed

# Unused utility functions removed

# src/lib/core/validation.sh
#!/bin/bash

# validation.sh - Input validation utilities
# Simple, clear validation functions

validate_address() {
    local address="$1"
    # Validate address format: hostname:port (e.g., localhost:4770, api.example.com:443)
    if ! echo "$address" | grep -qE '^[a-zA-Z0-9.-]+:[0-9]+$'; then
        handle_error ${ERROR_VALIDATION:-7} "Invalid ADDRESS format: $address" "validate_address"
        return ${ERROR_VALIDATION:-7}
    fi
    return 0
}

validate_json() {
    local json="$1"
    local context="$2"

    if ! echo "$json" | jq empty 2>/dev/null; then
        handle_error ${ERROR_VALIDATION:-7} "Invalid JSON in $context section" "validate_json"
        return ${ERROR_VALIDATION:-7}
    fi
    return 0
}

validate_file_exists() {
    local file="$1"

    if [[ ! -f "$file" ]]; then
        handle_error ${ERROR_FILE_NOT_FOUND:-3} "File not found: $file" "validate_file_exists"
        return ${ERROR_FILE_NOT_FOUND:-3}
    fi
    return 0
}

validate_directory_exists() {
    local dir="$1"

    if [[ ! -d "$dir" ]]; then
        log error "Directory not found: $dir"
        return 1
    fi
    return 0
}

validate_positive_integer() {
    local value="$1"
    local name="$2"

    if ! [[ "$value" =~ ^[0-9]+$ ]] || [[ "$value" -lt 1 ]]; then
        echo "Error: $name must be a positive integer, got: $value" >&2
        return 1
    fi
    return 0
}

validate_endpoint() {
    local endpoint="$1"
    # Validate gRPC endpoint format: package.Service/Method (e.g., grpc.health.v1.Health/Check)
    if ! echo "$endpoint" | grep -qE '^[a-zA-Z0-9.]+/[a-zA-Z0-9]+$'; then
        log error "Invalid ENDPOINT format: $endpoint"
        return 1
    fi
    return 0
}

validate_parallel_jobs() {
    local jobs="$1"
    validate_positive_integer "$jobs" "Parallel jobs"
}

validate_progress_mode() {
    local mode="$1"
    case "$mode" in
        "none"|"dots")
            return 0
            ;;
        *)
            log error "Invalid progress mode: $mode (must be none or dots)"
            return 1
            ;;
    esac
}

validate_test_file() {
    local file="$1"

    if [[ ! -e "$file" ]]; then
        log error "Test file does not exist: $file"
        return 1
    fi

    if [[ ! "$file" =~ \.gctf$ ]]; then
        log error "Test file must have .gctf extension: $file"
        return 1
    fi

    return 0
}

# Dependencies are now handled by bashly configuration

# src/lib/plugins/grpc_asserts.sh
#!/bin/bash

# Enhanced Asserts Plugin for grpctestify
# Handles advanced assertion types including indexed assertions

# Function to register Enhanced Asserts plugin
register_asserts_plugin() {
    register_plugin "asserts" "evaluate_enhanced_asserts" "Enhanced assertions with inline types" "internal"
}

# Function to evaluate enhanced assertions
evaluate_enhanced_asserts() {
    local test_file="$1"
    local responses_array="$2"

    # Extract ASSERTS section using existing utility
    local asserts_section
    asserts_section="$(extract_asserts "$test_file" "ASSERTS")"

    if [[ -z "$asserts_section" ]]; then
        return 0  # No asserts to evaluate
    fi

    # Process enhanced assertions
    process_enhanced_asserts "$asserts_section" "$responses_array"
}

# Function to process enhanced assertions with inline types
process_enhanced_asserts() {
    local asserts_section="$1"
    local responses_array="$2"
    local line_number=0

    while IFS= read -r line; do
        line_number=$((line_number + 1))

        # Skip empty lines and comments
        if [[ -z "$line" || "$line" =~ ^[[:space:]]*# ]]; then
            continue
        fi

        # Process different assertion types
        if [[ "$line" =~ ^\[([0-9*]+)\][[:space:]]+(.+)$ ]]; then
            # Indexed assertion: [index] assertion
            process_indexed_assertion "${BASH_REMATCH[1]}" "${BASH_REMATCH[2]}" "$responses_array" "$line_number"
        elif [[ "$line" =~ ^@([a-zA-Z_][a-zA-Z0-9_]*):(.+)$ ]]; then
            # Plugin assertion: @plugin_name:args
            process_plugin_assertion "${BASH_REMATCH[1]}" "${BASH_REMATCH[2]}" "$responses_array" "$line_number"
        # type:typename syntax removed - use @typename() plugins instead
        elif [[ "$line" =~ ^\[([0-9*]+)\]@([a-zA-Z_][a-zA-Z0-9_]*):(.+)$ ]]; then
            # Indexed plugin assertion: [index]@plugin_name:args
            process_indexed_plugin_assertion "${BASH_REMATCH[1]}" "${BASH_REMATCH[2]}" "${BASH_REMATCH[3]}" "$responses_array" "$line_number"
        # [index]type:typename syntax removed - use @typename() plugins instead
        else
            # Regular jq assertion
            process_regular_assertion "$line" "$responses_array" "$line_number"
        fi
    done <<< "$asserts_section"
}

# Function to process indexed assertion
process_indexed_assertion() {
    local index="$1"
    local assertion="$2"
    local responses_array="$3"
    local line_number="$4"

    if [[ "$index" == "*" ]]; then
        # Apply to all responses
        local response_count=$(echo "$responses_array" | jq 'length')
        for i in $(seq 0 $((response_count - 1))); do
            local response=$(echo "$responses_array" | jq -r ".[$i]")
            if ! evaluate_single_assertion "$assertion" "$response"; then
                echo "ASSERTS failed at line $line_number (response $((i+1))): $assertion"
                echo "Response: $response"
                return 1
            fi
        done
    else
        # Apply to specific response (1-based index)
        local response_index=$((index - 1))
        local response_count=$(echo "$responses_array" | jq 'length')

        if [[ $response_index -ge 0 && $response_index -lt $response_count ]]; then
            local response=$(echo "$responses_array" | jq -r ".[$response_index]")
            if ! evaluate_single_assertion "$assertion" "$response"; then
                echo "ASSERTS failed at line $line_number (response $((response_index+1))): $assertion"
                echo "Response: $response"
                return 1
            fi
        else
            echo "ASSERTS failed at line $line_number: Invalid index $index (available: 1-$response_count)"
            return 1
        fi
    fi
}

# Function to process plugin assertion
process_plugin_assertion() {
    local plugin_name="$1"
    local args="$2"
    local responses_array="$3"
    local line_number="$4"

    # Get the first response for plugin evaluation
    local response=$(echo "$responses_array" | jq -r '.[0]')

    if ! execute_plugin_assertion "$plugin_name" "$response" "$args"; then
        echo "ASSERTS failed at line $line_number: @$plugin_name:$args"
        echo "Response: $response"
        return 1
    fi
}

# type:typename functions removed - use @typename() plugins instead

# Function to process indexed plugin assertion
process_indexed_plugin_assertion() {
    local index="$1"
    local plugin_name="$2"
    local args="$3"
    local responses_array="$4"
    local line_number="$5"

    if [[ "$index" == "*" ]]; then
        # Apply to all responses
        local response_count=$(echo "$responses_array" | jq 'length')
        for i in $(seq 0 $((response_count - 1))); do
            local response=$(echo "$responses_array" | jq -r ".[$i]")
            if ! execute_plugin_assertion "$plugin_name" "$response" "$args"; then
                echo "ASSERTS failed at line $line_number (response $((i+1))): [$index]@$plugin_name:$args"
                echo "Response: $response"
                return 1
            fi
        done
    else
        # Apply to specific response (1-based index)
        local response_index=$((index - 1))
        local response_count=$(echo "$responses_array" | jq 'length')

        if [[ $response_index -ge 0 && $response_index -lt $response_count ]]; then
            local response=$(echo "$responses_array" | jq -r ".[$response_index]")
            if ! execute_plugin_assertion "$plugin_name" "$response" "$args"; then
                echo "ASSERTS failed at line $line_number (response $((response_index+1))): [$index]@$plugin_name:$args"
                echo "Response: $response"
                return 1
            fi
        else
            echo "ASSERTS failed at line $line_number: Invalid index $index (available: 1-$response_count)"
            return 1
        fi
    fi
}

# process_indexed_type_assertion removed - use @typename() plugins instead

# Function to process regular assertion
process_regular_assertion() {
    local assertion="$1"
    local responses_array="$2"
    local line_number="$3"

    # Get the first response for regular assertion
    local response=$(echo "$responses_array" | jq -r '.[0]')

    if ! evaluate_single_assertion "$assertion" "$response"; then
        echo "ASSERTS failed at line $line_number: $assertion"
        echo "Response: $response"
        return 1
    fi
}

# Function to evaluate single assertion
evaluate_single_assertion() {
    local assertion="$1"
    local response="$2"

    # Check if it's a jq filter
    if echo "$response" | jq -e "$assertion" >/dev/null 2>&1; then
        return 0
    else
        return 1
    fi
}

# Function to execute plugin assertion
execute_plugin_assertion() {
    local plugin_name="$1"
    local response="$2"
    local args="$3"

    # Get plugin function
    local plugin_func=$(get_plugin_function "$plugin_name")
    if [[ -n "$plugin_func" ]]; then
        if $plugin_func "$response" "$args"; then
            return 0
        else
            return 1
        fi
    else
        echo "Plugin $plugin_name not found"
        return 1
    fi
}

# evaluate_type_assertion removed - use @typename() plugins instead

# Export functions
export -f register_asserts_plugin
export -f evaluate_enhanced_asserts
export -f process_enhanced_asserts
export -f process_indexed_assertion
export -f process_plugin_assertion
export -f process_indexed_plugin_assertion
export -f process_regular_assertion
export -f evaluate_single_assertion
export -f execute_plugin_assertion

# Register the plugin
register_asserts_plugin

# src/lib/plugins/grpc_headers_trailers.sh
#!/bin/bash

# grpc_headers_trailers.sh - gRPC headers and trailers assertion plugin
# Usage: @header("name") == "value" or @trailer("name") | test("pattern")

# Function to assert gRPC response headers
assert_grpc_header() {
    local response="$1"
    local header_name="$2"
    local expected_value="$3"

    # Extract headers from gRPC response metadata
    # Headers are typically in the response metadata or context
    local actual_value
    if actual_value=$(echo "$response" | jq -r "._headers.\"$header_name\" // .headers.\"$header_name\" // .metadata.\"$header_name\" // empty" 2>/dev/null); then
        if [[ "$actual_value" == "null" || -z "$actual_value" ]]; then
            log error "Header '$header_name' not found in gRPC response"
            return 1
        fi
    else
        log error "Failed to parse gRPC response for header '$header_name'"
        return 1
    fi

    # Compare with expected value
    if [[ "$actual_value" == "$expected_value" ]]; then
        log debug "Header '$header_name' matches expected value: $expected_value"
        return 0
    else
        log error "Header '$header_name' mismatch - expected: '$expected_value', actual: '$actual_value'"
        return 1
    fi
}

# Function to assert gRPC response trailers
assert_grpc_trailer() {
    local response="$1"
    local trailer_name="$2"
    local expected_value="$3"

    # Extract trailers from gRPC response metadata
    # Trailers are typically in the response metadata or context
    local actual_value
    if actual_value=$(echo "$response" | jq -r "._trailers.\"$trailer_name\" // .trailers.\"$trailer_name\" // .metadata.\"$trailer_name\" // empty" 2>/dev/null); then
        if [[ "$actual_value" == "null" || -z "$actual_value" ]]; then
            log error "Trailer '$trailer_name' not found in gRPC response"
            return 1
        fi
    else
        log error "Failed to parse gRPC response for trailer '$trailer_name'"
        return 1
    fi

    # Compare with expected value
    if [[ "$actual_value" == "$expected_value" ]]; then
        log debug "Trailer '$trailer_name' matches expected value: $expected_value"
        return 0
    else
        log error "Trailer '$trailer_name' mismatch - expected: '$expected_value', actual: '$actual_value'"
        return 1
    fi
}

# Function to register gRPC Headers/Trailers plugin
register_grpc_headers_trailers_plugin() {
    register_plugin "header" "assert_grpc_header" "gRPC response header assertion" "internal"
    register_plugin "trailer" "assert_grpc_trailer" "gRPC response trailer assertion" "internal"

}

# Export functions
export -f register_grpc_headers_trailers_plugin
export -f assert_grpc_header
export -f assert_grpc_trailer

# src/lib/plugins/grpc_proto.sh
#!/bin/bash

# Proto Plugin for grpctestify
# Handles proto contracts and descriptor files configuration

# Proto state management - using local variables to avoid race conditions

# Function to register Proto plugin
register_proto_plugin() {
    register_plugin "proto" "parse_proto_section" "Proto contracts and descriptor files handler" "internal"
}

# Function to parse Proto section from .gctf file
parse_proto_section() {
    local test_file="$1"
    local proto_section=""
    local in_proto_section=false

    # Reset Proto state
    PROTO_MODE=""
    PROTO_FLAGS=""
    PROTO_FILES=""
    PROTO_DESCRIPTOR=""
    PROTO_IMPORT_PATHS=""

    # Parse Proto section from file
    while IFS= read -r line; do
        if [[ "$line" =~ ^---[[:space:]]*PROTO[[:space:]]*--- ]]; then
            in_proto_section=true
            continue
        elif [[ "$line" =~ ^---[[:space:]]*[A-Z]+[[:space:]]*--- ]]; then
            in_proto_section=false
            continue
        elif [[ "$in_proto_section" == true ]]; then
            proto_section+="$line"$'\n'
        fi
    done < "$test_file"

    if [[ -n "$proto_section" ]]; then
        process_proto_configuration "$proto_section"
    else
        # Default behavior: gRPC reflection
        PROTO_MODE="reflection"
        PROTO_FLAGS=""
    fi
}

# Function to process Proto configuration
process_proto_configuration() {
    local config="$1"
    local mode=""
    local files=""
    local descriptor=""
    local import_paths=""

    # Parse key=value pairs
    while IFS= read -r line; do
        line=$(echo "$line" | sed 's/^[[:space:]]*//;s/[[:space:]]*$//')
        [[ -z "$line" || "$line" =~ ^# ]] && continue

        if [[ "$line" =~ ^([^=]+)=(.*)$ ]]; then
            local key_name="${BASH_REMATCH[1]}"
            local value="${BASH_REMATCH[2]}"

            case "$key_name" in
                "mode")
                    mode="$value"
                    ;;
                "files")
                    files="$value"
                    ;;
                "descriptor")
                    descriptor="$value"
                    ;;
                "import_paths")
                    import_paths="$value"
                    ;;
            esac
        fi
    done <<< "$config"

    # Determine mode if not specified
    if [[ -z "$mode" ]]; then
        if [[ -n "$descriptor" ]]; then
            mode="descriptor"
        elif [[ -n "$files" ]]; then
            mode="proto"
        else
            mode="reflection"
        fi
    fi

    # Validate configuration
    validate_proto_configuration "$mode" "$files" "$descriptor"

    # Generate Proto flags
    generate_proto_flags "$mode" "$files" "$descriptor" "$import_paths"
}

# Function to validate Proto configuration
validate_proto_configuration() {
    local mode="$1"
    local files="$2"
    local descriptor="$3"

    case "$mode" in
        "reflection")
            # No validation needed for reflection mode
            ;;
        "proto")
            if [[ -z "$files" ]]; then
                error "Proto mode requires files parameter"
                exit 1
            fi
            ;;
        "descriptor")
            if [[ -z "$descriptor" ]]; then
                error "Descriptor mode requires descriptor parameter"
                exit 1
            fi
            ;;
        *)
            error "Invalid proto mode: $mode. Valid modes: reflection, proto, descriptor"
            exit 1
            ;;
    esac
}

# Function to generate Proto flags
generate_proto_flags() {
    local mode="$1"
    local files="$2"
    local descriptor="$3"
    local import_paths="$4"

    PROTO_MODE="$mode"
    PROTO_FLAGS=""
    PROTO_FILES="$files"
    PROTO_DESCRIPTOR="$descriptor"
    PROTO_IMPORT_PATHS="$import_paths"

    case "$mode" in
        "reflection")
            # No additional flags needed for reflection
            PROTO_FLAGS=""
            ;;
        "proto")
            # Add proto files
            if [[ -n "$files" ]]; then
                # Support multiple files separated by comma or space
                local file_list=$(echo "$files" | tr ',' ' ')
                for file in $file_list; do
                    file=$(echo "$file" | sed 's/^[[:space:]]*//;s/[[:space:]]*$//')
                    if [[ -n "$file" ]]; then
                        PROTO_FLAGS+=" -proto $file"
                    fi
                done
            fi

            # Add import paths
            if [[ -n "$import_paths" ]]; then
                local path_list=$(echo "$import_paths" | tr ',' ' ')
                for path in $path_list; do
                    path=$(echo "$path" | sed 's/^[[:space:]]*//;s/[[:space:]]*$//')
                    if [[ -n "$path" ]]; then
                        PROTO_FLAGS+=" -import-path $path"
                    fi
                done
            fi
            ;;
        "descriptor")
            # Add descriptor file
            if [[ -n "$descriptor" ]]; then
                PROTO_FLAGS+=" -proto $descriptor"
            fi
            ;;
    esac

    # Trim leading space
    PROTO_FLAGS=$(echo "$PROTO_FLAGS" | sed 's/^[[:space:]]*//')
}

# Function to resolve proto paths (support ENV variables)
resolve_proto_path() {
    local path="$1"

    # If path starts with $, treat as ENV variable
    if [[ "$path" =~ ^\$([A-Z_][A-Z0-9_]*) ]]; then
        local env_var="${BASH_REMATCH[1]}"
        if [[ -n "${!env_var}" ]]; then
            echo "${!env_var}"
        else
            error "Environment variable $env_var is not set"
            exit 1
        fi
    else
        echo "$path"
    fi
}

# Function to get Proto summary for verbose logging
get_proto_summary() {
    local flag_count=$(echo "$PROTO_FLAGS" | wc -w)
    echo "mode=$PROTO_MODE, flags=$flag_count"
}

# Function to get Proto flags for grpcurl
get_proto_flags() {
    echo "$PROTO_FLAGS"
}

# Function to get Proto mode
get_proto_mode() {
    echo "$PROTO_MODE"
}

# Function to get Proto files
get_proto_files() {
    echo "$PROTO_FILES"
}

# Function to get Proto descriptor
get_proto_descriptor() {
    echo "$PROTO_DESCRIPTOR"
}

# Function to get Proto import paths
get_proto_import_paths() {
    echo "$PROTO_IMPORT_PATHS"
}

# Export functions
export -f register_proto_plugin
export -f parse_proto_section
export -f process_proto_configuration
export -f validate_proto_configuration
export -f generate_proto_flags
export -f resolve_proto_path
export -f get_proto_summary
export -f get_proto_flags
export -f get_proto_mode
export -f get_proto_files
export -f get_proto_descriptor
export -f get_proto_import_paths

# Register the plugin
register_proto_plugin

# src/lib/plugins/grpc_response_time.sh
#!/bin/bash

# grpc_response_time.sh - gRPC response time assertion plugin
# Usage: @grpc_response_time:1000 (max milliseconds) or @grpc_response_time:500-2000 (range)

assert_grpc_response_time() {
    local response="$1"
    local expected_time="$2"

    # For gRPC, response time is typically measured by the runner and passed as metadata
    # Extract response time from response metadata or context
    local actual_time
    if actual_time=$(echo "$response" | jq -r '._response_time // .response_time // .duration // .time // empty' 2>/dev/null); then
        if [[ "$actual_time" == "null" || -z "$actual_time" ]]; then
            log error "Response time not found in gRPC response metadata"
            return 1
        fi
    else
        log error "Failed to parse gRPC response for response time"
        return 1
    fi

    # Parse expected time (support ranges like 500-2000)
    if [[ "$expected_time" =~ ^([0-9]+)-([0-9]+)$ ]]; then
        local min_time="${BASH_REMATCH[1]}"
        local max_time="${BASH_REMATCH[2]}"

        if [[ $actual_time -ge $min_time && $actual_time -le $max_time ]]; then
            log debug "gRPC response time $actual_time ms is in range $min_time-$max_time ms"
            return 0
        else
            log error "gRPC response time $actual_time ms is not in range $min_time-$max_time ms"
            return 1
        fi
    else
        # Single max time
        if [[ $actual_time -le $expected_time ]]; then
            log debug "gRPC response time $actual_time ms is within limit $expected_time ms"
            return 0
        else
            log error "gRPC response time $actual_time ms exceeds limit $expected_time ms"
            return 1
        fi
    fi
}

# src/lib/plugins/grpc_tls.sh
#!/bin/bash

# TLS Plugin for grpctestify
# Handles TLS/mTLS configuration and grpcurl flag generation
# Thread-safe implementation using local variables

# Function to register TLS plugin
register_tls_plugin() {
    register_plugin "tls" "parse_tls_section" "TLS/mTLS configuration handler" "internal"
}

# Function to parse TLS section from .gctf file
parse_tls_section() {
    local test_file="$1"
    local tls_section=""
    local in_tls_section=false

    # Parse TLS section from file
    while IFS= read -r line; do
        if [[ "$line" =~ ^---[[:space:]]*TLS[[:space:]]*--- ]]; then
            in_tls_section=true
            continue
        elif [[ "$line" =~ ^---[[:space:]]*[A-Z]+[[:space:]]*--- ]]; then
            in_tls_section=false
            continue
        elif [[ "$in_tls_section" == true ]]; then
            tls_section+="$line"$'\n'
        fi
    done < "$test_file"

    if [[ -n "$tls_section" ]]; then
        process_tls_configuration "$tls_section" "$test_file"
    else
        # Default behavior: TLS with insecure
        echo "default-insecure-tls|-insecure"
    fi
}

# Function to process TLS configuration
process_tls_configuration() {
    local config="$1"
    local test_file="$2"
    local mode=""
    local insecure=""
    local cacert=""
    local cert=""
    local key=""
    local servername=""
    local authority=""

    # Parse key=value pairs
    while IFS= read -r line; do
        line=$(echo "$line" | sed 's/^[[:space:]]*//;s/[[:space:]]*$//')
        [[ -z "$line" || "$line" =~ ^# ]] && continue

        if [[ "$line" =~ ^([^=]+)=(.*)$ ]]; then
            local key_name="${BASH_REMATCH[1]}"
            local value="${BASH_REMATCH[2]}"

            case "$key_name" in
                "mode")
                    mode="$value"
                    ;;
                "insecure")
                    insecure="$value"
                    ;;
                "cacert")
                    cacert="$value"
                    ;;
                "cert")
                    cert="$value"
                    ;;
                "key")
                    key="$value"
                    ;;
                "servername")
                    servername="$value"
                    ;;
                "authority")
                    authority="$value"
                    ;;
            esac
        fi
    done <<< "$config"

    # Determine mode if not specified
    if [[ -z "$mode" ]]; then
        if [[ -n "$cert" || -n "$key" ]]; then
            mode="mtls"
        else
            mode="tls"
        fi
    fi

    # Validate configuration
    validate_tls_configuration "$mode" "$insecure" "$cert" "$key"

    # Generate TLS flags
    generate_tls_flags "$mode" "$insecure" "$cacert" "$cert" "$key" "$servername" "$authority" "$test_file"
}

# Function to validate TLS configuration
validate_tls_configuration() {
    local mode="$1"
    local insecure="$2"
    local cert="$3"
    local key="$4"

    # Check for invalid combinations
    if [[ "$mode" == "plaintext" && ("$insecure" == "true" || "$insecure" == "false" || -n "$cert" || -n "$key") ]]; then
        error "TLS options not allowed with mode=plaintext"
        exit 1
    fi

    # Check for mTLS without cert/key
    if [[ "$mode" == "mtls" && (-z "$cert" || -z "$key") ]]; then
        error "mTLS mode requires both cert and key"
        exit 1
    fi
}

# Function to generate TLS flags
generate_tls_flags() {
    local mode="$1"
    local insecure="$2"
    local cacert="$3"
    local cert="$4"
    local key="$5"
    local servername="$6"
    local authority="$7"
    local test_file="$8"

    local tls_flags=""

    case "$mode" in
        "plaintext")
            tls_flags="-plaintext"
            ;;
        "tls"|"mtls")
            # Add TLS flags (no -plaintext)
            if [[ "$insecure" == "true" ]]; then
                tls_flags+=" -insecure"
            fi

            # Handle certificates - resolve paths (support ENV variables)
            if [[ -n "$cacert" ]]; then
                local resolved_cacert=$(resolve_tls_path "$cacert")
                tls_flags+=" -cacert $resolved_cacert"
            fi

            if [[ -n "$cert" ]]; then
                local resolved_cert=$(resolve_tls_path "$cert")
                tls_flags+=" -cert $resolved_cert"
            fi

            if [[ -n "$key" ]]; then
                local resolved_key=$(resolve_tls_path "$key")
                tls_flags+=" -key $resolved_key"
            fi

            if [[ -n "$servername" ]]; then
                tls_flags+=" -servername $servername"
            fi

            if [[ -n "$authority" ]]; then
                tls_flags+=" -authority $authority"
            fi
            ;;
    esac

    # Trim leading space
    tls_flags=$(echo "$tls_flags" | sed 's/^[[:space:]]*//')

    # Return mode and flags as pipe-separated string
    echo "$mode|$tls_flags"
}

# Function to resolve certificate/key paths (support ENV variables)
resolve_tls_path() {
    local path="$1"

    # If path starts with $, treat as ENV variable
    if [[ "$path" =~ ^\$([A-Z_][A-Z0-9_]*) ]]; then
        local env_var="${BASH_REMATCH[1]}"
        if [[ -n "${!env_var}" ]]; then
            # Check if it's a file path or inline content
            if [[ -f "${!env_var}" ]]; then
                echo "${!env_var}"
            else
                # Treat as inline PEM content, create temp file
                create_temp_pem_from_env "$env_var"
            fi
        else
            error "Environment variable $env_var is not set"
            exit 1
        fi
    else
        echo "$path"
    fi
}

# Function to create temporary PEM file from ENV variable
create_temp_pem_from_env() {
    local env_var="$1"
    local temp_file=$(mktemp)

    echo "${!env_var}" > "$temp_file"

    # Register cleanup on exit
    trap "rm -f '$temp_file'" EXIT

    echo "$temp_file"
}

# Function to get TLS summary for verbose logging
get_tls_summary() {
    local tls_result="$1"
    local mode=$(echo "$tls_result" | cut -d'|' -f1)
    local flags=$(echo "$tls_result" | cut -d'|' -f2)
    local flag_count=$(echo "$flags" | wc -w)
    echo "mode=$mode, flags=$flag_count"
}

# Function to get TLS flags for grpcurl
get_tls_flags() {
    local tls_result="$1"
    echo "$tls_result" | cut -d'|' -f2
}

# Export functions
export -f register_tls_plugin
export -f parse_tls_section
export -f process_tls_configuration
export -f validate_tls_configuration
export -f generate_tls_flags
export -f resolve_tls_path
export -f create_temp_pem_from_env
export -f get_tls_summary
export -f get_tls_flags

# Register the plugin
register_tls_plugin

# src/lib/plugins/grpc_type_validation.sh
#!/bin/bash

# grpc_type_validation.sh - Enhanced type validation plugin
# Provides UUID, timestamp, URL, email, and other advanced validation types

# UUID validation (RFC 4122)
validate_uuid() {
    local value="$1"
    local version="${2:-any}"  # v1, v4, v5, or any

    # Basic UUID format check (8-4-4-4-12 hex digits)
    if [[ ! "$value" =~ ^[0-9a-fA-F]{8}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}-[0-9a-fA-F]{12}$ ]]; then
        return 1
    fi

    # Version-specific validation
    if [[ "$version" != "any" ]]; then
        local version_digit="${value:14:1}"
        case "$version" in
            "v1"|"1") [[ "$version_digit" == "1" ]] || return 1 ;;
            "v4"|"4") [[ "$version_digit" == "4" ]] || return 1 ;;
            "v5"|"5") [[ "$version_digit" == "5" ]] || return 1 ;;
            *) return 1 ;;
        esac
    fi

    return 0
}

# ISO 8601 timestamp validation
validate_iso8601() {
    local value="$1"
    local strict="${2:-false}"

    if [[ "$strict" == "true" ]]; then
        # Strict ISO 8601: YYYY-MM-DDTHH:MM:SS[.sss]Z or YYYY-MM-DDTHH:MM:SS[.sss]Â±HH:MM
        [[ "$value" =~ ^[0-9]{4}-[0-9]{2}-[0-9]{2}T[0-9]{2}:[0-9]{2}:[0-9]{2}(\.[0-9]{1,3})?(Z|[+-][0-9]{2}:[0-9]{2})$ ]]
    else
        # Relaxed timestamp format
        [[ "$value" =~ ^[0-9]{4}-[0-9]{2}-[0-9]{2}T[0-9]{2}:[0-9]{2}:[0-9]{2} ]]
    fi
}

# RFC 3339 timestamp validation
validate_rfc3339() {
    local value="$1"
    # RFC 3339: YYYY-MM-DDTHH:MM:SS[.sss]Z or YYYY-MM-DDTHH:MM:SS[.sss]Â±HH:MM
    [[ "$value" =~ ^[0-9]{4}-[0-9]{2}-[0-9]{2}T[0-9]{2}:[0-9]{2}:[0-9]{2}(\.[0-9]+)?(Z|[+-][0-9]{2}:[0-9]{2})$ ]]
}

# Unix timestamp validation
validate_unix_timestamp() {
    local value="$1"
    local format="${2:-seconds}"  # seconds, milliseconds, microseconds

    case "$format" in
        "seconds")
            # 10 digits for current era (until year 2286)
            [[ "$value" =~ ^[0-9]{10}$ ]] && [[ "$value" -gt 0 ]]
            ;;
        "milliseconds"|"ms")
            # 13 digits
            [[ "$value" =~ ^[0-9]{13}$ ]] && [[ "$value" -gt 0 ]]
            ;;
        "microseconds"|"us")
            # 16 digits
            [[ "$value" =~ ^[0-9]{16}$ ]] && [[ "$value" -gt 0 ]]
            ;;
        *)
            return 1
            ;;
    esac
}

# URL validation (RFC 3986)
validate_url() {
    local value="$1"
    local scheme="${2:-any}"  # http, https, ftp, or any

    # Basic URL structure check
    if [[ ! "$value" =~ ^[a-zA-Z][a-zA-Z0-9+.-]*://[^[:space:]]+$ ]]; then
        return 1
    fi

    # Scheme-specific validation
    if [[ "$scheme" != "any" ]]; then
        case "$scheme" in
            "http")
                [[ "$value" =~ ^http://[^[:space:]]+$ ]] || return 1
                ;;
            "https")
                [[ "$value" =~ ^https://[^[:space:]]+$ ]] || return 1
                ;;
            "ftp")
                [[ "$value" =~ ^ftp://[^[:space:]]+$ ]] || return 1
                ;;
            "ws")
                [[ "$value" =~ ^ws://[^[:space:]]+$ ]] || return 1
                ;;
            "wss")
                [[ "$value" =~ ^wss://[^[:space:]]+$ ]] || return 1
                ;;
            *)
                return 1
                ;;
        esac
    fi

    return 0
}

# Email validation (RFC 5322 simplified)
validate_email() {
    local value="$1"
    local strict="${2:-false}"

    if [[ "$strict" == "true" ]]; then
        # Strict email validation
        [[ "$value" =~ ^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$ ]]
    else
        # Basic email validation
        [[ "$value" =~ ^[^@[:space:]]+@[^@[:space:]]+\.[^@[:space:]]+$ ]]
    fi
}

# JSON Web Token (JWT) validation
validate_jwt() {
    local value="$1"
    local check_structure="${2:-true}"

    # Basic JWT structure: header.payload.signature
    if [[ ! "$value" =~ ^[A-Za-z0-9_-]+\.[A-Za-z0-9_-]+\.[A-Za-z0-9_-]+$ ]]; then
        return 1
    fi

    if [[ "$check_structure" == "true" ]]; then
        # Check if header and payload are valid base64url
        local header payload
        header=$(echo "$value" | cut -d. -f1)
        payload=$(echo "$value" | cut -d. -f2)

        # Try to decode header and payload (basic check)
        if command -v base64 >/dev/null 2>&1; then
            # Add padding if needed and try to decode
            local padded_header="${header}$(printf '%*s' $(((4 - ${#header} % 4) % 4)) | tr ' ' '=')"
            local padded_payload="${payload}$(printf '%*s' $(((4 - ${#payload} % 4) % 4)) | tr ' ' '=')"

            echo "$padded_header" | tr '_-' '/+' | base64 -d >/dev/null 2>&1 || return 1
            echo "$padded_payload" | tr '_-' '/+' | base64 -d >/dev/null 2>&1 || return 1
        fi
    fi

    return 0
}

# IP address validation
validate_ip() {
    local value="$1"
    local version="${2:-any}"  # v4, v6, or any

    case "$version" in
        "v4"|"4")
            validate_ipv4 "$value"
            ;;
        "v6"|"6")
            validate_ipv6 "$value"
            ;;
        "any")
            validate_ipv4 "$value" || validate_ipv6 "$value"
            ;;
        *)
            return 1
            ;;
    esac
}

# IPv4 validation
validate_ipv4() {
    local value="$1"

    # Check basic format
    if [[ ! "$value" =~ ^[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}$ ]]; then
        return 1
    fi

    # Check each octet is 0-255
    local IFS='.'
    local octets=($value)
    for octet in "${octets[@]}"; do
        if [[ $octet -gt 255 ]] || [[ $octet -lt 0 ]]; then
            return 1
        fi
        # No leading zeros unless it's just "0"
        if [[ ${#octet} -gt 1 && $octet == 0* ]]; then
            return 1
        fi
    done

    return 0
}

# IPv6 validation (simplified)
validate_ipv6() {
    local value="$1"

    # Basic IPv6 pattern check
    [[ "$value" =~ ^([0-9a-fA-F]{0,4}:){2,7}[0-9a-fA-F]{0,4}$ ]] || \
    [[ "$value" =~ ^::1$ ]] || \
    [[ "$value" =~ ^::$ ]] || \
    [[ "$value" =~ ^([0-9a-fA-F]{1,4}:){1,7}:$ ]] || \
    [[ "$value" =~ ^:([0-9a-fA-F]{1,4}:){1,7}$ ]]
}

# Semantic version validation
validate_semver() {
    local value="$1"
    local allow_prerelease="${2:-true}"

    if [[ "$allow_prerelease" == "true" ]]; then
        # Allow prerelease and build metadata
        [[ "$value" =~ ^[0-9]+\.[0-9]+\.[0-9]+(-[0-9A-Za-z-]+(\.[0-9A-Za-z-]+)*)?(\+[0-9A-Za-z-]+(\.[0-9A-Za-z-]+)*)?$ ]]
    else
        # Strict semver (major.minor.patch only)
        [[ "$value" =~ ^[0-9]+\.[0-9]+\.[0-9]+$ ]]
    fi
}

# MAC address validation
validate_mac_address() {
    local value="$1"
    local format="${2:-any}"  # colon, dash, or any

    case "$format" in
        "colon")
            [[ "$value" =~ ^([0-9a-fA-F]{2}:){5}[0-9a-fA-F]{2}$ ]]
            ;;
        "dash")
            [[ "$value" =~ ^([0-9a-fA-F]{2}-){5}[0-9a-fA-F]{2}$ ]]
            ;;
        "any")
            [[ "$value" =~ ^([0-9a-fA-F]{2}[:-]){5}[0-9a-fA-F]{2}$ ]]
            ;;
        *)
            return 1
            ;;
    esac
}

# Base64 validation
validate_base64() {
    local value="$1"
    local strict="${2:-false}"

    if [[ "$strict" == "true" ]]; then
        # Strict base64: only A-Z, a-z, 0-9, +, /, and = for padding
        [[ "$value" =~ ^[A-Za-z0-9+/]*={0,2}$ ]] && [[ $((${#value} % 4)) -eq 0 ]]
    else
        # Basic base64 pattern
        [[ "$value" =~ ^[A-Za-z0-9+/].*$ ]]
    fi
}

# Credit card number validation (Luhn algorithm)
validate_credit_card() {
    local value="$1"
    local brand="${2:-any}"  # visa, mastercard, amex, or any

    # Remove spaces and dashes
    value="${value// /}"
    value="${value//-/}"

    # Check if all digits
    [[ "$value" =~ ^[0-9]+$ ]] || return 1

    # Brand-specific validation
    case "$brand" in
        "visa")
            [[ "$value" =~ ^4[0-9]{12,18}$ ]] || return 1
            ;;
        "mastercard")
            [[ "$value" =~ ^5[1-5][0-9]{14}$ ]] || return 1
            ;;
        "amex"|"american_express")
            [[ "$value" =~ ^3[47][0-9]{13}$ ]] || return 1
            ;;
        "discover")
            [[ "$value" =~ ^6011[0-9]{12}$ ]] || return 1
            ;;
        "any")
            # General credit card length check
            [[ ${#value} -ge 13 && ${#value} -le 19 ]] || return 1
            ;;
        *)
            return 1
            ;;
    esac

    # Luhn algorithm validation
    luhn_check "$value"
}

# Luhn algorithm implementation
luhn_check() {
    local number="$1"
    local sum=0
    local alternate=false

    # Process digits from right to left
    for ((i=${#number}-1; i>=0; i--)); do
        local digit=${number:$i:1}

        if [[ "$alternate" == "true" ]]; then
            digit=$((digit * 2))
            if [[ $digit -gt 9 ]]; then
                digit=$((digit - 9))
            fi
        fi

        sum=$((sum + digit))
        alternate=$([ "$alternate" == "true" ] && echo "false" || echo "true")
    done

    [[ $((sum % 10)) -eq 0 ]]
}

# Phone number validation (international format)
validate_phone() {
    local value="$1"
    local format="${2:-international}"  # international, us, or any

    case "$format" in
        "international")
            # E.164 format: +[1-4 digits country code][4-15 digits]
            [[ "$value" =~ ^\+[1-9][0-9]{4,14}$ ]]
            ;;
        "us")
            # US format: (XXX) XXX-XXXX or XXX-XXX-XXXX or XXXXXXXXXX
            [[ "$value" =~ ^\([0-9]{3}\)[[:space:]]*[0-9]{3}-[0-9]{4}$ ]] || \
            [[ "$value" =~ ^[0-9]{3}-[0-9]{3}-[0-9]{4}$ ]] || \
            [[ "$value" =~ ^[0-9]{10}$ ]]
            ;;
        "any")
            # Basic phone number pattern
            [[ "$value" =~ ^[\+]?[0-9\(\)\-\s\.]{7,15}$ ]]
            ;;
        *)
            return 1
            ;;
    esac
}

# Color code validation
validate_color() {
    local value="$1"
    local format="${2:-any}"  # hex, rgb, hsl, or any

    case "$format" in
        "hex")
            [[ "$value" =~ ^#([0-9a-fA-F]{3}|[0-9a-fA-F]{6})$ ]]
            ;;
        "rgb")
            [[ "$value" =~ ^rgb\([[:space:]]*([0-9]|[1-9][0-9]|1[0-9][0-9]|2[0-4][0-9]|25[0-5])[[:space:]]*,[[:space:]]*([0-9]|[1-9][0-9]|1[0-9][0-9]|2[0-4][0-9]|25[0-5])[[:space:]]*,[[:space:]]*([0-9]|[1-9][0-9]|1[0-9][0-9]|2[0-4][0-9]|25[0-5])[[:space:]]*\)$ ]]
            ;;
        "hsl")
            [[ "$value" =~ ^hsl\([[:space:]]*([0-9]|[1-9][0-9]|[12][0-9][0-9]|3[0-5][0-9]|360)[[:space:]]*,[[:space:]]*([0-9]|[1-9][0-9]|100)%[[:space:]]*,[[:space:]]*([0-9]|[1-9][0-9]|100)%[[:space:]]*\)$ ]]
            ;;
        "any")
            validate_color "$value" "hex" || \
            validate_color "$value" "rgb" || \
            validate_color "$value" "hsl"
            ;;
        *)
            return 1
            ;;
    esac
}

# Plugin assertion functions for jq integration
assert_type_uuid() {
    local response="$1"
    local field_path="$2"
    local uuid_version="${3:-any}"

    local value
    value=$(echo "$response" | jq -r "$field_path" 2>/dev/null)

    if [[ "$value" == "null" || -z "$value" ]]; then
        log error "Field '$field_path' is null or empty"
        return 1
    fi

    if validate_uuid "$value" "$uuid_version"; then
        log debug "UUID validation passed for field '$field_path': $value"
        return 0
    else
        log error "UUID validation failed for field '$field_path': $value"
        return 1
    fi
}

assert_type_timestamp() {
    local response="$1"
    local field_path="$2"
    local timestamp_format="${3:-iso8601}"

    local value
    value=$(echo "$response" | jq -r "$field_path" 2>/dev/null)

    if [[ "$value" == "null" || -z "$value" ]]; then
        log error "Field '$field_path' is null or empty"
        return 1
    fi

    case "$timestamp_format" in
        "iso8601"|"iso")
            validate_iso8601 "$value"
            ;;
        "rfc3339"|"rfc")
            validate_rfc3339 "$value"
            ;;
        "unix"|"epoch")
            validate_unix_timestamp "$value" "seconds"
            ;;
        "unix_ms"|"epoch_ms")
            validate_unix_timestamp "$value" "milliseconds"
            ;;
        *)
            log error "Unknown timestamp format: $timestamp_format"
            return 1
            ;;
    esac

    local result=$?
    if [[ $result -eq 0 ]]; then
        log debug "Timestamp validation passed for field '$field_path': $value"
    else
        log error "Timestamp validation failed for field '$field_path': $value (format: $timestamp_format)"
    fi
    return $result
}

assert_type_url() {
    local response="$1"
    local field_path="$2"
    local scheme="${3:-any}"

    local value
    value=$(echo "$response" | jq -r "$field_path" 2>/dev/null)

    if [[ "$value" == "null" || -z "$value" ]]; then
        log error "Field '$field_path' is null or empty"
        return 1
    fi

    if validate_url "$value" "$scheme"; then
        log debug "URL validation passed for field '$field_path': $value"
        return 0
    else
        log error "URL validation failed for field '$field_path': $value (scheme: $scheme)"
        return 1
    fi
}

assert_type_email() {
    local response="$1"
    local field_path="$2"
    local strict="${3:-false}"

    local value
    value=$(echo "$response" | jq -r "$field_path" 2>/dev/null)

    if [[ "$value" == "null" || -z "$value" ]]; then
        log error "Field '$field_path' is null or empty"
        return 1
    fi

    if validate_email "$value" "$strict"; then
        log debug "Email validation passed for field '$field_path': $value"
        return 0
    else
        log error "Email validation failed for field '$field_path': $value"
        return 1
    fi
}

assert_type_ip() {
    local response="$1"
    local field_path="$2"
    local version="${3:-any}"

    local value
    value=$(echo "$response" | jq -r "$field_path" 2>/dev/null)

    if [[ "$value" == "null" || -z "$value" ]]; then
        log error "Field '$field_path' is null or empty"
        return 1
    fi

    if validate_ip "$value" "$version"; then
        log debug "IP validation passed for field '$field_path': $value"
        return 0
    else
        log error "IP validation failed for field '$field_path': $value (version: $version)"
        return 1
    fi
}

# Register type validation plugin
register_type_validation_plugin() {
    register_plugin "uuid" "assert_type_uuid" "UUID validation plugin" "internal"
    register_plugin "timestamp" "assert_type_timestamp" "Timestamp validation plugin" "internal"
    register_plugin "url" "assert_type_url" "URL validation plugin" "internal"
    register_plugin "email" "assert_type_email" "Email validation plugin" "internal"
    register_plugin "ip" "assert_type_ip" "IP address validation plugin" "internal"
}

# Export validation functions for direct use
export -f validate_uuid
export -f validate_iso8601
export -f validate_rfc3339
export -f validate_unix_timestamp
export -f validate_url
export -f validate_email
export -f validate_jwt
export -f validate_ip
export -f validate_ipv4
export -f validate_ipv6
export -f validate_semver
export -f validate_mac_address
export -f validate_base64
export -f validate_credit_card
export -f validate_phone
export -f validate_color

# Export plugin functions
export -f assert_type_uuid
export -f assert_type_timestamp
export -f assert_type_url
export -f assert_type_email
export -f assert_type_ip
export -f register_type_validation_plugin

# src/lib/send_completions.sh
send_completions() {
  echo $'# grpctestify completion                                   -*- shell-script -*-'
  echo $''
  echo $'# This bash completions script was generated by'
  echo $'# completely (https://github.com/bashly-framework/completely)'
  echo $'# Modifying it manually is not recommended'
  echo $''
  echo $'_grpctestify_completions_filter() {'
  echo $'  local words="$1"'
  echo $'  local cur=${COMP_WORDS[COMP_CWORD]}'
  echo $'  local result=()'
  echo $''
  echo $'  if [[ "${cur:0:1}" == "-" ]]; then'
  echo $'    echo "$words"'
  echo $''
  echo $'  else'
  echo $'    for word in $words; do'
  echo $'      [[ "${word:0:1}" != "-" ]] && result+=("$word")'
  echo $'    done'
  echo $''
  echo $'    echo "${result[*]}"'
  echo $''
  echo $'  fi'
  echo $'}'
  echo $''
  echo $'_grpctestify_completions() {'
  echo $'  local cur=${COMP_WORDS[COMP_CWORD]}'
  echo $'  local compwords=("${COMP_WORDS[@]:1:$COMP_CWORD-1}")'
  echo $'  local compline="${compwords[*]}"'
  echo $''
  echo $'  case "$compline" in'
  echo $'    *\'--progress\')'
  echo $'      while read -r; do COMPREPLY+=("$REPLY"); done < <(compgen -W "$(_grpctestify_completions_filter "none dots")" -- "$cur")'
  echo $'      ;;'
  echo $''
  echo $'    *)'
  echo $'      while read -r; do COMPREPLY+=("$REPLY"); done < <(compgen -W "$(_grpctestify_completions_filter "--completion --config --create-plugin --help --init-config --list-plugins --log-junit --no-color --no-retry --parallel --progress --retry --retry-delay --timeout --update --verbose --version -c -h -v")" -- "$cur")'
  echo $'      ;;'
  echo $''
  echo $'  esac'
  echo $'} &&'
  echo $'  complete -F _grpctestify_completions grpctestify'
  echo $''
  echo $'# ex: filetype=sh'
}

# :command.command_functions

# :command.parse_requirements
parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --version)
        version_command
        exit
        ;;

      --help | -h)
        long_usage=yes
        grpctestify_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.environment_variables_filter
  # :command.environment_variables_default
  export GRPCTESTIFY_ADDRESS="${GRPCTESTIFY_ADDRESS:-localhost:4770}"
  export GRPCTESTIFY_TIMEOUT="${GRPCTESTIFY_TIMEOUT:-30}"
  export GRPCTESTIFY_VERBOSE="${GRPCTESTIFY_VERBOSE:-false}"
  export EXTERNAL_PLUGIN_DIR="${EXTERNAL_PLUGIN_DIR:-~/.grpctestify/plugins}"

  env_var_names+=("GRPCTESTIFY_ADDRESS")
  env_var_names+=("GRPCTESTIFY_TIMEOUT")
  env_var_names+=("GRPCTESTIFY_VERBOSE")
  env_var_names+=("EXTERNAL_PLUGIN_DIR")

  # :command.dependencies_filter
  missing_deps=
  # :dependency.filter
  if ! command -v grpcurl >/dev/null 2>&1; then
    printf "missing dependency: grpcurl\n" >&2
    printf "%s\n\n" "Install grpcurl: https://github.com/fullstorydev/grpcurl#installation" >&2
    missing_deps=1
  else
    deps['grpcurl']="$(command -v grpcurl | head -n1)"
  fi

  # :dependency.filter
  if ! command -v jq >/dev/null 2>&1; then
    printf "missing dependency: jq\n" >&2
    printf "%s\n\n" "Install jq: https://jqlang.github.io/jq/download/" >&2
    missing_deps=1
  else
    deps['jq']="$(command -v jq | head -n1)"
  fi

  # :dependency.filter
  if ! command -v bc >/dev/null 2>&1; then
    printf "missing dependency: bc\n" >&2
    printf "%s\n\n" "Install bc: sudo apt install bc (Ubuntu/Debian) or brew install bc (macOS)" >&2
    missing_deps=1
  else
    deps['bc']="$(command -v bc | head -n1)"
  fi

  if [[ -n $missing_deps ]]; then
    exit 1
  fi

  # :command.command_filter
  action="root"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --no-color | -c)

        # :flag.case_no_arg
        args['--no-color']=1
        shift
        ;;

      # :flag.case
      --verbose | -v)

        # :flag.case_no_arg
        args['--verbose']=1
        shift
        ;;

      # :flag.case
      --progress)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--progress']="$2"
          shift
          shift
        else
          printf "%s\n" "--progress requires an argument: --progress PROGRESS_MODE" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --parallel)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--parallel']="$2"
          shift
          shift
        else
          printf "%s\n" "--parallel requires an argument: --parallel PARALLEL" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --timeout)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--timeout']="$2"
          shift
          shift
        else
          printf "%s\n" "--timeout requires an argument: --timeout TIMEOUT" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --retry)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--retry']="$2"
          shift
          shift
        else
          printf "%s\n" "--retry requires an argument: --retry RETRIES" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --retry-delay)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--retry-delay']="$2"
          shift
          shift
        else
          printf "%s\n" "--retry-delay requires an argument: --retry-delay DELAY" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --no-retry)

        # :flag.case_no_arg
        args['--no-retry']=1
        shift
        ;;

      # :flag.case
      --update)

        # :flag.case_no_arg
        args['--update']=1
        shift
        ;;

      # :flag.case
      --completion)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--completion']="$2"
          shift
          shift
        else
          printf "%s\n" "--completion requires an argument: --completion SHELL_TYPE" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --config)

        # :flag.case_no_arg
        args['--config']=1
        shift
        ;;

      # :flag.case
      --init-config)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--init-config']="$2"
          shift
          shift
        else
          printf "%s\n" "--init-config requires an argument: --init-config CONFIG_FILE" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --list-plugins)

        # :flag.case_no_arg
        args['--list-plugins']=1
        shift
        ;;

      # :flag.case
      --create-plugin)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--create-plugin']="$2"
          shift
          shift
        else
          printf "%s\n" "--create-plugin requires an argument: --create-plugin PLUGIN_NAME" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --log-junit)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--log-junit']="$2"
          shift
          shift
        else
          printf "%s\n" "--log-junit requires an argument: --log-junit JUNIT_FILE" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        # :argument.case
        if [[ -z ${args['test_path']+x} ]]; then
          args['test_path']=$1
          shift
        else
          printf "invalid argument: %s\n" "$key" >&2
          exit 1
        fi

        ;;

    esac
  done

  # :command.default_assignments
  [[ -n ${args['--progress']:-} ]] || args['--progress']="none"
  [[ -n ${args['--parallel']:-} ]] || args['--parallel']="1"
  [[ -n ${args['--timeout']:-} ]] || args['--timeout']="30"
  [[ -n ${args['--retry']:-} ]] || args['--retry']="3"
  [[ -n ${args['--retry-delay']:-} ]] || args['--retry-delay']="1"

  # :command.whitelist_filter
  if [[ ${args['--progress']:-} ]] && [[ ! ${args['--progress']:-} =~ ^(none|dots)$ ]]; then
    printf "%s\n" "--progress must be one of: none, dots" >&2
    exit 1
  fi

}

# :command.initialize
initialize() {
  declare -g version="v1.0.0"
  set -e

  # :command.environment_variables_default
  export GRPCTESTIFY_ADDRESS="${GRPCTESTIFY_ADDRESS:-localhost:4770}"
  export GRPCTESTIFY_TIMEOUT="${GRPCTESTIFY_TIMEOUT:-30}"
  export GRPCTESTIFY_VERBOSE="${GRPCTESTIFY_VERBOSE:-false}"
  export EXTERNAL_PLUGIN_DIR="${EXTERNAL_PLUGIN_DIR:-~/.grpctestify/plugins}"

}

# :command.run
run() {
  # :command.globals
  declare -g long_usage=''
  declare -g -A args=()
  declare -g -A deps=()
  declare -g -a env_var_names=()
  declare -g -a input=()

  normalize_input "$@"
  parse_requirements "${input[@]}"

  case "$action" in
    "root") root_command ;;
  esac
}

if [[ "${BASH_SOURCE[0]}" == "${0}" ]]; then
  # :command.start
  command_line_args=("$@")
  initialize
  run "${command_line_args[@]}"
fi
